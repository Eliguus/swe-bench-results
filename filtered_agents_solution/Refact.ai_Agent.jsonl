{"instance_id": "django__django-14608", "model_patch": "diff --git a/django/forms/formsets.py b/django/forms/formsets.py\nindex a89c35599f..1b0d4554e0 100644\n--- a/django/forms/formsets.py\n+++ b/django/forms/formsets.py\n@@ -333,7 +333,7 @@ class BaseFormSet:\n         self._non_form_errors.\n         \"\"\"\n         self._errors = []\n-        self._non_form_errors = self.error_class()\n+        self._non_form_errors = self.error_class(error_class='nonform')\n         empty_forms_count = 0\n \n         if not self.is_bound:  # Stop further processing.\n@@ -380,7 +380,7 @@ class BaseFormSet:\n             # Give self.clean() a chance to do cross-form validation.\n             self.clean()\n         except ValidationError as e:\n-            self._non_form_errors = self.error_class(e.error_list)\n+            self._non_form_errors = self.error_class(e.error_list, error_class='nonform')\n \n     def clean(self):\n         \"\"\"\ndiff --git a/tests/admin_views/tests.py b/tests/admin_views/tests.py\nindex 880ba0b85f..2d5bf6887e 100644\n--- a/tests/admin_views/tests.py\n+++ b/tests/admin_views/tests.py\n@@ -3348,7 +3348,7 @@ class AdminViewListEditable(TestCase):\n         response = self.client.post(reverse('admin:admin_views_person_changelist'), data)\n         non_form_errors = response.context['cl'].formset.non_form_errors()\n         self.assertIsInstance(non_form_errors, ErrorList)\n-        self.assertEqual(str(non_form_errors), str(ErrorList([\"Grace is not a Zombie\"])))\n+        self.assertEqual(str(non_form_errors), str(ErrorList([\"Grace is not a Zombie\"], error_class='nonform')))\n \n     def test_list_editable_ordering(self):\n         collector = Collector.objects.create(id=1, name=\"Frederick Clegg\")\ndiff --git a/tests/forms_tests/tests/test_formsets.py b/tests/forms_tests/tests/test_formsets.py\nindex 889560aa74..122f6850db 100644\n--- a/tests/forms_tests/tests/test_formsets.py\n+++ b/tests/forms_tests/tests/test_formsets.py\n@@ -1482,3 +1482,81 @@ class AllValidTests(SimpleTestCase):\n         expected_errors = [{'votes': ['This field is required.']}, {'votes': ['This field is required.']}]\n         self.assertEqual(formset1._errors, expected_errors)\n         self.assertEqual(formset2._errors, expected_errors)\n+\n+\n+class NonFormErrorCSSClassTests(SimpleTestCase):\n+    \"\"\"Tests for the 'nonform' CSS class on FormSet non-form errors.\"\"\"\n+\n+    def test_non_form_errors_have_nonform_css_class(self):\n+        \"\"\"FormSet non-form errors should have 'nonform' CSS class.\"\"\"\n+        class TestFormSet(BaseFormSet):\n+            def clean(self):\n+                super().clean()\n+                raise ValidationError(\"This is a non-form error\")\n+\n+        FormSet = formset_factory(Choice, formset=TestFormSet)\n+        data = {\n+            'form-TOTAL_FORMS': '1',\n+            'form-INITIAL_FORMS': '0',\n+            'form-0-choice': 'test',\n+            'form-0-votes': '1',\n+        }\n+        formset = FormSet(data)\n+        self.assertFalse(formset.is_valid())\n+        \n+        non_form_errors = formset.non_form_errors()\n+        self.assertEqual(non_form_errors.error_class, 'errorlist nonform')\n+        self.assertIn('nonform', non_form_errors.error_class)\n+        self.assertIn('<ul class=\"errorlist nonform\">', str(non_form_errors))\n+\n+    def test_management_form_errors_have_nonform_css_class(self):\n+        \"\"\"FormSet management form errors should have 'nonform' CSS class.\"\"\"\n+        FormSet = formset_factory(Choice)\n+        # Missing management form data should trigger non-form errors\n+        formset = FormSet({})\n+        self.assertFalse(formset.is_valid())\n+        \n+        non_form_errors = formset.non_form_errors()\n+        self.assertEqual(non_form_errors.error_class, 'errorlist nonform')\n+        self.assertIn('nonform', non_form_errors.error_class)\n+        self.assertIn('<ul class=\"errorlist nonform\">', str(non_form_errors))\n+\n+    def test_consistency_with_form_non_field_errors(self):\n+        \"\"\"FormSet non-form errors should be consistent with Form non-field errors.\"\"\"\n+        # Test Form non-field errors (should have 'nonfield')\n+        class TestForm(Form):\n+            choice = CharField()\n+            votes = IntegerField()\n+            \n+            def clean(self):\n+                cleaned_data = super().clean()\n+                raise ValidationError(\"This is a non-field error\")\n+        \n+        form = TestForm({'choice': 'test', 'votes': '1'})\n+        self.assertFalse(form.is_valid())\n+        form_non_field_errors = form.non_field_errors()\n+        self.assertEqual(form_non_field_errors.error_class, 'errorlist nonfield')\n+        \n+        # Test FormSet non-form errors (should have 'nonform')\n+        class TestFormSet(BaseFormSet):\n+            def clean(self):\n+                super().clean()\n+                raise ValidationError(\"This is a non-form error\")\n+\n+        FormSet = formset_factory(Choice, formset=TestFormSet)\n+        data = {\n+            'form-TOTAL_FORMS': '1',\n+            'form-INITIAL_FORMS': '0',\n+            'form-0-choice': 'test',\n+            'form-0-votes': '1',\n+        }\n+        formset = FormSet(data)\n+        self.assertFalse(formset.is_valid())\n+        formset_non_form_errors = formset.non_form_errors()\n+        self.assertEqual(formset_non_form_errors.error_class, 'errorlist nonform')\n+        \n+        # Both should have 'errorlist' but different specific classes\n+        self.assertIn('errorlist', form_non_field_errors.error_class)\n+        self.assertIn('errorlist', formset_non_form_errors.error_class)\n+        self.assertIn('nonfield', form_non_field_errors.error_class)\n+        self.assertIn('nonform', formset_non_form_errors.error_class)\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "scikit-learn__scikit-learn-13779", "model_patch": "diff --git a/sklearn/ensemble/tests/test_voting.py b/sklearn/ensemble/tests/test_voting.py\nindex 2a19bc9a6..29bf10600 100644\n--- a/sklearn/ensemble/tests/test_voting.py\n+++ b/sklearn/ensemble/tests/test_voting.py\n@@ -507,3 +507,41 @@ def test_transform():\n             eclf3.transform(X).swapaxes(0, 1).reshape((4, 6)),\n             eclf2.transform(X)\n     )\n+\n+\n+@pytest.mark.filterwarnings('ignore: Default solver will be changed')  # 0.22\n+@pytest.mark.filterwarnings('ignore: Default multi_class will')  # 0.22\n+@pytest.mark.filterwarnings('ignore:The default value of n_estimators')\n+def test_none_estimator_with_sample_weight():\n+    \"\"\"Test that VotingClassifier and VotingRegressor work with None estimators and sample_weight.\"\"\"\n+    # Test VotingClassifier\n+    X, y = datasets.load_iris(return_X_y=True)\n+    sample_weight = np.ones(y.shape)\n+    \n+    # Create classifier with all estimators\n+    clf1 = LogisticRegression(solver='lbfgs', multi_class='auto', random_state=123)\n+    clf2 = RandomForestClassifier(n_estimators=10, random_state=123)\n+    eclf = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2)])\n+    \n+    # Fit with sample_weight - should work\n+    eclf.fit(X, y, sample_weight=sample_weight)\n+    \n+    # Set one estimator to None and fit again with sample_weight - should work\n+    eclf.set_params(lr=None)\n+    eclf.fit(X, y, sample_weight=sample_weight)\n+    \n+    # Test VotingRegressor\n+    X_r, y_r = datasets.load_boston(return_X_y=True)\n+    sample_weight_r = np.ones(y_r.shape)\n+    \n+    # Create regressor with all estimators\n+    reg1 = DummyRegressor(strategy='mean')\n+    reg2 = DummyRegressor(strategy='median')\n+    ereg = VotingRegressor(estimators=[('mean', reg1), ('median', reg2)])\n+    \n+    # Fit with sample_weight - should work\n+    ereg.fit(X_r, y_r, sample_weight=sample_weight_r)\n+    \n+    # Set one estimator to None and fit again with sample_weight - should work\n+    ereg.set_params(mean=None)\n+    ereg.fit(X_r, y_r, sample_weight=sample_weight_r)\ndiff --git a/sklearn/ensemble/voting.py b/sklearn/ensemble/voting.py\nindex 7afa7180c..13accdcec 100644\n--- a/sklearn/ensemble/voting.py\n+++ b/sklearn/ensemble/voting.py\n@@ -78,7 +78,7 @@ class _BaseVoting(_BaseComposition, TransformerMixin):\n \n         if sample_weight is not None:\n             for name, step in self.estimators:\n-                if not has_fit_parameter(step, 'sample_weight'):\n+                if step is not None and not has_fit_parameter(step, 'sample_weight'):\n                     raise ValueError('Underlying estimator \\'%s\\' does not'\n                                      ' support sample weights.' % name)\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "sympy__sympy-13031", "model_patch": "diff --git a/sympy/matrices/sparse.py b/sympy/matrices/sparse.py\nindex e6f36cdf35..ca7efda7f8 100644\n--- a/sympy/matrices/sparse.py\n+++ b/sympy/matrices/sparse.py\n@@ -985,8 +985,9 @@ def col_join(self, other):\n         >>> C == A.row_insert(A.rows, Matrix(B))\n         True\n         \"\"\"\n-        if not self:\n-            return type(self)(other)\n+        # A null matrix can always be stacked (see #10770)\n+        if self.rows == 0 and self.cols != other.cols:\n+            return self._new(0, other.cols, []).col_join(other)\n         A, B = self, other\n         if not A.cols == B.cols:\n             raise ShapeError()\n@@ -1191,8 +1192,9 @@ def row_join(self, other):\n         >>> C == A.col_insert(A.cols, B)\n         True\n         \"\"\"\n-        if not self:\n-            return type(self)(other)\n+        # A null matrix can always be stacked (see #10770)\n+        if self.cols == 0 and self.rows != other.rows:\n+            return self._new(other.rows, 0, []).row_join(other)\n         A, B = self, other\n         if not A.rows == B.rows:\n             raise ShapeError()\ndiff --git a/sympy/matrices/tests/test_sparse.py b/sympy/matrices/tests/test_sparse.py\nindex acea940281..0d838166eb 100644\n--- a/sympy/matrices/tests/test_sparse.py\n+++ b/sympy/matrices/tests/test_sparse.py\n@@ -587,3 +587,44 @@ def test_hermitian():\n     assert a.is_hermitian is None\n     a[0, 1] = a[1, 0]*I\n     assert a.is_hermitian is False\n+\n+\n+def test_sparse_matrix_hstack_vstack_empty():\n+    \"\"\"Test for regression #12938 - SparseMatrix hstack/vstack with empty matrices\"\"\"\n+    # Test hstack with empty matrices\n+    M1 = SparseMatrix.zeros(0, 0)\n+    M2 = SparseMatrix.zeros(0, 1)\n+    M3 = SparseMatrix.zeros(0, 2)\n+    M4 = SparseMatrix.zeros(0, 3)\n+    \n+    result = SparseMatrix.hstack(M1, M2, M3, M4)\n+    assert result.shape == (0, 6)\n+    \n+    # Test vstack with empty matrices\n+    V1 = SparseMatrix.zeros(0, 0)\n+    V2 = SparseMatrix.zeros(1, 0)\n+    V3 = SparseMatrix.zeros(2, 0)\n+    V4 = SparseMatrix.zeros(3, 0)\n+    \n+    result = SparseMatrix.vstack(V1, V2, V3, V4)\n+    assert result.shape == (6, 0)\n+    \n+    # Test individual row_join operations\n+    step1 = M1.row_join(M2)\n+    assert step1.shape == (0, 1)\n+    \n+    step2 = step1.row_join(M3)\n+    assert step2.shape == (0, 3)\n+    \n+    step3 = step2.row_join(M4)\n+    assert step3.shape == (0, 6)\n+    \n+    # Test individual col_join operations\n+    step1 = V1.col_join(V2)\n+    assert step1.shape == (1, 0)\n+    \n+    step2 = step1.col_join(V3)\n+    assert step2.shape == (3, 0)\n+    \n+    step3 = step2.col_join(V4)\n+    assert step3.shape == (6, 0)\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "scikit-learn__scikit-learn-14087", "model_patch": "diff --git a/sklearn/linear_model/logistic.py b/sklearn/linear_model/logistic.py\nindex 1999f1dae..e9a38e933 100644\n--- a/sklearn/linear_model/logistic.py\n+++ b/sklearn/linear_model/logistic.py\n@@ -2170,7 +2170,7 @@ class LogisticRegressionCV(LogisticRegression, BaseEstimator,\n                 # Take the best scores across every fold and the average of\n                 # all coefficients corresponding to the best scores.\n                 best_indices = np.argmax(scores, axis=1)\n-                if self.multi_class == 'ovr':\n+                if multi_class == 'ovr':\n                     w = np.mean([coefs_paths[i, best_indices[i], :]\n                                  for i in range(len(folds))], axis=0)\n                 else:\n@@ -2181,7 +2181,11 @@ class LogisticRegressionCV(LogisticRegression, BaseEstimator,\n                 self.C_.append(np.mean(self.Cs_[best_indices_C]))\n \n                 best_indices_l1 = best_indices // len(self.Cs_)\n-                self.l1_ratio_.append(np.mean(l1_ratios_[best_indices_l1]))\n+                if l1_ratios_[0] is None:\n+                    # When ElasticNet is not used, all l1_ratios are None\n+                    self.l1_ratio_.append(None)\n+                else:\n+                    self.l1_ratio_.append(np.mean([l1_ratios_[i] for i in best_indices_l1]))\n \n             if multi_class == 'multinomial':\n                 self.C_ = np.tile(self.C_, n_classes)\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "django__django-12708", "model_patch": "diff --git a/django/db/backends/base/schema.py b/django/db/backends/base/schema.py\nindex 61f88401ab..1f521cfc5c 100644\n--- a/django/db/backends/base/schema.py\n+++ b/django/db/backends/base/schema.py\n@@ -393,7 +393,7 @@ class BaseDatabaseSchemaEditor:\n         news = {tuple(fields) for fields in new_index_together}\n         # Deleted indexes\n         for fields in olds.difference(news):\n-            self._delete_composed_index(model, fields, {'index': True}, self.sql_delete_index)\n+            self._delete_composed_index(model, fields, {'index': True, 'unique': False}, self.sql_delete_index)\n         # Created indexes\n         for field_names in news.difference(olds):\n             fields = [model._meta.get_field(field) for field in field_names]\ndiff --git a/tests/schema/tests.py b/tests/schema/tests.py\nindex 9aa1e239ac..a4cc7b0e3a 100644\n--- a/tests/schema/tests.py\n+++ b/tests/schema/tests.py\n@@ -2184,6 +2184,58 @@ class SchemaTests(TransactionTestCase):\n         with connection.schema_editor() as editor:\n             editor.alter_index_together(Book, [['author', 'title']], [])\n \n+    @isolate_apps('schema')\n+    def test_index_together_with_unique_together_same_fields(self):\n+        \"\"\"\n+        Tests that deleting index_together works when unique_together exists\n+        on the same fields. Regression test for issue where both constraints\n+        were found when looking for index constraints to delete.\n+        \"\"\"\n+        class TestModel(Model):\n+            field1 = CharField(max_length=100)\n+            field2 = CharField(max_length=100)\n+            \n+            class Meta:\n+                app_label = 'schema'\n+                unique_together = [('field1', 'field2')]\n+                index_together = [('field1', 'field2')]\n+\n+        self.isolated_local_models = [TestModel]\n+\n+        # Create the table with both constraints\n+        with connection.schema_editor() as editor:\n+            editor.create_model(TestModel)\n+\n+        # Verify both constraints exist\n+        constraints = self.get_constraints(TestModel._meta.db_table)\n+        field_constraints = [\n+            details for details in constraints.values()\n+            if details['columns'] == ['field1', 'field2']\n+        ]\n+        \n+        index_constraints = [c for c in field_constraints if c['index'] and not c['unique']]\n+        unique_constraints = [c for c in field_constraints if c['unique']]\n+        \n+        self.assertEqual(len(index_constraints), 1, \"Should have one index constraint\")\n+        self.assertEqual(len(unique_constraints), 1, \"Should have one unique constraint\")\n+\n+        # This should not raise an error (was failing before the fix)\n+        with connection.schema_editor() as editor:\n+            editor.alter_index_together(TestModel, [('field1', 'field2')], [])\n+\n+        # Verify only the index constraint was deleted\n+        constraints = self.get_constraints(TestModel._meta.db_table)\n+        field_constraints = [\n+            details for details in constraints.values()\n+            if details['columns'] == ['field1', 'field2']\n+        ]\n+        \n+        index_constraints = [c for c in field_constraints if c['index'] and not c['unique']]\n+        unique_constraints = [c for c in field_constraints if c['unique']]\n+        \n+        self.assertEqual(len(index_constraints), 0, \"Index constraint should be deleted\")\n+        self.assertEqual(len(unique_constraints), 1, \"Unique constraint should remain\")\n+\n     def test_create_index_together(self):\n         \"\"\"\n         Tests creating models with index_together already defined\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "astropy__astropy-14995", "model_patch": "diff --git a/astropy/nddata/mixins/ndarithmetic.py b/astropy/nddata/mixins/ndarithmetic.py\nindex 4153dfccb2..17d81f4031 100644\n--- a/astropy/nddata/mixins/ndarithmetic.py\n+++ b/astropy/nddata/mixins/ndarithmetic.py\n@@ -522,6 +522,9 @@ class NDArithmeticMixin:\n             return deepcopy(operand.mask)\n         elif operand is None:\n             return deepcopy(self.mask)\n+        elif operand is not None and operand.mask is None:\n+            # operand has no mask, just return a copy of self.mask\n+            return deepcopy(self.mask)\n         else:\n             # Now lets calculate the resulting mask (operation enforces copy)\n             return handle_mask(self.mask, operand.mask, **kwds)\ndiff --git a/astropy/nddata/mixins/tests/test_ndarithmetic.py b/astropy/nddata/mixins/tests/test_ndarithmetic.py\nindex 8c461155ab..3f7c51b102 100644\n--- a/astropy/nddata/mixins/tests/test_ndarithmetic.py\n+++ b/astropy/nddata/mixins/tests/test_ndarithmetic.py\n@@ -1226,6 +1226,51 @@ def test_arithmetics_mask_func():\n         nd1.add(nd2, handle_mask=mask_sad_func, fun=1)\n \n \n+def test_arithmetics_mask_bitwise_or_with_none():\n+    \"\"\"Test mask propagation with np.bitwise_or when one operand has no mask.\n+    \n+    This tests the fix for issue where np.bitwise_or would fail when trying\n+    to operate on an integer array and None.\n+    \"\"\"\n+    array = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n+    mask = np.array([[0, 1, 64], [8, 0, 1], [2, 1, 0]])\n+\n+    # Test with mask and scalar (no mask)\n+    nd_mask = NDDataArithmetic(array, mask=mask)\n+    result = nd_mask.multiply(2., handle_mask=np.bitwise_or)\n+    assert_array_equal(result.mask, mask)\n+\n+    # Test with mask and NDData without mask\n+    nd_nomask = NDDataArithmetic(array)\n+    result = nd_mask.multiply(nd_nomask, handle_mask=np.bitwise_or)\n+    assert_array_equal(result.mask, mask)\n+\n+    # Test reverse order (no mask * mask)\n+    result = nd_nomask.multiply(nd_mask, handle_mask=np.bitwise_or)\n+    assert_array_equal(result.mask, mask)\n+\n+    # Test specific arithmetic operations that are safe\n+    for op_name in ['add', 'subtract', 'multiply']:\n+        op_method = getattr(nd_mask, op_name)\n+        result = op_method(2., handle_mask=np.bitwise_or)\n+        assert_array_equal(result.mask, mask, \n+                          f\"Failed for {op_name} with scalar\")\n+        \n+        result = op_method(nd_nomask, handle_mask=np.bitwise_or)\n+        assert_array_equal(result.mask, mask, \n+                          f\"Failed for {op_name} with no-mask operand\")\n+    \n+    # Test divide separately with safe values\n+    result = nd_mask.divide(2., handle_mask=np.bitwise_or)\n+    assert_array_equal(result.mask, mask)\n+    \n+    # Create a safe array for division (no zeros)\n+    safe_array = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n+    nd_safe = NDDataArithmetic(safe_array)\n+    result = nd_mask.divide(nd_safe, handle_mask=np.bitwise_or)\n+    assert_array_equal(result.mask, mask)\n+\n+\n @pytest.mark.parametrize(\"meth\", [\"add\", \"subtract\", \"divide\", \"multiply\"])\n def test_two_argument_useage(meth):\n     ndd1 = NDDataArithmetic(np.ones((3, 3)))\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "django__django-13964", "model_patch": "diff --git a/django/db/models/base.py b/django/db/models/base.py\nindex 2428218696..3bc96be83c 100644\n--- a/django/db/models/base.py\n+++ b/django/db/models/base.py\n@@ -941,6 +941,10 @@ class Model(metaclass=ModelBase):\n                 # cached relationship.\n                 if getattr(obj, field.target_field.attname) != getattr(self, field.attname):\n                     field.delete_cached_value(self)\n+                    # Update the foreign key field to reflect the current primary key value\n+                    # This handles cases where the related object's primary key was changed\n+                    # after assignment (e.g., non-auto primary keys set after object creation)\n+                    setattr(self, field.attname, getattr(obj, field.target_field.attname))\n \n     def delete(self, using=None, keep_parents=False):\n         using = using or router.db_for_write(self.__class__, instance=self)\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "sympy__sympy-18698", "model_patch": "diff --git a/sympy/polys/polytools.py b/sympy/polys/polytools.py\nindex c9e77a901f..3fd00a0f3a 100644\n--- a/sympy/polys/polytools.py\n+++ b/sympy/polys/polytools.py\n@@ -5895,6 +5895,56 @@ def _factors_product(factors):\n     return Mul(*[f.as_expr()**k for f, k in factors])\n \n \n+def _group_factors_by_multiplicity(factors, method):\n+    \"\"\"Group factors with the same multiplicity for square-free factorization.\n+    \n+    For sqf method, factors with the same exponent should be grouped together.\n+    For example: [(x-1, 3), (x-2, 3)] -> [(x**2-3*x+2, 3)]\n+    \"\"\"\n+    if method != 'sqf':\n+        return factors\n+    \n+    if not factors:\n+        return factors\n+    \n+    # Group factors by their exponent\n+    from collections import defaultdict\n+    groups = defaultdict(list)\n+    \n+    for factor, exp in factors:\n+        groups[exp].append(factor)\n+    \n+    # Rebuild the factor list, combining factors with same exponent\n+    result = []\n+    for exp in sorted(groups.keys()):\n+        factor_list = groups[exp]\n+        if len(factor_list) == 1:\n+            # Single factor with this exponent\n+            result.append((factor_list[0], exp))\n+        else:\n+            # Multiple factors with same exponent - multiply them together\n+            from sympy import Mul, expand\n+            if hasattr(factor_list[0], 'as_expr'):\n+                # Factors are Poly objects\n+                combined = expand(Mul(*[f.as_expr() for f in factor_list]))\n+                # Convert back to Poly if needed\n+                if hasattr(factor_list[0], 'ring'):\n+                    try:\n+                        from sympy.polys.polytools import Poly\n+                        combined_poly = Poly(combined, *factor_list[0].gens)\n+                        result.append((combined_poly, exp))\n+                    except:\n+                        result.append((combined, exp))\n+                else:\n+                    result.append((combined, exp))\n+            else:\n+                # Factors are expressions\n+                combined = expand(Mul(*factor_list))\n+                result.append((combined, exp))\n+    \n+    return result\n+\n+\n def _symbolic_factor_list(expr, opt, method):\n     \"\"\"Helper function for :func:`_symbolic_factor`. \"\"\"\n     coeff, factors = S.One, []\n@@ -5997,6 +6047,10 @@ def _generic_factor_list(expr, gens, args, method):\n \n         fp = _sorted_factors(fp, method)\n         fq = _sorted_factors(fq, method)\n+        \n+        # Group factors with the same multiplicity for sqf method\n+        fp = _group_factors_by_multiplicity(fp, method)\n+        fq = _group_factors_by_multiplicity(fq, method)\n \n         if not opt.polys:\n             fp = [(f.as_expr(), k) for f, k in fp]\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "django__django-15695", "model_patch": "diff --git a/django/db/migrations/operations/models.py b/django/db/migrations/operations/models.py\nindex d17232e4ec..974c2e16ab 100644\n--- a/django/db/migrations/operations/models.py\n+++ b/django/db/migrations/operations/models.py\n@@ -967,7 +967,35 @@ class RenameIndex(IndexOperation):\n \n     def database_backwards(self, app_label, schema_editor, from_state, to_state):\n         if self.old_fields:\n-            # Backward operation with unnamed index is a no-op.\n+            # Handle backward operation for unnamed indexes\n+            # We need to rename from the current name (new_name) back to the original auto-generated name\n+            from_model = from_state.apps.get_model(app_label, self.model_name)\n+            to_model = to_state.apps.get_model(app_label, self.model_name)\n+            \n+            if not self.allow_migrate_model(schema_editor.connection.alias, from_model):\n+                return\n+            \n+            # Current index uses the new name\n+            current_index = models.Index(\n+                fields=self.old_fields,\n+                name=self.new_name,\n+            )\n+            \n+            # Generate the original auto-generated name using the same method as index_together\n+            # index_together uses _create_index_name with suffix=\"_idx\"\n+            columns = [to_model._meta.get_field(field).column for field in self.old_fields]\n+            original_name = schema_editor._create_index_name(\n+                to_model._meta.db_table, columns, suffix=\"_idx\"\n+            )\n+            \n+            # Create target index with original name\n+            target_index = models.Index(\n+                fields=self.old_fields,\n+                name=original_name,\n+            )\n+            \n+            # Rename from current name back to original name\n+            schema_editor.rename_index(from_model, current_index, target_index)\n             return\n \n         self.new_name_lower, self.old_name_lower = (\ndiff --git a/tests/migrations/test_operations.py b/tests/migrations/test_operations.py\nindex cfd28b1b39..7e8c927d91 100644\n--- a/tests/migrations/test_operations.py\n+++ b/tests/migrations/test_operations.py\n@@ -2984,9 +2984,14 @@ class OperationTests(OperationTestBase):\n         with connection.schema_editor() as editor:\n             operation.database_forwards(app_label, editor, project_state, new_state)\n         self.assertIndexNameExists(table_name, \"new_pony_test_idx\")\n-        # Reverse is a no-op.\n-        with connection.schema_editor() as editor, self.assertNumQueries(0):\n+        # Reverse operation - should restore the original auto-generated name\n+        with connection.schema_editor() as editor:\n             operation.database_backwards(app_label, editor, new_state, project_state)\n+        # The index should be restored to its original auto-generated name\n+        self.assertIndexNameNotExists(table_name, \"new_pony_test_idx\")\n+        # Re-apply renaming.\n+        with connection.schema_editor() as editor:\n+            operation.database_forwards(app_label, editor, project_state, new_state)\n         self.assertIndexNameExists(table_name, \"new_pony_test_idx\")\n         # Deconstruction.\n         definition = operation.deconstruct()\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "sympy__sympy-16792", "model_patch": "diff --git a/sympy/utilities/codegen.py b/sympy/utilities/codegen.py\nindex f0befb2bd7..5918f67108 100644\n--- a/sympy/utilities/codegen.py\n+++ b/sympy/utilities/codegen.py\n@@ -739,7 +739,14 @@ def routine(self, name, expr, argument_sequence=None, global_vars=None):\n                 try:\n                     new_args.append(name_arg_dict[symbol])\n                 except KeyError:\n-                    new_args.append(InputArgument(symbol))\n+                    # Check if this symbol is a MatrixSymbol and needs dimensions\n+                    if isinstance(symbol, MatrixSymbol):\n+                        dims = []\n+                        for dim in symbol.shape:\n+                            dims.append((S.Zero, dim - 1))\n+                        new_args.append(InputArgument(symbol, dimensions=dims))\n+                    else:\n+                        new_args.append(InputArgument(symbol))\n             arg_list = new_args\n \n         return Routine(name, arg_list, return_val, local_vars, global_vars)\ndiff --git a/sympy/utilities/tests/test_autowrap.py b/sympy/utilities/tests/test_autowrap.py\nindex 47fe933dc1..f11d5aaa7a 100644\n--- a/sympy/utilities/tests/test_autowrap.py\n+++ b/sympy/utilities/tests/test_autowrap.py\n@@ -467,3 +467,26 @@ def test_ufuncify_source_multioutput():\n }\n #endif\"\"\" % {'num': CodeWrapper._module_counter}\n     assert source == expected\n+\n+\n+def test_cython_wrapper_matrix_symbol_not_in_expression():\n+    \"\"\"Test that MatrixSymbol arguments not appearing in expression are handled correctly.\"\"\"\n+    from sympy import MatrixSymbol\n+    \n+    # Test case: MatrixSymbol argument that doesn't appear in the expression\n+    x = MatrixSymbol('x', 2, 1)\n+    routine = make_routine(\"test\", 1.0, argument_sequence=(x,))\n+    code_gen = CythonCodeWrapper(C99CodeGen())\n+    source = get_string(code_gen.dump_pyx, [routine])\n+    \n+    expected = (\n+        \"import numpy as np\\n\"\n+        \"cimport numpy as np\\n\"\n+        \"\\n\"\n+        \"cdef extern from 'file.h':\\n\"\n+        \"    double test(double *x)\\n\"\n+        \"\\n\"\n+        \"def test_c(np.ndarray[np.double_t, ndim=2] x):\\n\"\n+        \"\\n\"\n+        \"    return test(<double*> x.data)\")\n+    assert source == expected\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "django__django-14787", "model_patch": "diff --git a/django/utils/decorators.py b/django/utils/decorators.py\nindex 5c9a5d01c7..6820fb7db7 100644\n--- a/django/utils/decorators.py\n+++ b/django/utils/decorators.py\n@@ -38,6 +38,28 @@ def _multi_decorate(decorators, method):\n         # 'func'. Also, wrap method.__get__() in a function because new\n         # attributes can't be set on bound method objects, only on functions.\n         bound_method = partial(method.__get__(self, type(self)))\n+        # Copy function attributes from the original method to the partial\n+        # so that decorators using @wraps or accessing func.__name__ work correctly\n+        try:\n+            bound_method.__name__ = method.__name__\n+        except (AttributeError, TypeError):\n+            pass\n+        try:\n+            bound_method.__module__ = method.__module__\n+        except (AttributeError, TypeError):\n+            pass\n+        try:\n+            bound_method.__doc__ = method.__doc__\n+        except (AttributeError, TypeError):\n+            pass\n+        try:\n+            bound_method.__qualname__ = method.__qualname__\n+        except (AttributeError, TypeError):\n+            pass\n+        try:\n+            bound_method.__annotations__ = method.__annotations__\n+        except (AttributeError, TypeError):\n+            pass\n         for dec in decorators:\n             bound_method = dec(bound_method)\n         return bound_method(*args, **kwargs)\ndiff --git a/tests/decorators/tests.py b/tests/decorators/tests.py\nindex 46b01c1852..dd09e1f2fa 100644\n--- a/tests/decorators/tests.py\n+++ b/tests/decorators/tests.py\n@@ -425,6 +425,69 @@ class MethodDecoratorTests(SimpleTestCase):\n                 def __module__(cls):\n                     return \"tests\"\n \n+    def test_wrapper_assignments_preserved(self):\n+        \"\"\"\n+        @method_decorator preserves wrapper assignments for decorators using @wraps.\n+        \"\"\"\n+        def logger(func):\n+            @wraps(func)\n+            def inner(*args, **kwargs):\n+                # This should not raise AttributeError: 'functools.partial' object has no attribute '__name__'\n+                inner.logged_name = func.__name__\n+                inner.logged_module = func.__module__\n+                inner.logged_doc = func.__doc__\n+                return func(*args, **kwargs)\n+            return inner\n+\n+        class Test:\n+            @method_decorator(logger)\n+            def hello_world(self):\n+                \"\"\"A test method\"\"\"\n+                return \"hello\"\n+\n+        test_instance = Test()\n+        result = test_instance.hello_world()\n+        self.assertEqual(result, \"hello\")\n+        \n+        # Verify that the decorator was able to access function attributes\n+        # The inner function should have been called and set these attributes\n+        decorated_method = test_instance.hello_world\n+        # Note: We can't directly check inner.logged_name because the inner function\n+        # is called each time, but we can verify no AttributeError was raised\n+        \n+    def test_function_attributes_accessible(self):\n+        \"\"\"\n+        Function attributes like __name__, __module__, __doc__ are accessible\n+        in decorators applied via @method_decorator.\n+        \"\"\"\n+        captured_attrs = {}\n+        \n+        def attr_capturer(func):\n+            def inner(*args, **kwargs):\n+                captured_attrs['name'] = func.__name__\n+                captured_attrs['module'] = func.__module__\n+                captured_attrs['doc'] = func.__doc__\n+                captured_attrs['qualname'] = getattr(func, '__qualname__', None)\n+                return func(*args, **kwargs)\n+            return inner\n+\n+        class Test:\n+            @method_decorator(attr_capturer)\n+            def test_method(self):\n+                \"\"\"Test method docstring\"\"\"\n+                return \"result\"\n+\n+        test_instance = Test()\n+        result = test_instance.test_method()\n+        \n+        self.assertEqual(result, \"result\")\n+        self.assertEqual(captured_attrs['name'], 'test_method')\n+        self.assertEqual(captured_attrs['doc'], 'Test method docstring')\n+        self.assertIsNotNone(captured_attrs['module'])\n+        # qualname might not be available in all Python versions\n+        if captured_attrs['qualname'] is not None:\n+            self.assertIn('test_method', captured_attrs['qualname'])\n+\n \n class XFrameOptionsDecoratorsTests(TestCase):\n     \"\"\"\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "sympy__sympy-18199", "model_patch": "diff --git a/sympy/ntheory/residue_ntheory.py b/sympy/ntheory/residue_ntheory.py\nindex 9a3052d4c3..a957bccff6 100644\n--- a/sympy/ntheory/residue_ntheory.py\n+++ b/sympy/ntheory/residue_ntheory.py\n@@ -707,6 +707,11 @@ def _nthroot_mod1(s, q, p, all_roots):\n     .. [1] A. M. Johnston \"A Generalized qth Root Algorithm\"\n \n     \"\"\"\n+    # Handle special case when s ≡ 0 (mod p)\n+    # In this case, x = 0 is the only root since 0**q ≡ 0 (mod p)\n+    if s % p == 0:\n+        return [0] if all_roots else 0\n+    \n     g = primitive_root(p)\n     if not isprime(q):\n         r = _nthroot_mod2(s, q, p)\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "sympy__sympy-21379", "model_patch": "diff --git a/sympy/core/mod.py b/sympy/core/mod.py\nindex b4f3de2523..59f0324a6b 100644\n--- a/sympy/core/mod.py\n+++ b/sympy/core/mod.py\n@@ -166,7 +166,12 @@ def doit(p, q):\n         # XXX other possibilities?\n \n         # extract gcd; any further simplification should be done by the user\n-        G = gcd(p, q)\n+        # But skip GCD computation if expressions contain Piecewise, as it can't be handled by polynomial system\n+        from sympy.functions.elementary.piecewise import Piecewise\n+        if (hasattr(p, 'find') and p.find(Piecewise)) or (hasattr(q, 'find') and q.find(Piecewise)):\n+            G = S.One  # Skip GCD computation for Piecewise-containing expressions\n+        else:\n+            G = gcd(p, q)\n         if G != 1:\n             p, q = [\n                 gcd_terms(i/G, clear=False, fraction=False) for i in (p, q)]\ndiff --git a/sympy/core/tests/test_arit.py b/sympy/core/tests/test_arit.py\nindex 2dc6589f8c..abec60a06e 100644\n--- a/sympy/core/tests/test_arit.py\n+++ b/sympy/core/tests/test_arit.py\n@@ -1,7 +1,7 @@\n from sympy import (Basic, Symbol, sin, cos, atan, exp, sqrt, Rational,\n         Float, re, pi, sympify, Add, Mul, Pow, Mod, I, log, S, Max, symbols,\n         oo, zoo, Integer, sign, im, nan, Dummy, factorial, comp, floor, Poly,\n-        FiniteSet\n+        FiniteSet, sinh, Piecewise\n )\n from sympy.core.parameters import distribute\n from sympy.core.expr import unchanged\n@@ -1987,6 +1987,44 @@ def test_Mod_is_nonposneg():\n     assert Mod(k, n).is_nonnegative is None\n \n \n+def test_Mod_piecewise():\n+    \"\"\"Test that Mod.eval() handles Piecewise expressions correctly.\n+    \n+    This tests the fix for the issue where expressions containing\n+    exp(sinh(Piecewise(...)/z)) with real symbols would raise\n+    PolynomialError during substitution due to GCD computation\n+    on Piecewise expressions.\n+    \"\"\"\n+    from sympy.core.cache import clear_cache\n+    \n+    # Test case 1: Original issue - should not raise PolynomialError\n+    clear_cache()\n+    x, y, z = symbols('x y z', real=True)\n+    expr = exp(sinh(Piecewise((x, y > x), (y, True)) / z))\n+    \n+    # This should work without raising PolynomialError\n+    result = expr.subs({1: 1.0})\n+    assert result is not None\n+    \n+    # Test case 2: Direct Mod with Piecewise should work\n+    clear_cache()\n+    x, y = symbols('x y', real=True)\n+    pw = Piecewise((x, y > x), (y, True))\n+    \n+    # This should not raise PolynomialError\n+    mod_expr = Mod(pw, pi)\n+    assert mod_expr is not None\n+    \n+    # Test case 3: Ensure normal GCD behavior is preserved for non-Piecewise\n+    clear_cache()\n+    x = symbols('x')\n+    \n+    # Normal case without Piecewise should still use GCD\n+    mod_expr = Mod(6*x, 4*x)\n+    # Should be able to evaluate without error\n+    assert mod_expr is not None\n+\n+\n def test_issue_6001():\n     A = Symbol(\"A\", commutative=False)\n     eq = A + A**2\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "django__django-13658", "model_patch": "diff --git a/django/core/management/__init__.py b/django/core/management/__init__.py\nindex 1ba093e51f..e411e86348 100644\n--- a/django/core/management/__init__.py\n+++ b/django/core/management/__init__.py\n@@ -344,7 +344,7 @@ class ManagementUtility:\n         # Preprocess options to extract --settings and --pythonpath.\n         # These options could affect the commands that are available, so they\n         # must be processed early.\n-        parser = CommandParser(usage='%(prog)s subcommand [options] [args]', add_help=False, allow_abbrev=False)\n+        parser = CommandParser(prog=self.prog_name, usage='%(prog)s subcommand [options] [args]', add_help=False, allow_abbrev=False)\n         parser.add_argument('--settings')\n         parser.add_argument('--pythonpath')\n         parser.add_argument('args', nargs='*')  # catch-all\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "django__django-16255", "model_patch": "diff --git a/django/contrib/sitemaps/__init__.py b/django/contrib/sitemaps/__init__.py\nindex 27756d9d96..b40ad806ed 100644\n--- a/django/contrib/sitemaps/__init__.py\n+++ b/django/contrib/sitemaps/__init__.py\n@@ -168,7 +168,7 @@ class Sitemap:\n         if callable(self.lastmod):\n             try:\n                 return max([self.lastmod(item) for item in self.items()])\n-            except TypeError:\n+            except (TypeError, ValueError):\n                 return None\n         else:\n             return self.lastmod\ndiff --git a/tests/sitemaps_tests/test_http.py b/tests/sitemaps_tests/test_http.py\nindex 4a269b8737..d992dc65da 100644\n--- a/tests/sitemaps_tests/test_http.py\n+++ b/tests/sitemaps_tests/test_http.py\n@@ -450,6 +450,45 @@ class HTTPSitemapTests(SitemapTestsBase):\n         )\n         self.assertXMLEqual(response.content.decode(), expected_content)\n \n+    def test_empty_sitemap_with_callable_lastmod(self):\n+        \"\"\"\n+        Test that empty sitemaps with callable lastmod don't raise ValueError.\n+        Regression test for issue where max() on empty sequence raised ValueError.\n+        \"\"\"\n+        from datetime import datetime\n+        \n+        class EmptySitemapWithCallableLastmod(Sitemap):\n+            def items(self):\n+                return []\n+            \n+            def lastmod(self, item):\n+                return datetime(2023, 1, 1, 12, 0, 0)\n+        \n+        sitemap = EmptySitemapWithCallableLastmod()\n+        # This should not raise ValueError\n+        result = sitemap.get_latest_lastmod()\n+        self.assertIsNone(result)\n+\n+    def test_empty_sitemap_with_callable_lastmod_integration(self):\n+        \"\"\"\n+        Integration test for empty sitemap with callable lastmod via HTTP.\n+        \"\"\"\n+        # Test index view - should not raise ValueError\n+        index_response = self.client.get(\"/empty-callable-lastmod/index.xml\")\n+        self.assertEqual(index_response.status_code, 200)\n+        self.assertNotContains(index_response, \"<lastmod>\")\n+        \n+        # Test sitemap view - should not raise ValueError\n+        sitemap_response = self.client.get(\"/empty-callable-lastmod/sitemap.xml\")\n+        self.assertEqual(sitemap_response.status_code, 200)\n+        expected_content = (\n+            '<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n'\n+            '<urlset xmlns=\"http://www.sitemaps.org/schemas/sitemap/0.9\" '\n+            'xmlns:xhtml=\"http://www.w3.org/1999/xhtml\">\\n\\n'\n+            \"</urlset>\"\n+        )\n+        self.assertXMLEqual(sitemap_response.content.decode(), expected_content)\n+\n     def test_callable_sitemod_partial(self):\n         \"\"\"\n         Not all items have `lastmod`. Therefore the `Last-Modified` header\ndiff --git a/tests/sitemaps_tests/urls/http.py b/tests/sitemaps_tests/urls/http.py\nindex 9a468de476..530c8b8f24 100644\n--- a/tests/sitemaps_tests/urls/http.py\n+++ b/tests/sitemaps_tests/urls/http.py\n@@ -134,6 +134,19 @@ class GetLatestLastmodSiteMap(SimpleSitemap):\n         return datetime(2013, 3, 13, 10, 0, 0)\n \n \n+class EmptySitemapWithCallableLastmod(Sitemap):\n+    \"\"\"Empty sitemap with callable lastmod - regression test for ValueError.\"\"\"\n+    changefreq = \"never\"\n+    priority = 0.5\n+    location = \"/location/\"\n+\n+    def items(self):\n+        return []\n+\n+    def lastmod(self, item):\n+        return datetime(2013, 3, 13, 10, 0, 0)\n+\n+\n def testmodelview(request, id):\n     return HttpResponse()\n \n@@ -233,6 +246,10 @@ callable_lastmod_full_sitemap = {\n     \"callable-lastmod\": CallableLastmodFullSitemap,\n }\n \n+empty_sitemap_with_callable_lastmod = {\n+    \"empty-callable-lastmod\": EmptySitemapWithCallableLastmod,\n+}\n+\n urlpatterns = [\n     path(\"simple/index.xml\", views.index, {\"sitemaps\": simple_sitemaps}),\n     path(\"simple-paged/index.xml\", views.index, {\"sitemaps\": simple_sitemaps_paged}),\n@@ -423,6 +440,18 @@ urlpatterns = [\n         {\"sitemaps\": generic_sitemaps_lastmod},\n         name=\"django.contrib.sitemaps.views.index\",\n     ),\n+    path(\n+        \"empty-callable-lastmod/index.xml\",\n+        views.index,\n+        {\"sitemaps\": empty_sitemap_with_callable_lastmod},\n+        name=\"django.contrib.sitemaps.views.index\",\n+    ),\n+    path(\n+        \"empty-callable-lastmod/sitemap.xml\",\n+        views.sitemap,\n+        {\"sitemaps\": empty_sitemap_with_callable_lastmod},\n+        name=\"django.contrib.sitemaps.views.sitemap\",\n+    ),\n ]\n \n urlpatterns += i18n_patterns(\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "matplotlib__matplotlib-23476", "model_patch": "diff --git a/lib/matplotlib/backend_bases.py b/lib/matplotlib/backend_bases.py\nindex 9ae2982c62..0bd55dc4d0 100644\n--- a/lib/matplotlib/backend_bases.py\n+++ b/lib/matplotlib/backend_bases.py\n@@ -1652,8 +1652,9 @@ class FigureCanvasBase:\n         self.mouse_grabber = None  # the Axes currently grabbing mouse\n         self.toolbar = None  # NavigationToolbar2 will set me\n         self._is_idle_drawing = False\n-        # We don't want to scale up the figure DPI more than once.\n-        figure._original_dpi = figure.dpi\n+# We don't want to scale up the figure DPI more than once.\n+        if not hasattr(figure, '_original_dpi'):\n+            figure._original_dpi = figure.dpi\n         self._device_pixel_ratio = 1\n         super().__init__()  # Typically the GUI widget init (if any).\n \ndiff --git a/lib/matplotlib/tests/test_pickle.py b/lib/matplotlib/tests/test_pickle.py\nindex 0d0a5e5977..0cd2d9459e 100644\n--- a/lib/matplotlib/tests/test_pickle.py\n+++ b/lib/matplotlib/tests/test_pickle.py\n@@ -237,3 +237,51 @@ def test_dynamic_norm():\n def test_vertexselector():\n     line, = plt.plot([0, 1], picker=True)\n     pickle.loads(pickle.dumps(VertexSelector(line)))\n+\n+\n+def test_dpi_preservation_on_unpickle():\n+    \"\"\"\n+    Test that figure DPI is preserved across pickle/unpickle cycles.\n+    \n+    This test ensures that the _original_dpi attribute is not corrupted\n+    during canvas recreation, which was causing DPI doubling on MacOSX\n+    backend with device pixel ratio scaling.\n+    \n+    See: https://github.com/matplotlib/matplotlib/issues/23476\n+    \"\"\"\n+    # Create a figure with specific DPI\n+    fig = plt.figure(dpi=100)\n+    original_dpi = fig.dpi\n+    \n+    # Ensure _original_dpi is set correctly\n+    assert hasattr(fig, '_original_dpi')\n+    assert fig._original_dpi == original_dpi\n+    \n+    # Simulate device pixel ratio scaling (like on Retina displays)\n+    device_pixel_ratio = 2.0\n+    scaled_dpi = device_pixel_ratio * fig._original_dpi\n+    fig._set_dpi(scaled_dpi, forward=False)\n+    \n+    # Verify scaling worked but _original_dpi is preserved\n+    assert fig.dpi == scaled_dpi\n+    assert fig._original_dpi == original_dpi\n+    \n+    # Test multiple pickle/unpickle cycles\n+    for i in range(3):\n+        # Pickle and unpickle\n+        buffer = BytesIO()\n+        pickle.dump(fig, buffer, pickle.HIGHEST_PROTOCOL)\n+        buffer.seek(0)\n+        fig = pickle.load(buffer)\n+        \n+        # Verify DPI and _original_dpi are preserved\n+        assert fig.dpi == scaled_dpi, f\"DPI changed in cycle {i+1}\"\n+        assert hasattr(fig, '_original_dpi'), f\"_original_dpi missing in cycle {i+1}\"\n+        assert fig._original_dpi == original_dpi, f\"_original_dpi corrupted in cycle {i+1}\"\n+        \n+        # Simulate re-scaling (like moving window between displays)\n+        new_scaled_dpi = device_pixel_ratio * fig._original_dpi\n+        fig._set_dpi(new_scaled_dpi, forward=False)\n+        \n+        # Verify DPI didn't double\n+        assert fig.dpi == scaled_dpi, f\"DPI doubled in cycle {i+1}\"\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "sympy__sympy-18189", "model_patch": "diff --git a/sympy/solvers/diophantine.py b/sympy/solvers/diophantine.py\nindex 6092e35dab..b43f5c1dcf 100644\n--- a/sympy/solvers/diophantine.py\n+++ b/sympy/solvers/diophantine.py\n@@ -182,7 +182,7 @@ def diophantine(eq, param=symbols(\"t\", integer=True), syms=None,\n             if syms != var:\n                 dict_sym_index = dict(zip(syms, range(len(syms))))\n                 return {tuple([t[dict_sym_index[i]] for i in var])\n-                            for t in diophantine(eq, param)}\n+                            for t in diophantine(eq, param, permute=permute)}\n         n, d = eq.as_numer_denom()\n         if n.is_number:\n             return set()\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "sympy__sympy-17139", "model_patch": "diff --git a/sympy/simplify/fu.py b/sympy/simplify/fu.py\nindex ad1130ef96..7da9d48037 100644\n--- a/sympy/simplify/fu.py\n+++ b/sympy/simplify/fu.py\n@@ -501,6 +501,11 @@ def _f(rv):\n         if not (rv.is_Pow and rv.base.func == f):\n             return rv\n \n+        # Skip transformations for non-real exponents (e.g., complex numbers)\n+        # since trigonometric transformation rules are designed for real exponents\n+        if rv.exp.is_real is False:\n+            return rv\n+\n         if (rv.exp < 0) == True:\n             return rv\n         if (rv.exp > max) == True:\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "django__django-14155", "model_patch": "diff --git a/django/urls/resolvers.py b/django/urls/resolvers.py\nindex 9b00e24509..8e053d7795 100644\n--- a/django/urls/resolvers.py\n+++ b/django/urls/resolvers.py\n@@ -46,8 +46,23 @@ class ResolverMatch:\n         self.namespace = ':'.join(self.namespaces)\n \n         if not hasattr(func, '__name__'):\n-            # A class-based view\n-            self._func_path = func.__class__.__module__ + '.' + func.__class__.__name__\n+            # Check if it's a functools.partial object\n+            if hasattr(func, 'func') and hasattr(func.func, '__name__'):\n+                # functools.partial - show the underlying function with partial args\n+                underlying_func = func.func\n+                base_path = underlying_func.__module__ + '.' + underlying_func.__name__\n+                \n+                # Build a descriptive representation including partial arguments\n+                parts = [base_path]\n+                if func.args:\n+                    parts.extend(repr(arg) for arg in func.args)\n+                if func.keywords:\n+                    parts.extend(f'{k}={repr(v)}' for k, v in func.keywords.items())\n+                \n+                self._func_path = f\"functools.partial({', '.join(parts)})\"\n+            else:\n+                # A class-based view or other callable without __name__\n+                self._func_path = func.__class__.__module__ + '.' + func.__class__.__name__\n         else:\n             # A function-based view\n             self._func_path = func.__module__ + '.' + func.__name__\ndiff --git a/tests/urlpatterns_reverse/tests.py b/tests/urlpatterns_reverse/tests.py\nindex 09028be795..9a8497cded 100644\n--- a/tests/urlpatterns_reverse/tests.py\n+++ b/tests/urlpatterns_reverse/tests.py\n@@ -1145,6 +1145,41 @@ class ResolverMatchTests(SimpleTestCase):\n             \"namespaces=[], route=^no_kwargs/([0-9]+)/([0-9]+)/$)\",\n         )\n \n+    def test_repr_functools_partial(self):\n+        \"\"\"Test ResolverMatch.__repr__() with functools.partial functions.\"\"\"\n+        import functools\n+        \n+        def sample_view(request, arg1, arg2='default'):\n+            return f\"View called with arg1={arg1}, arg2={arg2}\"\n+        \n+        # Test simple partial with kwargs\n+        partial_view = functools.partial(sample_view, arg2='partial_default')\n+        match = ResolverMatch(partial_view, ('test',), {}, 'test-partial-view')\n+        self.assertIn('functools.partial(', repr(match))\n+        self.assertIn('sample_view', repr(match))\n+        self.assertIn(\"arg2='partial_default'\", repr(match))\n+        \n+        # Test partial with positional args\n+        partial_view = functools.partial(sample_view, 'fixed_arg1')\n+        match = ResolverMatch(partial_view, (), {}, 'test-partial-args')\n+        self.assertIn('functools.partial(', repr(match))\n+        self.assertIn('sample_view', repr(match))\n+        self.assertIn(\"'fixed_arg1'\", repr(match))\n+        \n+        # Test partial with both args and kwargs\n+        partial_view = functools.partial(sample_view, 'fixed_arg1', arg2='partial_default')\n+        match = ResolverMatch(partial_view, (), {}, 'test-partial-both')\n+        self.assertIn('functools.partial(', repr(match))\n+        self.assertIn('sample_view', repr(match))\n+        self.assertIn(\"'fixed_arg1'\", repr(match))\n+        self.assertIn(\"arg2='partial_default'\", repr(match))\n+        \n+        # Test empty partial\n+        partial_view = functools.partial(sample_view)\n+        match = ResolverMatch(partial_view, ('arg1',), {}, 'test-empty-partial')\n+        expected_func_path = f'functools.partial({sample_view.__module__}.{sample_view.__name__})'\n+        self.assertEqual(match._func_path, expected_func_path)\n+\n \n @override_settings(ROOT_URLCONF='urlpatterns_reverse.erroneous_urls')\n class ErroneousViewTests(SimpleTestCase):\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "django__django-10914", "model_patch": "diff --git a/django/conf/global_settings.py b/django/conf/global_settings.py\nindex acee9887d2..bdeec80610 100644\n--- a/django/conf/global_settings.py\n+++ b/django/conf/global_settings.py\n@@ -304,7 +304,7 @@ FILE_UPLOAD_TEMP_DIR = None\n \n # The numeric mode to set newly-uploaded files to. The value should be a mode\n # you'd pass directly to os.chmod; see https://docs.python.org/library/os.html#files-and-directories.\n-FILE_UPLOAD_PERMISSIONS = None\n+FILE_UPLOAD_PERMISSIONS = 0o644\n \n # The numeric mode to assign to newly-created directories, when uploading files.\n # The value should be a mode as you'd pass to os.chmod;\ndiff --git a/docs/ref/settings.txt b/docs/ref/settings.txt\nindex 46e99af993..eba5bd2e31 100644\n--- a/docs/ref/settings.txt\n+++ b/docs/ref/settings.txt\n@@ -1484,7 +1484,7 @@ This value mirrors the functionality and caveats of the\n ``FILE_UPLOAD_PERMISSIONS``\n ---------------------------\n \n-Default: ``None``\n+Default: ``0o644``\n \n The numeric mode (i.e. ``0o644``) to set newly uploaded files to. For\n more information about what these modes mean, see the documentation for\ndiff --git a/tests/file_storage/tests.py b/tests/file_storage/tests.py\nindex 434869554c..429a466d89 100644\n--- a/tests/file_storage/tests.py\n+++ b/tests/file_storage/tests.py\n@@ -897,6 +897,8 @@ class FileStoragePermissions(unittest.TestCase):\n         self.storage = FileSystemStorage(self.storage_dir)\n         fname = self.storage.save(\"some_file\", ContentFile(\"data\"))\n         mode = os.stat(self.storage.path(fname))[0] & 0o777\n+        # When FILE_UPLOAD_PERMISSIONS=None, should still use umask-based permissions\n+        # for backward compatibility in this specific case\n         self.assertEqual(mode, 0o666 & ~self.umask)\n \n     @override_settings(FILE_UPLOAD_DIRECTORY_PERMISSIONS=0o765)\n@@ -913,6 +915,34 @@ class FileStoragePermissions(unittest.TestCase):\n         dir_mode = os.stat(os.path.dirname(self.storage.path(name)))[0] & 0o777\n         self.assertEqual(dir_mode, 0o777 & ~self.umask)\n \n+    def test_file_upload_consistent_permissions(self):\n+        \"\"\"\n+        Test that small and large files get consistent permissions with the new default.\n+        \"\"\"\n+        from django.core.files.uploadedfile import TemporaryUploadedFile\n+        \n+        self.storage = FileSystemStorage(self.storage_dir)\n+        \n+        # Test small file (ContentFile)\n+        small_file = ContentFile(\"small content\")\n+        small_name = self.storage.save(\"small_file.txt\", small_file)\n+        small_mode = os.stat(self.storage.path(small_name))[0] & 0o777\n+        \n+        # Test large file (TemporaryUploadedFile)\n+        large_content = b\"x\" * 3000  # Large enough to trigger temp file behavior\n+        temp_file = TemporaryUploadedFile(\"large_file.txt\", \"text/plain\", len(large_content), \"utf-8\")\n+        temp_file.write(large_content)\n+        temp_file.seek(0)\n+        \n+        large_name = self.storage.save(\"large_file.txt\", temp_file)\n+        large_mode = os.stat(self.storage.path(large_name))[0] & 0o777\n+        \n+        # Both should have the same permissions (0o644 with new default)\n+        self.assertEqual(small_mode, large_mode)\n+        self.assertEqual(small_mode, 0o644)\n+        \n+        temp_file.close()\n+\n \n class FileStoragePathParsing(SimpleTestCase):\n     def setUp(self):\ndiff --git a/tests/test_utils/tests.py b/tests/test_utils/tests.py\nindex a1a113a26e..6a910427fa 100644\n--- a/tests/test_utils/tests.py\n+++ b/tests/test_utils/tests.py\n@@ -1099,7 +1099,7 @@ class OverrideSettingsTests(SimpleTestCase):\n         the file_permissions_mode attribute of\n         django.core.files.storage.default_storage.\n         \"\"\"\n-        self.assertIsNone(default_storage.file_permissions_mode)\n+        self.assertEqual(default_storage.file_permissions_mode, 0o644)  # New default\n         with self.settings(FILE_UPLOAD_PERMISSIONS=0o777):\n             self.assertEqual(default_storage.file_permissions_mode, 0o777)\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "sympy__sympy-17630", "model_patch": "diff --git a/sympy/matrices/expressions/blockmatrix.py b/sympy/matrices/expressions/blockmatrix.py\nindex 95302a05ca..0b852100c3 100644\n--- a/sympy/matrices/expressions/blockmatrix.py\n+++ b/sympy/matrices/expressions/blockmatrix.py\n@@ -164,7 +164,45 @@ def structurally_equal(self, other):\n     def _blockmul(self, other):\n         if (isinstance(other, BlockMatrix) and\n                 self.colblocksizes == other.rowblocksizes):\n-            return BlockMatrix(self.blocks*other.blocks)\n+            # Perform element-wise block multiplication to preserve ZeroMatrix objects\n+            from sympy.matrices import Matrix\n+            result_blocks = []\n+            for i in range(self.blockshape[0]):\n+                row = []\n+                for j in range(other.blockshape[1]):\n+                    # Compute the (i,j) block of the result\n+                    block_sum = None\n+                    for k in range(self.blockshape[1]):\n+                        left_block = self.blocks[i, k]\n+                        right_block = other.blocks[k, j]\n+                        \n+                        # Handle ZeroMatrix cases to preserve block structure\n+                        if left_block.is_ZeroMatrix or right_block.is_ZeroMatrix:\n+                            # Result is a ZeroMatrix with appropriate dimensions\n+                            product = ZeroMatrix(left_block.rows, right_block.cols)\n+                        else:\n+                            product = left_block * right_block\n+                        \n+                        if block_sum is None:\n+                            block_sum = product\n+                        else:\n+                            # Handle addition of ZeroMatrix blocks\n+                            if block_sum.is_ZeroMatrix:\n+                                block_sum = product\n+                            elif product.is_ZeroMatrix:\n+                                # block_sum stays the same\n+                                pass\n+                            else:\n+                                block_sum = block_sum + product\n+                    \n+                    # If block_sum is still None, it means all products were zero\n+                    if block_sum is None:\n+                        block_sum = ZeroMatrix(self.blocks[i, 0].rows, other.blocks[0, j].cols)\n+                    \n+                    row.append(block_sum)\n+                result_blocks.append(row)\n+            \n+            return BlockMatrix(result_blocks)\n \n         return self * other\n \ndiff --git a/sympy/matrices/expressions/tests/test_blockmatrix.py b/sympy/matrices/expressions/tests/test_blockmatrix.py\nindex 1e1033affc..84b0e76843 100644\n--- a/sympy/matrices/expressions/tests/test_blockmatrix.py\n+++ b/sympy/matrices/expressions/tests/test_blockmatrix.py\n@@ -222,3 +222,47 @@ def test_block_collapse_type():\n     assert block_collapse(Transpose(bm1)).__class__ == BlockDiagMatrix\n     assert bc_transpose(Transpose(bm1)).__class__ == BlockDiagMatrix\n     assert bc_inverse(Inverse(bm1)).__class__ == BlockDiagMatrix\n+\n+def test_zeromatrix_blockmatrix_multiplication():\n+    \"\"\"Test that ZeroMatrix blocks are preserved during BlockMatrix multiplication.\n+    \n+    This addresses the issue where ZeroMatrix objects were converted to Zero objects\n+    during block multiplication, causing AttributeError when accessing colblocksizes.\n+    \"\"\"\n+    from sympy.matrices.expressions.matexpr import ZeroMatrix\n+    \n+    # Test case from the original issue\n+    a = MatrixSymbol(\"a\", 2, 2)\n+    z = ZeroMatrix(2, 2)\n+    b = BlockMatrix([[a, z], [z, z]])\n+    \n+    # Test single multiplication\n+    result1 = b._blockmul(b)\n+    assert isinstance(result1, BlockMatrix)\n+    assert isinstance(result1.blocks[0, 1], ZeroMatrix)\n+    assert isinstance(result1.blocks[1, 0], ZeroMatrix)\n+    assert isinstance(result1.blocks[1, 1], ZeroMatrix)\n+    assert result1.blocks[0, 0] == a**2\n+    \n+    # Test double multiplication - this was failing before the fix\n+    result2 = b._blockmul(b)._blockmul(b)\n+    assert isinstance(result2, BlockMatrix)\n+    assert isinstance(result2.blocks[0, 1], ZeroMatrix)\n+    assert isinstance(result2.blocks[1, 0], ZeroMatrix)\n+    assert isinstance(result2.blocks[1, 1], ZeroMatrix)\n+    assert result2.blocks[0, 0] == a**3\n+    \n+    # Test with block_collapse\n+    result3 = block_collapse(b * b)\n+    assert isinstance(result3, BlockMatrix)\n+    assert isinstance(result3.blocks[0, 1], ZeroMatrix)\n+    \n+    result4 = block_collapse(b * b * b)\n+    assert isinstance(result4, BlockMatrix)\n+    assert isinstance(result4.blocks[0, 1], ZeroMatrix)\n+    \n+    # Test colblocksizes access - this was causing AttributeError before\n+    assert result1.colblocksizes == [2, 2]\n+    assert result2.colblocksizes == [2, 2]\n+    assert result3.colblocksizes == [2, 2]\n+    assert result4.colblocksizes == [2, 2]\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "django__django-11179", "model_patch": "diff --git a/django/db/models/deletion.py b/django/db/models/deletion.py\nindex 92fe4affb9..3a462f1c4c 100644\n--- a/django/db/models/deletion.py\n+++ b/django/db/models/deletion.py\n@@ -277,6 +277,7 @@ class Collector:\n             if self.can_fast_delete(instance):\n                 with transaction.mark_for_rollback_on_error():\n                     count = sql.DeleteQuery(model).delete_batch([instance.pk], self.using)\n+                setattr(instance, model._meta.pk.attname, None)\n                 return count, {model._meta.label: count}\n \n         with transaction.atomic(using=self.using, savepoint=False):\ndiff --git a/tests/delete/tests.py b/tests/delete/tests.py\nindex 55eeb226ea..4893b5611f 100644\n--- a/tests/delete/tests.py\n+++ b/tests/delete/tests.py\n@@ -208,6 +208,48 @@ class DeletionTests(TestCase):\n \n         models.signals.pre_delete.disconnect(pre_delete)\n \n+    def test_delete_clears_pk_for_single_instance(self):\n+        \"\"\"\n+        Test that delete() clears the primary key for single instances\n+        without dependencies (fast delete path).\n+        \"\"\"\n+        # Test simple model without dependencies\n+        r = R.objects.create()\n+        pk_before = r.pk\n+        self.assertIsNotNone(pk_before)\n+        \n+        r.delete()\n+        \n+        # PK should be cleared after delete\n+        self.assertIsNone(r.pk)\n+        \n+        # Verify object was actually deleted from database\n+        self.assertFalse(R.objects.filter(pk=pk_before).exists())\n+\n+    def test_delete_clears_pk_for_multiple_instances(self):\n+        \"\"\"\n+        Test that delete() clears the primary key for multiple instances\n+        (regular delete path).\n+        \"\"\"\n+        # Create multiple instances\n+        r1 = R.objects.create()\n+        r2 = R.objects.create()\n+        pk1_before = r1.pk\n+        pk2_before = r2.pk\n+        \n+        # Delete using collector (simulates multiple instance deletion)\n+        from django.db.models.deletion import Collector\n+        collector = Collector(using='default')\n+        collector.collect([r1, r2])\n+        collector.delete()\n+        \n+        # PKs should be cleared after delete\n+        self.assertIsNone(r1.pk)\n+        self.assertIsNone(r2.pk)\n+        \n+        # Verify objects were actually deleted from database\n+        self.assertFalse(R.objects.filter(pk__in=[pk1_before, pk2_before]).exists())\n+\n     def test_deletion_order(self):\n         pre_delete_order = []\n         post_delete_order = []\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "sympy__sympy-15345", "model_patch": "diff --git a/sympy/printing/mathematica.py b/sympy/printing/mathematica.py\nindex ea7e3a2d94..806ac3e994 100644\n--- a/sympy/printing/mathematica.py\n+++ b/sympy/printing/mathematica.py\n@@ -116,6 +116,12 @@ def _print_Derivative(self, expr):\n         dvars = [i[0] if i[1] == 1 else i for i in expr.variable_count]\n         return \"Hold[D[\" + ', '.join(self.doprint(a) for a in [dexpr] + dvars) + \"]]\"\n \n+    def _print_Max(self, expr):\n+        return \"Max[%s]\" % self.stringify(expr.args, \", \")\n+\n+    def _print_Min(self, expr):\n+        return \"Min[%s]\" % self.stringify(expr.args, \", \")\n+\n \n def mathematica_code(expr, **settings):\n     r\"\"\"Converts an expr to a string of the Wolfram Mathematica code\ndiff --git a/sympy/printing/tests/test_mathematica.py b/sympy/printing/tests/test_mathematica.py\nindex dd636d0623..cea1eae16e 100644\n--- a/sympy/printing/tests/test_mathematica.py\n+++ b/sympy/printing/tests/test_mathematica.py\n@@ -2,7 +2,7 @@\n                         Rational, Integer, Tuple, Derivative)\n from sympy.integrals import Integral\n from sympy.concrete import Sum\n-from sympy.functions import exp, sin, cos, conjugate\n+from sympy.functions import exp, sin, cos, conjugate, Max, Min\n \n from sympy import mathematica_code as mcode\n \n@@ -90,3 +90,31 @@ def test_Sum():\n                      (y, -oo, oo))) == \\\n         \"Hold[Sum[Exp[-x^2 - y^2], {x, -Infinity, Infinity}, \" \\\n         \"{y, -Infinity, Infinity}]]\"\n+\n+\n+def test_Max():\n+    # Test basic Max functionality\n+    assert mcode(Max(x, 2)) == \"Max[2, x]\"\n+    assert mcode(Max(x, y)) == \"Max[x, y]\"\n+    assert mcode(Max(x, y, z)) == \"Max[x, y, z]\"\n+    \n+    # Test with numbers - when all numeric, Max evaluates to the maximum value\n+    assert mcode(Max(1, 2, 3)) == \"3\"  # Max simplifies to single value\n+    assert mcode(Max(x, 1, 2)) == \"Max[2, x]\"  # Max keeps the larger number and x\n+    \n+    # Test nested expressions\n+    assert mcode(Max(x + 1, y - 1)) == \"Max[x + 1, y - 1]\"\n+\n+\n+def test_Min():\n+    # Test basic Min functionality  \n+    assert mcode(Min(x, 2)) == \"Min[2, x]\"\n+    assert mcode(Min(x, y)) == \"Min[x, y]\"\n+    assert mcode(Min(x, y, z)) == \"Min[x, y, z]\"\n+    \n+    # Test with numbers - when all numeric, Min evaluates to the minimum value\n+    assert mcode(Min(1, 2, 3)) == \"1\"  # Min simplifies to single value\n+    assert mcode(Min(x, 1, 2)) == \"Min[1, x]\"  # Min keeps the smaller number and x\n+    \n+    # Test nested expressions\n+    assert mcode(Min(x + 1, y - 1)) == \"Min[x + 1, y - 1]\"\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "sympy__sympy-21612", "model_patch": "diff --git a/sympy/parsing/latex/_antlr/latexlexer.py b/sympy/parsing/latex/_antlr/latexlexer.py\nindex 29eb4b462a..c24599906e 100644\n--- a/sympy/parsing/latex/_antlr/latexlexer.py\n+++ b/sympy/parsing/latex/_antlr/latexlexer.py\n@@ -10,417 +10,354 @@\n # Generated with antlr4\n #    antlr4 is licensed under the BSD-3-Clause License\n #    https://github.com/antlr/antlr4/blob/master/LICENSE.txt\n-from __future__ import print_function\n+# encoding: utf-8\n+\n+# *** GENERATED BY `setup.py antlr`, DO NOT EDIT BY HAND ***\n+#\n+# Generated from ../LaTeX.g4, derived from latex2sympy\n+#     latex2sympy is licensed under the MIT license\n+#     https://github.com/augustt198/latex2sympy/blob/master/LICENSE.txt\n+#\n+# Generated with antlr4\n+#    antlr4 is licensed under the BSD-3-Clause License\n+#    https://github.com/antlr/antlr4/blob/master/LICENSE.txt\n from antlr4 import *\n from io import StringIO\n import sys\n-\n+if sys.version_info[1] > 5:\n+    from typing import TextIO\n+else:\n+    from typing.io import TextIO\n \n \n def serializedATN():\n-    with StringIO() as buf:\n-        buf.write(u\"\\3\\u608b\\ua72a\\u8133\\ub9ed\\u417c\\u3be7\\u7786\\u5964\\2\")\n-        buf.write(u\"Z\\u0390\\b\\1\\4\\2\\t\\2\\4\\3\\t\\3\\4\\4\\t\\4\\4\\5\\t\\5\\4\\6\\t\\6\\4\")\n-        buf.write(u\"\\7\\t\\7\\4\\b\\t\\b\\4\\t\\t\\t\\4\\n\\t\\n\\4\\13\\t\\13\\4\\f\\t\\f\\4\\r\")\n-        buf.write(u\"\\t\\r\\4\\16\\t\\16\\4\\17\\t\\17\\4\\20\\t\\20\\4\\21\\t\\21\\4\\22\\t\\22\")\n-        buf.write(u\"\\4\\23\\t\\23\\4\\24\\t\\24\\4\\25\\t\\25\\4\\26\\t\\26\\4\\27\\t\\27\\4\")\n-        buf.write(u\"\\30\\t\\30\\4\\31\\t\\31\\4\\32\\t\\32\\4\\33\\t\\33\\4\\34\\t\\34\\4\\35\")\n-        buf.write(u\"\\t\\35\\4\\36\\t\\36\\4\\37\\t\\37\\4 \\t \\4!\\t!\\4\\\"\\t\\\"\\4#\\t#\\4\")\n-        buf.write(u\"$\\t$\\4%\\t%\\4&\\t&\\4\\'\\t\\'\\4(\\t(\\4)\\t)\\4*\\t*\\4+\\t+\\4,\\t\")\n-        buf.write(u\",\\4-\\t-\\4.\\t.\\4/\\t/\\4\\60\\t\\60\\4\\61\\t\\61\\4\\62\\t\\62\\4\\63\")\n-        buf.write(u\"\\t\\63\\4\\64\\t\\64\\4\\65\\t\\65\\4\\66\\t\\66\\4\\67\\t\\67\\48\\t8\\4\")\n-        buf.write(u\"9\\t9\\4:\\t:\\4;\\t;\\4<\\t<\\4=\\t=\\4>\\t>\\4?\\t?\\4@\\t@\\4A\\tA\")\n-        buf.write(u\"\\4B\\tB\\4C\\tC\\4D\\tD\\4E\\tE\\4F\\tF\\4G\\tG\\4H\\tH\\4I\\tI\\4J\\t\")\n-        buf.write(u\"J\\4K\\tK\\4L\\tL\\4M\\tM\\4N\\tN\\4O\\tO\\4P\\tP\\4Q\\tQ\\4R\\tR\\4S\")\n-        buf.write(u\"\\tS\\4T\\tT\\4U\\tU\\4V\\tV\\4W\\tW\\4X\\tX\\4Y\\tY\\4Z\\tZ\\4[\\t[\\3\")\n-        buf.write(u\"\\2\\3\\2\\3\\3\\6\\3\\u00bb\\n\\3\\r\\3\\16\\3\\u00bc\\3\\3\\3\\3\\3\\4\\3\")\n-        buf.write(u\"\\4\\3\\4\\3\\4\\3\\4\\3\\4\\3\\4\\3\\4\\3\\4\\3\\4\\3\\4\\3\\4\\5\\4\\u00cd\")\n-        buf.write(u\"\\n\\4\\3\\4\\3\\4\\3\\5\\3\\5\\3\\5\\3\\5\\3\\5\\3\\5\\3\\5\\3\\5\\3\\5\\3\\5\")\n-        buf.write(u\"\\3\\5\\5\\5\\u00dc\\n\\5\\3\\5\\3\\5\\3\\6\\3\\6\\3\\6\\3\\6\\3\\6\\3\\6\\3\")\n-        buf.write(u\"\\6\\3\\6\\3\\6\\3\\6\\3\\6\\3\\6\\3\\6\\5\\6\\u00ed\\n\\6\\3\\6\\3\\6\\3\\7\")\n-        buf.write(u\"\\3\\7\\3\\7\\3\\7\\3\\7\\3\\7\\3\\7\\3\\7\\3\\b\\3\\b\\3\\b\\3\\b\\3\\b\\3\\b\")\n-        buf.write(u\"\\3\\b\\3\\b\\3\\b\\3\\t\\3\\t\\3\\t\\3\\t\\3\\t\\3\\t\\3\\t\\3\\t\\3\\t\\3\\t\")\n-        buf.write(u\"\\3\\t\\3\\t\\3\\t\\3\\t\\3\\t\\5\\t\\u0111\\n\\t\\3\\t\\3\\t\\3\\n\\3\\n\\3\")\n-        buf.write(u\"\\n\\3\\n\\3\\n\\3\\n\\3\\n\\3\\n\\3\\n\\3\\n\\3\\n\\3\\n\\3\\n\\3\\n\\3\\n\\3\")\n-        buf.write(u\"\\13\\3\\13\\3\\13\\3\\13\\3\\13\\3\\13\\3\\13\\3\\13\\3\\13\\3\\13\\3\\13\")\n-        buf.write(u\"\\3\\13\\3\\13\\3\\13\\3\\13\\3\\13\\3\\13\\3\\f\\3\\f\\3\\f\\3\\f\\3\\f\\3\")\n-        buf.write(u\"\\f\\3\\f\\3\\f\\3\\r\\3\\r\\3\\r\\3\\r\\3\\r\\3\\r\\3\\r\\3\\r\\3\\r\\3\\16\\3\")\n-        buf.write(u\"\\16\\3\\16\\3\\16\\3\\16\\3\\16\\3\\16\\3\\16\\3\\16\\3\\16\\3\\16\\3\\16\")\n-        buf.write(u\"\\3\\16\\3\\16\\3\\16\\3\\16\\3\\16\\3\\16\\3\\16\\3\\16\\3\\16\\3\\16\\3\")\n-        buf.write(u\"\\16\\3\\16\\3\\16\\3\\16\\3\\16\\3\\16\\3\\16\\3\\16\\3\\16\\3\\16\\3\\16\")\n-        buf.write(u\"\\3\\16\\3\\16\\3\\16\\3\\16\\3\\16\\3\\16\\3\\16\\3\\16\\3\\16\\3\\16\\3\")\n-        buf.write(u\"\\16\\3\\16\\3\\16\\3\\16\\3\\16\\3\\16\\3\\16\\3\\16\\5\\16\\u0179\\n\\16\")\n-        buf.write(u\"\\3\\16\\3\\16\\3\\17\\3\\17\\3\\20\\3\\20\\3\\21\\3\\21\\3\\22\\3\\22\\3\")\n-        buf.write(u\"\\23\\3\\23\\3\\24\\3\\24\\3\\25\\3\\25\\3\\26\\3\\26\\3\\27\\3\\27\\3\\27\")\n-        buf.write(u\"\\3\\30\\3\\30\\3\\30\\3\\31\\3\\31\\3\\32\\3\\32\\3\\33\\3\\33\\3\\34\\3\")\n-        buf.write(u\"\\34\\3\\34\\3\\34\\3\\34\\3\\34\\3\\34\\3\\34\\3\\35\\3\\35\\3\\35\\3\\35\")\n-        buf.write(u\"\\3\\35\\3\\35\\3\\35\\3\\36\\3\\36\\3\\36\\3\\36\\3\\36\\3\\36\\3\\36\\3\")\n-        buf.write(u\"\\36\\3\\37\\3\\37\\3\\37\\3\\37\\3\\37\\3\\37\\3\\37\\3\\37\\3 \\3 \\3 \")\n-        buf.write(u\"\\3 \\3 \\3!\\3!\\3!\\3!\\3!\\3!\\3!\\3!\\3!\\3!\\3!\\3!\\3!\\3!\\3!\\3\")\n-        buf.write(u\"!\\3!\\3!\\3!\\3!\\3!\\3!\\3!\\3!\\3!\\3!\\3!\\3!\\3!\\3!\\3!\\3!\\3!\")\n-        buf.write(u\"\\3!\\3!\\3!\\3!\\3!\\3!\\3!\\3!\\3!\\3!\\3!\\3!\\3!\\3!\\3!\\3!\\3!\\3\")\n-        buf.write(u\"!\\3!\\3!\\3!\\3!\\5!\\u01f4\\n!\\3\\\"\\3\\\"\\3\\\"\\3\\\"\\3\\\"\\3#\\3#\\3\")\n-        buf.write(u\"#\\3#\\3#\\3$\\3$\\3$\\3$\\3$\\3$\\3%\\3%\\3%\\3%\\3%\\3&\\3&\\3&\\3&\")\n-        buf.write(u\"\\3&\\3\\'\\3\\'\\3\\'\\3\\'\\3(\\3(\\3(\\3(\\3(\\3)\\3)\\3)\\3)\\3)\\3*\")\n-        buf.write(u\"\\3*\\3*\\3*\\3*\\3+\\3+\\3+\\3+\\3+\\3,\\3,\\3,\\3,\\3,\\3-\\3-\\3-\\3\")\n-        buf.write(u\"-\\3-\\3.\\3.\\3.\\3.\\3.\\3.\\3.\\3.\\3/\\3/\\3/\\3/\\3/\\3/\\3/\\3/\")\n-        buf.write(u\"\\3\\60\\3\\60\\3\\60\\3\\60\\3\\60\\3\\60\\3\\60\\3\\60\\3\\61\\3\\61\\3\")\n-        buf.write(u\"\\61\\3\\61\\3\\61\\3\\61\\3\\61\\3\\61\\3\\62\\3\\62\\3\\62\\3\\62\\3\\62\")\n-        buf.write(u\"\\3\\62\\3\\62\\3\\62\\3\\63\\3\\63\\3\\63\\3\\63\\3\\63\\3\\63\\3\\63\\3\")\n-        buf.write(u\"\\63\\3\\64\\3\\64\\3\\64\\3\\64\\3\\64\\3\\64\\3\\65\\3\\65\\3\\65\\3\\65\")\n-        buf.write(u\"\\3\\65\\3\\65\\3\\66\\3\\66\\3\\66\\3\\66\\3\\66\\3\\66\\3\\67\\3\\67\\3\")\n-        buf.write(u\"\\67\\3\\67\\3\\67\\3\\67\\3\\67\\3\\67\\38\\38\\38\\38\\38\\38\\38\\38\")\n-        buf.write(u\"\\39\\39\\39\\39\\39\\39\\39\\39\\3:\\3:\\3:\\3:\\3:\\3:\\3:\\3:\\3;\\3\")\n-        buf.write(u\";\\3;\\3;\\3;\\3;\\3;\\3;\\3<\\3<\\3<\\3<\\3<\\3<\\3<\\3=\\3=\\3=\\3=\")\n-        buf.write(u\"\\3=\\3=\\3=\\3>\\3>\\3>\\3>\\3>\\3>\\3?\\3?\\3?\\3?\\3?\\3?\\3?\\3?\\3\")\n-        buf.write(u\"?\\3?\\3@\\3@\\3@\\3@\\3@\\3@\\3@\\3A\\3A\\3A\\3A\\3A\\3A\\3B\\3B\\3B\")\n-        buf.write(u\"\\3B\\3B\\3C\\3C\\3C\\3C\\3C\\3C\\3D\\3D\\3D\\3D\\3D\\3D\\3D\\3E\\3E\\3\")\n-        buf.write(u\"E\\3E\\3E\\3E\\3E\\3E\\3F\\3F\\3F\\3F\\3F\\3F\\3F\\3F\\3G\\3G\\3G\\3G\")\n-        buf.write(u\"\\3G\\3G\\3G\\3G\\3H\\3H\\3I\\3I\\3J\\3J\\3K\\3K\\3L\\3L\\7L\\u02fb\\n\")\n-        buf.write(u\"L\\fL\\16L\\u02fe\\13L\\3L\\3L\\3L\\6L\\u0303\\nL\\rL\\16L\\u0304\")\n-        buf.write(u\"\\5L\\u0307\\nL\\3M\\3M\\3N\\3N\\3O\\6O\\u030e\\nO\\rO\\16O\\u030f\")\n-        buf.write(u\"\\3O\\3O\\3O\\3O\\3O\\7O\\u0317\\nO\\fO\\16O\\u031a\\13O\\3O\\7O\\u031d\")\n-        buf.write(u\"\\nO\\fO\\16O\\u0320\\13O\\3O\\3O\\3O\\3O\\3O\\7O\\u0327\\nO\\fO\\16\")\n-        buf.write(u\"O\\u032a\\13O\\3O\\3O\\6O\\u032e\\nO\\rO\\16O\\u032f\\5O\\u0332\\n\")\n-        buf.write(u\"O\\3P\\3P\\7P\\u0336\\nP\\fP\\16P\\u0339\\13P\\5P\\u033b\\nP\\3P\\3\")\n-        buf.write(u\"P\\3P\\7P\\u0340\\nP\\fP\\16P\\u0343\\13P\\3P\\5P\\u0346\\nP\\5P\\u0348\")\n-        buf.write(u\"\\nP\\3Q\\3Q\\3Q\\3Q\\3Q\\3R\\3R\\3S\\3S\\3S\\3S\\3S\\3S\\3S\\3S\\3S\\5\")\n-        buf.write(u\"S\\u035a\\nS\\3T\\3T\\3T\\3T\\3T\\3T\\3U\\3U\\3U\\3U\\3U\\3U\\3U\\3U\")\n-        buf.write(u\"\\3U\\3U\\3V\\3V\\3W\\3W\\3W\\3W\\3W\\3W\\3W\\3W\\3W\\5W\\u0377\\nW\\3\")\n-        buf.write(u\"X\\3X\\3X\\3X\\3X\\3X\\3Y\\3Y\\3Y\\3Y\\3Y\\3Y\\3Y\\3Y\\3Y\\3Y\\3Z\\3Z\")\n-        buf.write(u\"\\3[\\3[\\6[\\u038d\\n[\\r[\\16[\\u038e\\5\\u02fc\\u0337\\u0341\\2\")\n-        buf.write(u\"\\\\\\3\\3\\5\\4\\7\\5\\t\\6\\13\\7\\r\\b\\17\\t\\21\\n\\23\\13\\25\\f\\27\\r\")\n-        buf.write(u\"\\31\\16\\33\\17\\35\\20\\37\\21!\\22#\\23%\\24\\'\\25)\\26+\\27-\\30\")\n-        buf.write(u\"/\\31\\61\\32\\63\\33\\65\\34\\67\\359\\36;\\37= ?!A\\\"C#E$G%I&K\")\n-        buf.write(u\"\\'M(O)Q*S+U,W-Y.[/]\\60_\\61a\\62c\\63e\\64g\\65i\\66k\\67m8\")\n-        buf.write(u\"o9q:s;u<w=y>{?}@\\177A\\u0081B\\u0083C\\u0085D\\u0087E\\u0089\")\n-        buf.write(u\"F\\u008bG\\u008dH\\u008fI\\u0091J\\u0093K\\u0095\\2\\u0097L\\u0099\")\n-        buf.write(u\"M\\u009b\\2\\u009dN\\u009fO\\u00a1P\\u00a3Q\\u00a5R\\u00a7S\\u00a9\")\n-        buf.write(u\"T\\u00abU\\u00adV\\u00afW\\u00b1X\\u00b3Y\\u00b5Z\\3\\2\\5\\5\\2\")\n-        buf.write(u\"\\13\\f\\17\\17\\\"\\\"\\4\\2C\\\\c|\\3\\2\\62;\\2\\u03b7\\2\\3\\3\\2\\2\\2\")\n-        buf.write(u\"\\2\\5\\3\\2\\2\\2\\2\\7\\3\\2\\2\\2\\2\\t\\3\\2\\2\\2\\2\\13\\3\\2\\2\\2\\2\\r\")\n-        buf.write(u\"\\3\\2\\2\\2\\2\\17\\3\\2\\2\\2\\2\\21\\3\\2\\2\\2\\2\\23\\3\\2\\2\\2\\2\\25\")\n-        buf.write(u\"\\3\\2\\2\\2\\2\\27\\3\\2\\2\\2\\2\\31\\3\\2\\2\\2\\2\\33\\3\\2\\2\\2\\2\\35\")\n-        buf.write(u\"\\3\\2\\2\\2\\2\\37\\3\\2\\2\\2\\2!\\3\\2\\2\\2\\2#\\3\\2\\2\\2\\2%\\3\\2\\2\")\n-        buf.write(u\"\\2\\2\\'\\3\\2\\2\\2\\2)\\3\\2\\2\\2\\2+\\3\\2\\2\\2\\2-\\3\\2\\2\\2\\2/\\3\")\n-        buf.write(u\"\\2\\2\\2\\2\\61\\3\\2\\2\\2\\2\\63\\3\\2\\2\\2\\2\\65\\3\\2\\2\\2\\2\\67\\3\")\n-        buf.write(u\"\\2\\2\\2\\29\\3\\2\\2\\2\\2;\\3\\2\\2\\2\\2=\\3\\2\\2\\2\\2?\\3\\2\\2\\2\\2\")\n-        buf.write(u\"A\\3\\2\\2\\2\\2C\\3\\2\\2\\2\\2E\\3\\2\\2\\2\\2G\\3\\2\\2\\2\\2I\\3\\2\\2\\2\")\n-        buf.write(u\"\\2K\\3\\2\\2\\2\\2M\\3\\2\\2\\2\\2O\\3\\2\\2\\2\\2Q\\3\\2\\2\\2\\2S\\3\\2\\2\")\n-        buf.write(u\"\\2\\2U\\3\\2\\2\\2\\2W\\3\\2\\2\\2\\2Y\\3\\2\\2\\2\\2[\\3\\2\\2\\2\\2]\\3\\2\")\n-        buf.write(u\"\\2\\2\\2_\\3\\2\\2\\2\\2a\\3\\2\\2\\2\\2c\\3\\2\\2\\2\\2e\\3\\2\\2\\2\\2g\\3\")\n-        buf.write(u\"\\2\\2\\2\\2i\\3\\2\\2\\2\\2k\\3\\2\\2\\2\\2m\\3\\2\\2\\2\\2o\\3\\2\\2\\2\\2\")\n-        buf.write(u\"q\\3\\2\\2\\2\\2s\\3\\2\\2\\2\\2u\\3\\2\\2\\2\\2w\\3\\2\\2\\2\\2y\\3\\2\\2\\2\")\n-        buf.write(u\"\\2{\\3\\2\\2\\2\\2}\\3\\2\\2\\2\\2\\177\\3\\2\\2\\2\\2\\u0081\\3\\2\\2\\2\")\n-        buf.write(u\"\\2\\u0083\\3\\2\\2\\2\\2\\u0085\\3\\2\\2\\2\\2\\u0087\\3\\2\\2\\2\\2\\u0089\")\n-        buf.write(u\"\\3\\2\\2\\2\\2\\u008b\\3\\2\\2\\2\\2\\u008d\\3\\2\\2\\2\\2\\u008f\\3\\2\")\n-        buf.write(u\"\\2\\2\\2\\u0091\\3\\2\\2\\2\\2\\u0093\\3\\2\\2\\2\\2\\u0097\\3\\2\\2\\2\")\n-        buf.write(u\"\\2\\u0099\\3\\2\\2\\2\\2\\u009d\\3\\2\\2\\2\\2\\u009f\\3\\2\\2\\2\\2\\u00a1\")\n-        buf.write(u\"\\3\\2\\2\\2\\2\\u00a3\\3\\2\\2\\2\\2\\u00a5\\3\\2\\2\\2\\2\\u00a7\\3\\2\")\n-        buf.write(u\"\\2\\2\\2\\u00a9\\3\\2\\2\\2\\2\\u00ab\\3\\2\\2\\2\\2\\u00ad\\3\\2\\2\\2\")\n-        buf.write(u\"\\2\\u00af\\3\\2\\2\\2\\2\\u00b1\\3\\2\\2\\2\\2\\u00b3\\3\\2\\2\\2\\2\\u00b5\")\n-        buf.write(u\"\\3\\2\\2\\2\\3\\u00b7\\3\\2\\2\\2\\5\\u00ba\\3\\2\\2\\2\\7\\u00cc\\3\\2\")\n-        buf.write(u\"\\2\\2\\t\\u00db\\3\\2\\2\\2\\13\\u00ec\\3\\2\\2\\2\\r\\u00f0\\3\\2\\2\\2\")\n-        buf.write(u\"\\17\\u00f8\\3\\2\\2\\2\\21\\u0110\\3\\2\\2\\2\\23\\u0114\\3\\2\\2\\2\\25\")\n-        buf.write(u\"\\u0123\\3\\2\\2\\2\\27\\u0134\\3\\2\\2\\2\\31\\u013c\\3\\2\\2\\2\\33\\u0178\")\n-        buf.write(u\"\\3\\2\\2\\2\\35\\u017c\\3\\2\\2\\2\\37\\u017e\\3\\2\\2\\2!\\u0180\\3\\2\")\n-        buf.write(u\"\\2\\2#\\u0182\\3\\2\\2\\2%\\u0184\\3\\2\\2\\2\\'\\u0186\\3\\2\\2\\2)\\u0188\")\n-        buf.write(u\"\\3\\2\\2\\2+\\u018a\\3\\2\\2\\2-\\u018c\\3\\2\\2\\2/\\u018f\\3\\2\\2\\2\")\n-        buf.write(u\"\\61\\u0192\\3\\2\\2\\2\\63\\u0194\\3\\2\\2\\2\\65\\u0196\\3\\2\\2\\2\\67\")\n-        buf.write(u\"\\u0198\\3\\2\\2\\29\\u01a0\\3\\2\\2\\2;\\u01a7\\3\\2\\2\\2=\\u01af\\3\")\n-        buf.write(u\"\\2\\2\\2?\\u01b7\\3\\2\\2\\2A\\u01f3\\3\\2\\2\\2C\\u01f5\\3\\2\\2\\2E\")\n-        buf.write(u\"\\u01fa\\3\\2\\2\\2G\\u01ff\\3\\2\\2\\2I\\u0205\\3\\2\\2\\2K\\u020a\\3\")\n-        buf.write(u\"\\2\\2\\2M\\u020f\\3\\2\\2\\2O\\u0213\\3\\2\\2\\2Q\\u0218\\3\\2\\2\\2S\")\n-        buf.write(u\"\\u021d\\3\\2\\2\\2U\\u0222\\3\\2\\2\\2W\\u0227\\3\\2\\2\\2Y\\u022c\\3\")\n-        buf.write(u\"\\2\\2\\2[\\u0231\\3\\2\\2\\2]\\u0239\\3\\2\\2\\2_\\u0241\\3\\2\\2\\2a\")\n-        buf.write(u\"\\u0249\\3\\2\\2\\2c\\u0251\\3\\2\\2\\2e\\u0259\\3\\2\\2\\2g\\u0261\\3\")\n-        buf.write(u\"\\2\\2\\2i\\u0267\\3\\2\\2\\2k\\u026d\\3\\2\\2\\2m\\u0273\\3\\2\\2\\2o\")\n-        buf.write(u\"\\u027b\\3\\2\\2\\2q\\u0283\\3\\2\\2\\2s\\u028b\\3\\2\\2\\2u\\u0293\\3\")\n-        buf.write(u\"\\2\\2\\2w\\u029b\\3\\2\\2\\2y\\u02a2\\3\\2\\2\\2{\\u02a9\\3\\2\\2\\2}\")\n-        buf.write(u\"\\u02af\\3\\2\\2\\2\\177\\u02b9\\3\\2\\2\\2\\u0081\\u02c0\\3\\2\\2\\2\")\n-        buf.write(u\"\\u0083\\u02c6\\3\\2\\2\\2\\u0085\\u02cb\\3\\2\\2\\2\\u0087\\u02d1\")\n-        buf.write(u\"\\3\\2\\2\\2\\u0089\\u02d8\\3\\2\\2\\2\\u008b\\u02e0\\3\\2\\2\\2\\u008d\")\n-        buf.write(u\"\\u02e8\\3\\2\\2\\2\\u008f\\u02f0\\3\\2\\2\\2\\u0091\\u02f2\\3\\2\\2\")\n-        buf.write(u\"\\2\\u0093\\u02f4\\3\\2\\2\\2\\u0095\\u02f6\\3\\2\\2\\2\\u0097\\u02f8\")\n-        buf.write(u\"\\3\\2\\2\\2\\u0099\\u0308\\3\\2\\2\\2\\u009b\\u030a\\3\\2\\2\\2\\u009d\")\n-        buf.write(u\"\\u0331\\3\\2\\2\\2\\u009f\\u0347\\3\\2\\2\\2\\u00a1\\u0349\\3\\2\\2\")\n-        buf.write(u\"\\2\\u00a3\\u034e\\3\\2\\2\\2\\u00a5\\u0359\\3\\2\\2\\2\\u00a7\\u035b\")\n-        buf.write(u\"\\3\\2\\2\\2\\u00a9\\u0361\\3\\2\\2\\2\\u00ab\\u036b\\3\\2\\2\\2\\u00ad\")\n-        buf.write(u\"\\u0376\\3\\2\\2\\2\\u00af\\u0378\\3\\2\\2\\2\\u00b1\\u037e\\3\\2\\2\")\n-        buf.write(u\"\\2\\u00b3\\u0388\\3\\2\\2\\2\\u00b5\\u038a\\3\\2\\2\\2\\u00b7\\u00b8\")\n-        buf.write(u\"\\7.\\2\\2\\u00b8\\4\\3\\2\\2\\2\\u00b9\\u00bb\\t\\2\\2\\2\\u00ba\\u00b9\")\n-        buf.write(u\"\\3\\2\\2\\2\\u00bb\\u00bc\\3\\2\\2\\2\\u00bc\\u00ba\\3\\2\\2\\2\\u00bc\")\n-        buf.write(u\"\\u00bd\\3\\2\\2\\2\\u00bd\\u00be\\3\\2\\2\\2\\u00be\\u00bf\\b\\3\\2\")\n-        buf.write(u\"\\2\\u00bf\\6\\3\\2\\2\\2\\u00c0\\u00c1\\7^\\2\\2\\u00c1\\u00cd\\7.\")\n-        buf.write(u\"\\2\\2\\u00c2\\u00c3\\7^\\2\\2\\u00c3\\u00c4\\7v\\2\\2\\u00c4\\u00c5\")\n-        buf.write(u\"\\7j\\2\\2\\u00c5\\u00c6\\7k\\2\\2\\u00c6\\u00c7\\7p\\2\\2\\u00c7\\u00c8\")\n-        buf.write(u\"\\7u\\2\\2\\u00c8\\u00c9\\7r\\2\\2\\u00c9\\u00ca\\7c\\2\\2\\u00ca\\u00cb\")\n-        buf.write(u\"\\7e\\2\\2\\u00cb\\u00cd\\7g\\2\\2\\u00cc\\u00c0\\3\\2\\2\\2\\u00cc\")\n-        buf.write(u\"\\u00c2\\3\\2\\2\\2\\u00cd\\u00ce\\3\\2\\2\\2\\u00ce\\u00cf\\b\\4\\2\")\n-        buf.write(u\"\\2\\u00cf\\b\\3\\2\\2\\2\\u00d0\\u00d1\\7^\\2\\2\\u00d1\\u00dc\\7<\")\n-        buf.write(u\"\\2\\2\\u00d2\\u00d3\\7^\\2\\2\\u00d3\\u00d4\\7o\\2\\2\\u00d4\\u00d5\")\n-        buf.write(u\"\\7g\\2\\2\\u00d5\\u00d6\\7f\\2\\2\\u00d6\\u00d7\\7u\\2\\2\\u00d7\\u00d8\")\n-        buf.write(u\"\\7r\\2\\2\\u00d8\\u00d9\\7c\\2\\2\\u00d9\\u00da\\7e\\2\\2\\u00da\\u00dc\")\n-        buf.write(u\"\\7g\\2\\2\\u00db\\u00d0\\3\\2\\2\\2\\u00db\\u00d2\\3\\2\\2\\2\\u00dc\")\n-        buf.write(u\"\\u00dd\\3\\2\\2\\2\\u00dd\\u00de\\b\\5\\2\\2\\u00de\\n\\3\\2\\2\\2\\u00df\")\n-        buf.write(u\"\\u00e0\\7^\\2\\2\\u00e0\\u00ed\\7=\\2\\2\\u00e1\\u00e2\\7^\\2\\2\\u00e2\")\n-        buf.write(u\"\\u00e3\\7v\\2\\2\\u00e3\\u00e4\\7j\\2\\2\\u00e4\\u00e5\\7k\\2\\2\\u00e5\")\n-        buf.write(u\"\\u00e6\\7e\\2\\2\\u00e6\\u00e7\\7m\\2\\2\\u00e7\\u00e8\\7u\\2\\2\\u00e8\")\n-        buf.write(u\"\\u00e9\\7r\\2\\2\\u00e9\\u00ea\\7c\\2\\2\\u00ea\\u00eb\\7e\\2\\2\\u00eb\")\n-        buf.write(u\"\\u00ed\\7g\\2\\2\\u00ec\\u00df\\3\\2\\2\\2\\u00ec\\u00e1\\3\\2\\2\\2\")\n-        buf.write(u\"\\u00ed\\u00ee\\3\\2\\2\\2\\u00ee\\u00ef\\b\\6\\2\\2\\u00ef\\f\\3\\2\")\n-        buf.write(u\"\\2\\2\\u00f0\\u00f1\\7^\\2\\2\\u00f1\\u00f2\\7s\\2\\2\\u00f2\\u00f3\")\n-        buf.write(u\"\\7w\\2\\2\\u00f3\\u00f4\\7c\\2\\2\\u00f4\\u00f5\\7f\\2\\2\\u00f5\\u00f6\")\n-        buf.write(u\"\\3\\2\\2\\2\\u00f6\\u00f7\\b\\7\\2\\2\\u00f7\\16\\3\\2\\2\\2\\u00f8\\u00f9\")\n-        buf.write(u\"\\7^\\2\\2\\u00f9\\u00fa\\7s\\2\\2\\u00fa\\u00fb\\7s\\2\\2\\u00fb\\u00fc\")\n-        buf.write(u\"\\7w\\2\\2\\u00fc\\u00fd\\7c\\2\\2\\u00fd\\u00fe\\7f\\2\\2\\u00fe\\u00ff\")\n-        buf.write(u\"\\3\\2\\2\\2\\u00ff\\u0100\\b\\b\\2\\2\\u0100\\20\\3\\2\\2\\2\\u0101\\u0102\")\n-        buf.write(u\"\\7^\\2\\2\\u0102\\u0111\\7#\\2\\2\\u0103\\u0104\\7^\\2\\2\\u0104\\u0105\")\n-        buf.write(u\"\\7p\\2\\2\\u0105\\u0106\\7g\\2\\2\\u0106\\u0107\\7i\\2\\2\\u0107\\u0108\")\n-        buf.write(u\"\\7v\\2\\2\\u0108\\u0109\\7j\\2\\2\\u0109\\u010a\\7k\\2\\2\\u010a\\u010b\")\n-        buf.write(u\"\\7p\\2\\2\\u010b\\u010c\\7u\\2\\2\\u010c\\u010d\\7r\\2\\2\\u010d\\u010e\")\n-        buf.write(u\"\\7c\\2\\2\\u010e\\u010f\\7e\\2\\2\\u010f\\u0111\\7g\\2\\2\\u0110\\u0101\")\n-        buf.write(u\"\\3\\2\\2\\2\\u0110\\u0103\\3\\2\\2\\2\\u0111\\u0112\\3\\2\\2\\2\\u0112\")\n-        buf.write(u\"\\u0113\\b\\t\\2\\2\\u0113\\22\\3\\2\\2\\2\\u0114\\u0115\\7^\\2\\2\\u0115\")\n-        buf.write(u\"\\u0116\\7p\\2\\2\\u0116\\u0117\\7g\\2\\2\\u0117\\u0118\\7i\\2\\2\\u0118\")\n-        buf.write(u\"\\u0119\\7o\\2\\2\\u0119\\u011a\\7g\\2\\2\\u011a\\u011b\\7f\\2\\2\\u011b\")\n-        buf.write(u\"\\u011c\\7u\\2\\2\\u011c\\u011d\\7r\\2\\2\\u011d\\u011e\\7c\\2\\2\\u011e\")\n-        buf.write(u\"\\u011f\\7e\\2\\2\\u011f\\u0120\\7g\\2\\2\\u0120\\u0121\\3\\2\\2\\2\")\n-        buf.write(u\"\\u0121\\u0122\\b\\n\\2\\2\\u0122\\24\\3\\2\\2\\2\\u0123\\u0124\\7^\")\n-        buf.write(u\"\\2\\2\\u0124\\u0125\\7p\\2\\2\\u0125\\u0126\\7g\\2\\2\\u0126\\u0127\")\n-        buf.write(u\"\\7i\\2\\2\\u0127\\u0128\\7v\\2\\2\\u0128\\u0129\\7j\\2\\2\\u0129\\u012a\")\n-        buf.write(u\"\\7k\\2\\2\\u012a\\u012b\\7e\\2\\2\\u012b\\u012c\\7m\\2\\2\\u012c\\u012d\")\n-        buf.write(u\"\\7u\\2\\2\\u012d\\u012e\\7r\\2\\2\\u012e\\u012f\\7c\\2\\2\\u012f\\u0130\")\n-        buf.write(u\"\\7e\\2\\2\\u0130\\u0131\\7g\\2\\2\\u0131\\u0132\\3\\2\\2\\2\\u0132\")\n-        buf.write(u\"\\u0133\\b\\13\\2\\2\\u0133\\26\\3\\2\\2\\2\\u0134\\u0135\\7^\\2\\2\\u0135\")\n-        buf.write(u\"\\u0136\\7n\\2\\2\\u0136\\u0137\\7g\\2\\2\\u0137\\u0138\\7h\\2\\2\\u0138\")\n-        buf.write(u\"\\u0139\\7v\\2\\2\\u0139\\u013a\\3\\2\\2\\2\\u013a\\u013b\\b\\f\\2\\2\")\n-        buf.write(u\"\\u013b\\30\\3\\2\\2\\2\\u013c\\u013d\\7^\\2\\2\\u013d\\u013e\\7t\\2\")\n-        buf.write(u\"\\2\\u013e\\u013f\\7k\\2\\2\\u013f\\u0140\\7i\\2\\2\\u0140\\u0141\")\n-        buf.write(u\"\\7j\\2\\2\\u0141\\u0142\\7v\\2\\2\\u0142\\u0143\\3\\2\\2\\2\\u0143\")\n-        buf.write(u\"\\u0144\\b\\r\\2\\2\\u0144\\32\\3\\2\\2\\2\\u0145\\u0146\\7^\\2\\2\\u0146\")\n-        buf.write(u\"\\u0147\\7x\\2\\2\\u0147\\u0148\\7t\\2\\2\\u0148\\u0149\\7w\\2\\2\\u0149\")\n-        buf.write(u\"\\u014a\\7n\\2\\2\\u014a\\u0179\\7g\\2\\2\\u014b\\u014c\\7^\\2\\2\\u014c\")\n-        buf.write(u\"\\u014d\\7x\\2\\2\\u014d\\u014e\\7e\\2\\2\\u014e\\u014f\\7g\\2\\2\\u014f\")\n-        buf.write(u\"\\u0150\\7p\\2\\2\\u0150\\u0151\\7v\\2\\2\\u0151\\u0152\\7g\\2\\2\\u0152\")\n-        buf.write(u\"\\u0179\\7t\\2\\2\\u0153\\u0154\\7^\\2\\2\\u0154\\u0155\\7x\\2\\2\\u0155\")\n-        buf.write(u\"\\u0156\\7d\\2\\2\\u0156\\u0157\\7q\\2\\2\\u0157\\u0179\\7z\\2\\2\\u0158\")\n-        buf.write(u\"\\u0159\\7^\\2\\2\\u0159\\u015a\\7x\\2\\2\\u015a\\u015b\\7u\\2\\2\\u015b\")\n-        buf.write(u\"\\u015c\\7m\\2\\2\\u015c\\u015d\\7k\\2\\2\\u015d\\u0179\\7r\\2\\2\\u015e\")\n-        buf.write(u\"\\u015f\\7^\\2\\2\\u015f\\u0160\\7x\\2\\2\\u0160\\u0161\\7u\\2\\2\\u0161\")\n-        buf.write(u\"\\u0162\\7r\\2\\2\\u0162\\u0163\\7c\\2\\2\\u0163\\u0164\\7e\\2\\2\\u0164\")\n-        buf.write(u\"\\u0179\\7g\\2\\2\\u0165\\u0166\\7^\\2\\2\\u0166\\u0167\\7j\\2\\2\\u0167\")\n-        buf.write(u\"\\u0168\\7h\\2\\2\\u0168\\u0169\\7k\\2\\2\\u0169\\u0179\\7n\\2\\2\\u016a\")\n-        buf.write(u\"\\u016b\\7^\\2\\2\\u016b\\u0179\\7,\\2\\2\\u016c\\u016d\\7^\\2\\2\\u016d\")\n-        buf.write(u\"\\u0179\\7/\\2\\2\\u016e\\u016f\\7^\\2\\2\\u016f\\u0179\\7\\60\\2\\2\")\n-        buf.write(u\"\\u0170\\u0171\\7^\\2\\2\\u0171\\u0179\\7\\61\\2\\2\\u0172\\u0173\")\n-        buf.write(u\"\\7^\\2\\2\\u0173\\u0179\\7$\\2\\2\\u0174\\u0175\\7^\\2\\2\\u0175\\u0179\")\n-        buf.write(u\"\\7*\\2\\2\\u0176\\u0177\\7^\\2\\2\\u0177\\u0179\\7?\\2\\2\\u0178\\u0145\")\n-        buf.write(u\"\\3\\2\\2\\2\\u0178\\u014b\\3\\2\\2\\2\\u0178\\u0153\\3\\2\\2\\2\\u0178\")\n-        buf.write(u\"\\u0158\\3\\2\\2\\2\\u0178\\u015e\\3\\2\\2\\2\\u0178\\u0165\\3\\2\\2\")\n-        buf.write(u\"\\2\\u0178\\u016a\\3\\2\\2\\2\\u0178\\u016c\\3\\2\\2\\2\\u0178\\u016e\")\n-        buf.write(u\"\\3\\2\\2\\2\\u0178\\u0170\\3\\2\\2\\2\\u0178\\u0172\\3\\2\\2\\2\\u0178\")\n-        buf.write(u\"\\u0174\\3\\2\\2\\2\\u0178\\u0176\\3\\2\\2\\2\\u0179\\u017a\\3\\2\\2\")\n-        buf.write(u\"\\2\\u017a\\u017b\\b\\16\\2\\2\\u017b\\34\\3\\2\\2\\2\\u017c\\u017d\")\n-        buf.write(u\"\\7-\\2\\2\\u017d\\36\\3\\2\\2\\2\\u017e\\u017f\\7/\\2\\2\\u017f \\3\")\n-        buf.write(u\"\\2\\2\\2\\u0180\\u0181\\7,\\2\\2\\u0181\\\"\\3\\2\\2\\2\\u0182\\u0183\")\n-        buf.write(u\"\\7\\61\\2\\2\\u0183$\\3\\2\\2\\2\\u0184\\u0185\\7*\\2\\2\\u0185&\\3\")\n-        buf.write(u\"\\2\\2\\2\\u0186\\u0187\\7+\\2\\2\\u0187(\\3\\2\\2\\2\\u0188\\u0189\")\n-        buf.write(u\"\\7}\\2\\2\\u0189*\\3\\2\\2\\2\\u018a\\u018b\\7\\177\\2\\2\\u018b,\\3\")\n-        buf.write(u\"\\2\\2\\2\\u018c\\u018d\\7^\\2\\2\\u018d\\u018e\\7}\\2\\2\\u018e.\\3\")\n-        buf.write(u\"\\2\\2\\2\\u018f\\u0190\\7^\\2\\2\\u0190\\u0191\\7\\177\\2\\2\\u0191\")\n-        buf.write(u\"\\60\\3\\2\\2\\2\\u0192\\u0193\\7]\\2\\2\\u0193\\62\\3\\2\\2\\2\\u0194\")\n-        buf.write(u\"\\u0195\\7_\\2\\2\\u0195\\64\\3\\2\\2\\2\\u0196\\u0197\\7~\\2\\2\\u0197\")\n-        buf.write(u\"\\66\\3\\2\\2\\2\\u0198\\u0199\\7^\\2\\2\\u0199\\u019a\\7t\\2\\2\\u019a\")\n-        buf.write(u\"\\u019b\\7k\\2\\2\\u019b\\u019c\\7i\\2\\2\\u019c\\u019d\\7j\\2\\2\\u019d\")\n-        buf.write(u\"\\u019e\\7v\\2\\2\\u019e\\u019f\\7~\\2\\2\\u019f8\\3\\2\\2\\2\\u01a0\")\n-        buf.write(u\"\\u01a1\\7^\\2\\2\\u01a1\\u01a2\\7n\\2\\2\\u01a2\\u01a3\\7g\\2\\2\\u01a3\")\n-        buf.write(u\"\\u01a4\\7h\\2\\2\\u01a4\\u01a5\\7v\\2\\2\\u01a5\\u01a6\\7~\\2\\2\\u01a6\")\n-        buf.write(u\":\\3\\2\\2\\2\\u01a7\\u01a8\\7^\\2\\2\\u01a8\\u01a9\\7n\\2\\2\\u01a9\")\n-        buf.write(u\"\\u01aa\\7c\\2\\2\\u01aa\\u01ab\\7p\\2\\2\\u01ab\\u01ac\\7i\\2\\2\\u01ac\")\n-        buf.write(u\"\\u01ad\\7n\\2\\2\\u01ad\\u01ae\\7g\\2\\2\\u01ae<\\3\\2\\2\\2\\u01af\")\n-        buf.write(u\"\\u01b0\\7^\\2\\2\\u01b0\\u01b1\\7t\\2\\2\\u01b1\\u01b2\\7c\\2\\2\\u01b2\")\n-        buf.write(u\"\\u01b3\\7p\\2\\2\\u01b3\\u01b4\\7i\\2\\2\\u01b4\\u01b5\\7n\\2\\2\\u01b5\")\n-        buf.write(u\"\\u01b6\\7g\\2\\2\\u01b6>\\3\\2\\2\\2\\u01b7\\u01b8\\7^\\2\\2\\u01b8\")\n-        buf.write(u\"\\u01b9\\7n\\2\\2\\u01b9\\u01ba\\7k\\2\\2\\u01ba\\u01bb\\7o\\2\\2\\u01bb\")\n-        buf.write(u\"@\\3\\2\\2\\2\\u01bc\\u01bd\\7^\\2\\2\\u01bd\\u01be\\7v\\2\\2\\u01be\")\n-        buf.write(u\"\\u01f4\\7q\\2\\2\\u01bf\\u01c0\\7^\\2\\2\\u01c0\\u01c1\\7t\\2\\2\\u01c1\")\n-        buf.write(u\"\\u01c2\\7k\\2\\2\\u01c2\\u01c3\\7i\\2\\2\\u01c3\\u01c4\\7j\\2\\2\\u01c4\")\n-        buf.write(u\"\\u01c5\\7v\\2\\2\\u01c5\\u01c6\\7c\\2\\2\\u01c6\\u01c7\\7t\\2\\2\\u01c7\")\n-        buf.write(u\"\\u01c8\\7t\\2\\2\\u01c8\\u01c9\\7q\\2\\2\\u01c9\\u01f4\\7y\\2\\2\\u01ca\")\n-        buf.write(u\"\\u01cb\\7^\\2\\2\\u01cb\\u01cc\\7T\\2\\2\\u01cc\\u01cd\\7k\\2\\2\\u01cd\")\n-        buf.write(u\"\\u01ce\\7i\\2\\2\\u01ce\\u01cf\\7j\\2\\2\\u01cf\\u01d0\\7v\\2\\2\\u01d0\")\n-        buf.write(u\"\\u01d1\\7c\\2\\2\\u01d1\\u01d2\\7t\\2\\2\\u01d2\\u01d3\\7t\\2\\2\\u01d3\")\n-        buf.write(u\"\\u01d4\\7q\\2\\2\\u01d4\\u01f4\\7y\\2\\2\\u01d5\\u01d6\\7^\\2\\2\\u01d6\")\n-        buf.write(u\"\\u01d7\\7n\\2\\2\\u01d7\\u01d8\\7q\\2\\2\\u01d8\\u01d9\\7p\\2\\2\\u01d9\")\n-        buf.write(u\"\\u01da\\7i\\2\\2\\u01da\\u01db\\7t\\2\\2\\u01db\\u01dc\\7k\\2\\2\\u01dc\")\n-        buf.write(u\"\\u01dd\\7i\\2\\2\\u01dd\\u01de\\7j\\2\\2\\u01de\\u01df\\7v\\2\\2\\u01df\")\n-        buf.write(u\"\\u01e0\\7c\\2\\2\\u01e0\\u01e1\\7t\\2\\2\\u01e1\\u01e2\\7t\\2\\2\\u01e2\")\n-        buf.write(u\"\\u01e3\\7q\\2\\2\\u01e3\\u01f4\\7y\\2\\2\\u01e4\\u01e5\\7^\\2\\2\\u01e5\")\n-        buf.write(u\"\\u01e6\\7N\\2\\2\\u01e6\\u01e7\\7q\\2\\2\\u01e7\\u01e8\\7p\\2\\2\\u01e8\")\n-        buf.write(u\"\\u01e9\\7i\\2\\2\\u01e9\\u01ea\\7t\\2\\2\\u01ea\\u01eb\\7k\\2\\2\\u01eb\")\n-        buf.write(u\"\\u01ec\\7i\\2\\2\\u01ec\\u01ed\\7j\\2\\2\\u01ed\\u01ee\\7v\\2\\2\\u01ee\")\n-        buf.write(u\"\\u01ef\\7c\\2\\2\\u01ef\\u01f0\\7t\\2\\2\\u01f0\\u01f1\\7t\\2\\2\\u01f1\")\n-        buf.write(u\"\\u01f2\\7q\\2\\2\\u01f2\\u01f4\\7y\\2\\2\\u01f3\\u01bc\\3\\2\\2\\2\")\n-        buf.write(u\"\\u01f3\\u01bf\\3\\2\\2\\2\\u01f3\\u01ca\\3\\2\\2\\2\\u01f3\\u01d5\")\n-        buf.write(u\"\\3\\2\\2\\2\\u01f3\\u01e4\\3\\2\\2\\2\\u01f4B\\3\\2\\2\\2\\u01f5\\u01f6\")\n-        buf.write(u\"\\7^\\2\\2\\u01f6\\u01f7\\7k\\2\\2\\u01f7\\u01f8\\7p\\2\\2\\u01f8\\u01f9\")\n-        buf.write(u\"\\7v\\2\\2\\u01f9D\\3\\2\\2\\2\\u01fa\\u01fb\\7^\\2\\2\\u01fb\\u01fc\")\n-        buf.write(u\"\\7u\\2\\2\\u01fc\\u01fd\\7w\\2\\2\\u01fd\\u01fe\\7o\\2\\2\\u01feF\")\n-        buf.write(u\"\\3\\2\\2\\2\\u01ff\\u0200\\7^\\2\\2\\u0200\\u0201\\7r\\2\\2\\u0201\")\n-        buf.write(u\"\\u0202\\7t\\2\\2\\u0202\\u0203\\7q\\2\\2\\u0203\\u0204\\7f\\2\\2\\u0204\")\n-        buf.write(u\"H\\3\\2\\2\\2\\u0205\\u0206\\7^\\2\\2\\u0206\\u0207\\7g\\2\\2\\u0207\")\n-        buf.write(u\"\\u0208\\7z\\2\\2\\u0208\\u0209\\7r\\2\\2\\u0209J\\3\\2\\2\\2\\u020a\")\n-        buf.write(u\"\\u020b\\7^\\2\\2\\u020b\\u020c\\7n\\2\\2\\u020c\\u020d\\7q\\2\\2\\u020d\")\n-        buf.write(u\"\\u020e\\7i\\2\\2\\u020eL\\3\\2\\2\\2\\u020f\\u0210\\7^\\2\\2\\u0210\")\n-        buf.write(u\"\\u0211\\7n\\2\\2\\u0211\\u0212\\7p\\2\\2\\u0212N\\3\\2\\2\\2\\u0213\")\n-        buf.write(u\"\\u0214\\7^\\2\\2\\u0214\\u0215\\7u\\2\\2\\u0215\\u0216\\7k\\2\\2\\u0216\")\n-        buf.write(u\"\\u0217\\7p\\2\\2\\u0217P\\3\\2\\2\\2\\u0218\\u0219\\7^\\2\\2\\u0219\")\n-        buf.write(u\"\\u021a\\7e\\2\\2\\u021a\\u021b\\7q\\2\\2\\u021b\\u021c\\7u\\2\\2\\u021c\")\n-        buf.write(u\"R\\3\\2\\2\\2\\u021d\\u021e\\7^\\2\\2\\u021e\\u021f\\7v\\2\\2\\u021f\")\n-        buf.write(u\"\\u0220\\7c\\2\\2\\u0220\\u0221\\7p\\2\\2\\u0221T\\3\\2\\2\\2\\u0222\")\n-        buf.write(u\"\\u0223\\7^\\2\\2\\u0223\\u0224\\7e\\2\\2\\u0224\\u0225\\7u\\2\\2\\u0225\")\n-        buf.write(u\"\\u0226\\7e\\2\\2\\u0226V\\3\\2\\2\\2\\u0227\\u0228\\7^\\2\\2\\u0228\")\n-        buf.write(u\"\\u0229\\7u\\2\\2\\u0229\\u022a\\7g\\2\\2\\u022a\\u022b\\7e\\2\\2\\u022b\")\n-        buf.write(u\"X\\3\\2\\2\\2\\u022c\\u022d\\7^\\2\\2\\u022d\\u022e\\7e\\2\\2\\u022e\")\n-        buf.write(u\"\\u022f\\7q\\2\\2\\u022f\\u0230\\7v\\2\\2\\u0230Z\\3\\2\\2\\2\\u0231\")\n-        buf.write(u\"\\u0232\\7^\\2\\2\\u0232\\u0233\\7c\\2\\2\\u0233\\u0234\\7t\\2\\2\\u0234\")\n-        buf.write(u\"\\u0235\\7e\\2\\2\\u0235\\u0236\\7u\\2\\2\\u0236\\u0237\\7k\\2\\2\\u0237\")\n-        buf.write(u\"\\u0238\\7p\\2\\2\\u0238\\\\\\3\\2\\2\\2\\u0239\\u023a\\7^\\2\\2\\u023a\")\n-        buf.write(u\"\\u023b\\7c\\2\\2\\u023b\\u023c\\7t\\2\\2\\u023c\\u023d\\7e\\2\\2\\u023d\")\n-        buf.write(u\"\\u023e\\7e\\2\\2\\u023e\\u023f\\7q\\2\\2\\u023f\\u0240\\7u\\2\\2\\u0240\")\n-        buf.write(u\"^\\3\\2\\2\\2\\u0241\\u0242\\7^\\2\\2\\u0242\\u0243\\7c\\2\\2\\u0243\")\n-        buf.write(u\"\\u0244\\7t\\2\\2\\u0244\\u0245\\7e\\2\\2\\u0245\\u0246\\7v\\2\\2\\u0246\")\n-        buf.write(u\"\\u0247\\7c\\2\\2\\u0247\\u0248\\7p\\2\\2\\u0248`\\3\\2\\2\\2\\u0249\")\n-        buf.write(u\"\\u024a\\7^\\2\\2\\u024a\\u024b\\7c\\2\\2\\u024b\\u024c\\7t\\2\\2\\u024c\")\n-        buf.write(u\"\\u024d\\7e\\2\\2\\u024d\\u024e\\7e\\2\\2\\u024e\\u024f\\7u\\2\\2\\u024f\")\n-        buf.write(u\"\\u0250\\7e\\2\\2\\u0250b\\3\\2\\2\\2\\u0251\\u0252\\7^\\2\\2\\u0252\")\n-        buf.write(u\"\\u0253\\7c\\2\\2\\u0253\\u0254\\7t\\2\\2\\u0254\\u0255\\7e\\2\\2\\u0255\")\n-        buf.write(u\"\\u0256\\7u\\2\\2\\u0256\\u0257\\7g\\2\\2\\u0257\\u0258\\7e\\2\\2\\u0258\")\n-        buf.write(u\"d\\3\\2\\2\\2\\u0259\\u025a\\7^\\2\\2\\u025a\\u025b\\7c\\2\\2\\u025b\")\n-        buf.write(u\"\\u025c\\7t\\2\\2\\u025c\\u025d\\7e\\2\\2\\u025d\\u025e\\7e\\2\\2\\u025e\")\n-        buf.write(u\"\\u025f\\7q\\2\\2\\u025f\\u0260\\7v\\2\\2\\u0260f\\3\\2\\2\\2\\u0261\")\n-        buf.write(u\"\\u0262\\7^\\2\\2\\u0262\\u0263\\7u\\2\\2\\u0263\\u0264\\7k\\2\\2\\u0264\")\n-        buf.write(u\"\\u0265\\7p\\2\\2\\u0265\\u0266\\7j\\2\\2\\u0266h\\3\\2\\2\\2\\u0267\")\n-        buf.write(u\"\\u0268\\7^\\2\\2\\u0268\\u0269\\7e\\2\\2\\u0269\\u026a\\7q\\2\\2\\u026a\")\n-        buf.write(u\"\\u026b\\7u\\2\\2\\u026b\\u026c\\7j\\2\\2\\u026cj\\3\\2\\2\\2\\u026d\")\n-        buf.write(u\"\\u026e\\7^\\2\\2\\u026e\\u026f\\7v\\2\\2\\u026f\\u0270\\7c\\2\\2\\u0270\")\n-        buf.write(u\"\\u0271\\7p\\2\\2\\u0271\\u0272\\7j\\2\\2\\u0272l\\3\\2\\2\\2\\u0273\")\n-        buf.write(u\"\\u0274\\7^\\2\\2\\u0274\\u0275\\7c\\2\\2\\u0275\\u0276\\7t\\2\\2\\u0276\")\n-        buf.write(u\"\\u0277\\7u\\2\\2\\u0277\\u0278\\7k\\2\\2\\u0278\\u0279\\7p\\2\\2\\u0279\")\n-        buf.write(u\"\\u027a\\7j\\2\\2\\u027an\\3\\2\\2\\2\\u027b\\u027c\\7^\\2\\2\\u027c\")\n-        buf.write(u\"\\u027d\\7c\\2\\2\\u027d\\u027e\\7t\\2\\2\\u027e\\u027f\\7e\\2\\2\\u027f\")\n-        buf.write(u\"\\u0280\\7q\\2\\2\\u0280\\u0281\\7u\\2\\2\\u0281\\u0282\\7j\\2\\2\\u0282\")\n-        buf.write(u\"p\\3\\2\\2\\2\\u0283\\u0284\\7^\\2\\2\\u0284\\u0285\\7c\\2\\2\\u0285\")\n-        buf.write(u\"\\u0286\\7t\\2\\2\\u0286\\u0287\\7v\\2\\2\\u0287\\u0288\\7c\\2\\2\\u0288\")\n-        buf.write(u\"\\u0289\\7p\\2\\2\\u0289\\u028a\\7j\\2\\2\\u028ar\\3\\2\\2\\2\\u028b\")\n-        buf.write(u\"\\u028c\\7^\\2\\2\\u028c\\u028d\\7n\\2\\2\\u028d\\u028e\\7h\\2\\2\\u028e\")\n-        buf.write(u\"\\u028f\\7n\\2\\2\\u028f\\u0290\\7q\\2\\2\\u0290\\u0291\\7q\\2\\2\\u0291\")\n-        buf.write(u\"\\u0292\\7t\\2\\2\\u0292t\\3\\2\\2\\2\\u0293\\u0294\\7^\\2\\2\\u0294\")\n-        buf.write(u\"\\u0295\\7t\\2\\2\\u0295\\u0296\\7h\\2\\2\\u0296\\u0297\\7n\\2\\2\\u0297\")\n-        buf.write(u\"\\u0298\\7q\\2\\2\\u0298\\u0299\\7q\\2\\2\\u0299\\u029a\\7t\\2\\2\\u029a\")\n-        buf.write(u\"v\\3\\2\\2\\2\\u029b\\u029c\\7^\\2\\2\\u029c\\u029d\\7n\\2\\2\\u029d\")\n-        buf.write(u\"\\u029e\\7e\\2\\2\\u029e\\u029f\\7g\\2\\2\\u029f\\u02a0\\7k\\2\\2\\u02a0\")\n-        buf.write(u\"\\u02a1\\7n\\2\\2\\u02a1x\\3\\2\\2\\2\\u02a2\\u02a3\\7^\\2\\2\\u02a3\")\n-        buf.write(u\"\\u02a4\\7t\\2\\2\\u02a4\\u02a5\\7e\\2\\2\\u02a5\\u02a6\\7g\\2\\2\\u02a6\")\n-        buf.write(u\"\\u02a7\\7k\\2\\2\\u02a7\\u02a8\\7n\\2\\2\\u02a8z\\3\\2\\2\\2\\u02a9\")\n-        buf.write(u\"\\u02aa\\7^\\2\\2\\u02aa\\u02ab\\7u\\2\\2\\u02ab\\u02ac\\7s\\2\\2\\u02ac\")\n-        buf.write(u\"\\u02ad\\7t\\2\\2\\u02ad\\u02ae\\7v\\2\\2\\u02ae|\\3\\2\\2\\2\\u02af\")\n-        buf.write(u\"\\u02b0\\7^\\2\\2\\u02b0\\u02b1\\7q\\2\\2\\u02b1\\u02b2\\7x\\2\\2\\u02b2\")\n-        buf.write(u\"\\u02b3\\7g\\2\\2\\u02b3\\u02b4\\7t\\2\\2\\u02b4\\u02b5\\7n\\2\\2\\u02b5\")\n-        buf.write(u\"\\u02b6\\7k\\2\\2\\u02b6\\u02b7\\7p\\2\\2\\u02b7\\u02b8\\7g\\2\\2\\u02b8\")\n-        buf.write(u\"~\\3\\2\\2\\2\\u02b9\\u02ba\\7^\\2\\2\\u02ba\\u02bb\\7v\\2\\2\\u02bb\")\n-        buf.write(u\"\\u02bc\\7k\\2\\2\\u02bc\\u02bd\\7o\\2\\2\\u02bd\\u02be\\7g\\2\\2\\u02be\")\n-        buf.write(u\"\\u02bf\\7u\\2\\2\\u02bf\\u0080\\3\\2\\2\\2\\u02c0\\u02c1\\7^\\2\\2\")\n-        buf.write(u\"\\u02c1\\u02c2\\7e\\2\\2\\u02c2\\u02c3\\7f\\2\\2\\u02c3\\u02c4\\7\")\n-        buf.write(u\"q\\2\\2\\u02c4\\u02c5\\7v\\2\\2\\u02c5\\u0082\\3\\2\\2\\2\\u02c6\\u02c7\")\n-        buf.write(u\"\\7^\\2\\2\\u02c7\\u02c8\\7f\\2\\2\\u02c8\\u02c9\\7k\\2\\2\\u02c9\\u02ca\")\n-        buf.write(u\"\\7x\\2\\2\\u02ca\\u0084\\3\\2\\2\\2\\u02cb\\u02cc\\7^\\2\\2\\u02cc\")\n-        buf.write(u\"\\u02cd\\7h\\2\\2\\u02cd\\u02ce\\7t\\2\\2\\u02ce\\u02cf\\7c\\2\\2\\u02cf\")\n-        buf.write(u\"\\u02d0\\7e\\2\\2\\u02d0\\u0086\\3\\2\\2\\2\\u02d1\\u02d2\\7^\\2\\2\")\n-        buf.write(u\"\\u02d2\\u02d3\\7d\\2\\2\\u02d3\\u02d4\\7k\\2\\2\\u02d4\\u02d5\\7\")\n-        buf.write(u\"p\\2\\2\\u02d5\\u02d6\\7q\\2\\2\\u02d6\\u02d7\\7o\\2\\2\\u02d7\\u0088\")\n-        buf.write(u\"\\3\\2\\2\\2\\u02d8\\u02d9\\7^\\2\\2\\u02d9\\u02da\\7f\\2\\2\\u02da\")\n-        buf.write(u\"\\u02db\\7d\\2\\2\\u02db\\u02dc\\7k\\2\\2\\u02dc\\u02dd\\7p\\2\\2\\u02dd\")\n-        buf.write(u\"\\u02de\\7q\\2\\2\\u02de\\u02df\\7o\\2\\2\\u02df\\u008a\\3\\2\\2\\2\")\n-        buf.write(u\"\\u02e0\\u02e1\\7^\\2\\2\\u02e1\\u02e2\\7v\\2\\2\\u02e2\\u02e3\\7\")\n-        buf.write(u\"d\\2\\2\\u02e3\\u02e4\\7k\\2\\2\\u02e4\\u02e5\\7p\\2\\2\\u02e5\\u02e6\")\n-        buf.write(u\"\\7q\\2\\2\\u02e6\\u02e7\\7o\\2\\2\\u02e7\\u008c\\3\\2\\2\\2\\u02e8\")\n-        buf.write(u\"\\u02e9\\7^\\2\\2\\u02e9\\u02ea\\7o\\2\\2\\u02ea\\u02eb\\7c\\2\\2\\u02eb\")\n-        buf.write(u\"\\u02ec\\7v\\2\\2\\u02ec\\u02ed\\7j\\2\\2\\u02ed\\u02ee\\7k\\2\\2\\u02ee\")\n-        buf.write(u\"\\u02ef\\7v\\2\\2\\u02ef\\u008e\\3\\2\\2\\2\\u02f0\\u02f1\\7a\\2\\2\")\n-        buf.write(u\"\\u02f1\\u0090\\3\\2\\2\\2\\u02f2\\u02f3\\7`\\2\\2\\u02f3\\u0092\\3\")\n-        buf.write(u\"\\2\\2\\2\\u02f4\\u02f5\\7<\\2\\2\\u02f5\\u0094\\3\\2\\2\\2\\u02f6\\u02f7\")\n-        buf.write(u\"\\t\\2\\2\\2\\u02f7\\u0096\\3\\2\\2\\2\\u02f8\\u02fc\\7f\\2\\2\\u02f9\")\n-        buf.write(u\"\\u02fb\\5\\u0095K\\2\\u02fa\\u02f9\\3\\2\\2\\2\\u02fb\\u02fe\\3\\2\")\n-        buf.write(u\"\\2\\2\\u02fc\\u02fd\\3\\2\\2\\2\\u02fc\\u02fa\\3\\2\\2\\2\\u02fd\\u0306\")\n-        buf.write(u\"\\3\\2\\2\\2\\u02fe\\u02fc\\3\\2\\2\\2\\u02ff\\u0307\\t\\3\\2\\2\\u0300\")\n-        buf.write(u\"\\u0302\\7^\\2\\2\\u0301\\u0303\\t\\3\\2\\2\\u0302\\u0301\\3\\2\\2\\2\")\n-        buf.write(u\"\\u0303\\u0304\\3\\2\\2\\2\\u0304\\u0302\\3\\2\\2\\2\\u0304\\u0305\")\n-        buf.write(u\"\\3\\2\\2\\2\\u0305\\u0307\\3\\2\\2\\2\\u0306\\u02ff\\3\\2\\2\\2\\u0306\")\n-        buf.write(u\"\\u0300\\3\\2\\2\\2\\u0307\\u0098\\3\\2\\2\\2\\u0308\\u0309\\t\\3\\2\")\n-        buf.write(u\"\\2\\u0309\\u009a\\3\\2\\2\\2\\u030a\\u030b\\t\\4\\2\\2\\u030b\\u009c\")\n-        buf.write(u\"\\3\\2\\2\\2\\u030c\\u030e\\5\\u009bN\\2\\u030d\\u030c\\3\\2\\2\\2\\u030e\")\n-        buf.write(u\"\\u030f\\3\\2\\2\\2\\u030f\\u030d\\3\\2\\2\\2\\u030f\\u0310\\3\\2\\2\")\n-        buf.write(u\"\\2\\u0310\\u0318\\3\\2\\2\\2\\u0311\\u0312\\7.\\2\\2\\u0312\\u0313\")\n-        buf.write(u\"\\5\\u009bN\\2\\u0313\\u0314\\5\\u009bN\\2\\u0314\\u0315\\5\\u009b\")\n-        buf.write(u\"N\\2\\u0315\\u0317\\3\\2\\2\\2\\u0316\\u0311\\3\\2\\2\\2\\u0317\\u031a\")\n-        buf.write(u\"\\3\\2\\2\\2\\u0318\\u0316\\3\\2\\2\\2\\u0318\\u0319\\3\\2\\2\\2\\u0319\")\n-        buf.write(u\"\\u0332\\3\\2\\2\\2\\u031a\\u0318\\3\\2\\2\\2\\u031b\\u031d\\5\\u009b\")\n-        buf.write(u\"N\\2\\u031c\\u031b\\3\\2\\2\\2\\u031d\\u0320\\3\\2\\2\\2\\u031e\\u031c\")\n-        buf.write(u\"\\3\\2\\2\\2\\u031e\\u031f\\3\\2\\2\\2\\u031f\\u0328\\3\\2\\2\\2\\u0320\")\n-        buf.write(u\"\\u031e\\3\\2\\2\\2\\u0321\\u0322\\7.\\2\\2\\u0322\\u0323\\5\\u009b\")\n-        buf.write(u\"N\\2\\u0323\\u0324\\5\\u009bN\\2\\u0324\\u0325\\5\\u009bN\\2\\u0325\")\n-        buf.write(u\"\\u0327\\3\\2\\2\\2\\u0326\\u0321\\3\\2\\2\\2\\u0327\\u032a\\3\\2\\2\")\n-        buf.write(u\"\\2\\u0328\\u0326\\3\\2\\2\\2\\u0328\\u0329\\3\\2\\2\\2\\u0329\\u032b\")\n-        buf.write(u\"\\3\\2\\2\\2\\u032a\\u0328\\3\\2\\2\\2\\u032b\\u032d\\7\\60\\2\\2\\u032c\")\n-        buf.write(u\"\\u032e\\5\\u009bN\\2\\u032d\\u032c\\3\\2\\2\\2\\u032e\\u032f\\3\\2\")\n-        buf.write(u\"\\2\\2\\u032f\\u032d\\3\\2\\2\\2\\u032f\\u0330\\3\\2\\2\\2\\u0330\\u0332\")\n-        buf.write(u\"\\3\\2\\2\\2\\u0331\\u030d\\3\\2\\2\\2\\u0331\\u031e\\3\\2\\2\\2\\u0332\")\n-        buf.write(u\"\\u009e\\3\\2\\2\\2\\u0333\\u0337\\7(\\2\\2\\u0334\\u0336\\5\\u0095\")\n-        buf.write(u\"K\\2\\u0335\\u0334\\3\\2\\2\\2\\u0336\\u0339\\3\\2\\2\\2\\u0337\\u0338\")\n-        buf.write(u\"\\3\\2\\2\\2\\u0337\\u0335\\3\\2\\2\\2\\u0338\\u033b\\3\\2\\2\\2\\u0339\")\n-        buf.write(u\"\\u0337\\3\\2\\2\\2\\u033a\\u0333\\3\\2\\2\\2\\u033a\\u033b\\3\\2\\2\")\n-        buf.write(u\"\\2\\u033b\\u033c\\3\\2\\2\\2\\u033c\\u0348\\7?\\2\\2\\u033d\\u0345\")\n-        buf.write(u\"\\7?\\2\\2\\u033e\\u0340\\5\\u0095K\\2\\u033f\\u033e\\3\\2\\2\\2\\u0340\")\n-        buf.write(u\"\\u0343\\3\\2\\2\\2\\u0341\\u0342\\3\\2\\2\\2\\u0341\\u033f\\3\\2\\2\")\n-        buf.write(u\"\\2\\u0342\\u0344\\3\\2\\2\\2\\u0343\\u0341\\3\\2\\2\\2\\u0344\\u0346\")\n-        buf.write(u\"\\7(\\2\\2\\u0345\\u0341\\3\\2\\2\\2\\u0345\\u0346\\3\\2\\2\\2\\u0346\")\n-        buf.write(u\"\\u0348\\3\\2\\2\\2\\u0347\\u033a\\3\\2\\2\\2\\u0347\\u033d\\3\\2\\2\")\n-        buf.write(u\"\\2\\u0348\\u00a0\\3\\2\\2\\2\\u0349\\u034a\\7^\\2\\2\\u034a\\u034b\")\n-        buf.write(u\"\\7p\\2\\2\\u034b\\u034c\\7g\\2\\2\\u034c\\u034d\\7s\\2\\2\\u034d\\u00a2\")\n-        buf.write(u\"\\3\\2\\2\\2\\u034e\\u034f\\7>\\2\\2\\u034f\\u00a4\\3\\2\\2\\2\\u0350\")\n-        buf.write(u\"\\u0351\\7^\\2\\2\\u0351\\u0352\\7n\\2\\2\\u0352\\u0353\\7g\\2\\2\\u0353\")\n-        buf.write(u\"\\u035a\\7s\\2\\2\\u0354\\u0355\\7^\\2\\2\\u0355\\u0356\\7n\\2\\2\\u0356\")\n-        buf.write(u\"\\u035a\\7g\\2\\2\\u0357\\u035a\\5\\u00a7T\\2\\u0358\\u035a\\5\\u00a9\")\n-        buf.write(u\"U\\2\\u0359\\u0350\\3\\2\\2\\2\\u0359\\u0354\\3\\2\\2\\2\\u0359\\u0357\")\n-        buf.write(u\"\\3\\2\\2\\2\\u0359\\u0358\\3\\2\\2\\2\\u035a\\u00a6\\3\\2\\2\\2\\u035b\")\n-        buf.write(u\"\\u035c\\7^\\2\\2\\u035c\\u035d\\7n\\2\\2\\u035d\\u035e\\7g\\2\\2\\u035e\")\n-        buf.write(u\"\\u035f\\7s\\2\\2\\u035f\\u0360\\7s\\2\\2\\u0360\\u00a8\\3\\2\\2\\2\")\n-        buf.write(u\"\\u0361\\u0362\\7^\\2\\2\\u0362\\u0363\\7n\\2\\2\\u0363\\u0364\\7\")\n-        buf.write(u\"g\\2\\2\\u0364\\u0365\\7s\\2\\2\\u0365\\u0366\\7u\\2\\2\\u0366\\u0367\")\n-        buf.write(u\"\\7n\\2\\2\\u0367\\u0368\\7c\\2\\2\\u0368\\u0369\\7p\\2\\2\\u0369\\u036a\")\n-        buf.write(u\"\\7v\\2\\2\\u036a\\u00aa\\3\\2\\2\\2\\u036b\\u036c\\7@\\2\\2\\u036c\")\n-        buf.write(u\"\\u00ac\\3\\2\\2\\2\\u036d\\u036e\\7^\\2\\2\\u036e\\u036f\\7i\\2\\2\")\n-        buf.write(u\"\\u036f\\u0370\\7g\\2\\2\\u0370\\u0377\\7s\\2\\2\\u0371\\u0372\\7\")\n-        buf.write(u\"^\\2\\2\\u0372\\u0373\\7i\\2\\2\\u0373\\u0377\\7g\\2\\2\\u0374\\u0377\")\n-        buf.write(u\"\\5\\u00afX\\2\\u0375\\u0377\\5\\u00b1Y\\2\\u0376\\u036d\\3\\2\\2\")\n-        buf.write(u\"\\2\\u0376\\u0371\\3\\2\\2\\2\\u0376\\u0374\\3\\2\\2\\2\\u0376\\u0375\")\n-        buf.write(u\"\\3\\2\\2\\2\\u0377\\u00ae\\3\\2\\2\\2\\u0378\\u0379\\7^\\2\\2\\u0379\")\n-        buf.write(u\"\\u037a\\7i\\2\\2\\u037a\\u037b\\7g\\2\\2\\u037b\\u037c\\7s\\2\\2\\u037c\")\n-        buf.write(u\"\\u037d\\7s\\2\\2\\u037d\\u00b0\\3\\2\\2\\2\\u037e\\u037f\\7^\\2\\2\")\n-        buf.write(u\"\\u037f\\u0380\\7i\\2\\2\\u0380\\u0381\\7g\\2\\2\\u0381\\u0382\\7\")\n-        buf.write(u\"s\\2\\2\\u0382\\u0383\\7u\\2\\2\\u0383\\u0384\\7n\\2\\2\\u0384\\u0385\")\n-        buf.write(u\"\\7c\\2\\2\\u0385\\u0386\\7p\\2\\2\\u0386\\u0387\\7v\\2\\2\\u0387\\u00b2\")\n-        buf.write(u\"\\3\\2\\2\\2\\u0388\\u0389\\7#\\2\\2\\u0389\\u00b4\\3\\2\\2\\2\\u038a\")\n-        buf.write(u\"\\u038c\\7^\\2\\2\\u038b\\u038d\\t\\3\\2\\2\\u038c\\u038b\\3\\2\\2\\2\")\n-        buf.write(u\"\\u038d\\u038e\\3\\2\\2\\2\\u038e\\u038c\\3\\2\\2\\2\\u038e\\u038f\")\n-        buf.write(u\"\\3\\2\\2\\2\\u038f\\u00b6\\3\\2\\2\\2\\33\\2\\u00bc\\u00cc\\u00db\\u00ec\")\n-        buf.write(u\"\\u0110\\u0178\\u01f3\\u02fc\\u0304\\u0306\\u030f\\u0318\\u031e\")\n-        buf.write(u\"\\u0328\\u032f\\u0331\\u0337\\u033a\\u0341\\u0345\\u0347\\u0359\")\n-        buf.write(u\"\\u0376\\u038e\\3\\b\\2\\2\")\n-        return buf.getvalue()\n-\n+    return [\n+        4,0,88,910,6,-1,2,0,7,0,2,1,7,1,2,2,7,2,2,3,7,3,2,4,7,4,2,5,7,5,\n+        2,6,7,6,2,7,7,7,2,8,7,8,2,9,7,9,2,10,7,10,2,11,7,11,2,12,7,12,2,\n+        13,7,13,2,14,7,14,2,15,7,15,2,16,7,16,2,17,7,17,2,18,7,18,2,19,7,\n+        19,2,20,7,20,2,21,7,21,2,22,7,22,2,23,7,23,2,24,7,24,2,25,7,25,2,\n+        26,7,26,2,27,7,27,2,28,7,28,2,29,7,29,2,30,7,30,2,31,7,31,2,32,7,\n+        32,2,33,7,33,2,34,7,34,2,35,7,35,2,36,7,36,2,37,7,37,2,38,7,38,2,\n+        39,7,39,2,40,7,40,2,41,7,41,2,42,7,42,2,43,7,43,2,44,7,44,2,45,7,\n+        45,2,46,7,46,2,47,7,47,2,48,7,48,2,49,7,49,2,50,7,50,2,51,7,51,2,\n+        52,7,52,2,53,7,53,2,54,7,54,2,55,7,55,2,56,7,56,2,57,7,57,2,58,7,\n+        58,2,59,7,59,2,60,7,60,2,61,7,61,2,62,7,62,2,63,7,63,2,64,7,64,2,\n+        65,7,65,2,66,7,66,2,67,7,67,2,68,7,68,2,69,7,69,2,70,7,70,2,71,7,\n+        71,2,72,7,72,2,73,7,73,2,74,7,74,2,75,7,75,2,76,7,76,2,77,7,77,2,\n+        78,7,78,2,79,7,79,2,80,7,80,2,81,7,81,2,82,7,82,2,83,7,83,2,84,7,\n+        84,2,85,7,85,2,86,7,86,2,87,7,87,2,88,7,88,2,89,7,89,1,0,1,0,1,1,\n+        4,1,185,8,1,11,1,12,1,186,1,1,1,1,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,\n+        2,1,2,1,2,1,2,1,2,3,2,203,8,2,1,2,1,2,1,3,1,3,1,3,1,3,1,3,1,3,1,\n+        3,1,3,1,3,1,3,1,3,3,3,218,8,3,1,3,1,3,1,4,1,4,1,4,1,4,1,4,1,4,1,\n+        4,1,4,1,4,1,4,1,4,1,4,1,4,3,4,235,8,4,1,4,1,4,1,5,1,5,1,5,1,5,1,\n+        5,1,5,1,5,1,5,1,6,1,6,1,6,1,6,1,6,1,6,1,6,1,6,1,6,1,7,1,7,1,7,1,\n+        7,1,7,1,7,1,7,1,7,1,7,1,7,1,7,1,7,1,7,1,7,1,7,3,7,271,8,7,1,7,1,\n+        7,1,8,1,8,1,8,1,8,1,8,1,8,1,8,1,8,1,8,1,8,1,8,1,8,1,8,1,8,1,8,1,\n+        9,1,9,1,9,1,9,1,9,1,9,1,9,1,9,1,9,1,9,1,9,1,9,1,9,1,9,1,9,1,9,1,\n+        9,1,10,1,10,1,10,1,10,1,10,1,10,1,10,1,10,1,11,1,11,1,11,1,11,1,\n+        11,1,11,1,11,1,11,1,11,1,12,1,12,1,12,1,12,1,12,1,12,1,12,1,12,1,\n+        12,1,12,1,12,1,12,1,12,1,12,1,12,1,12,1,12,1,12,1,12,1,12,1,12,1,\n+        12,1,12,1,12,1,12,1,12,1,12,1,12,1,12,1,12,1,12,1,12,1,12,1,12,1,\n+        12,1,12,1,12,1,12,1,12,1,12,1,12,1,12,1,12,1,12,1,12,1,12,1,12,1,\n+        12,1,12,1,12,1,12,3,12,375,8,12,1,12,1,12,1,13,1,13,1,14,1,14,1,\n+        15,1,15,1,16,1,16,1,17,1,17,1,18,1,18,1,19,1,19,1,20,1,20,1,21,1,\n+        21,1,21,1,22,1,22,1,22,1,23,1,23,1,24,1,24,1,25,1,25,1,26,1,26,1,\n+        26,1,26,1,26,1,26,1,26,1,26,1,27,1,27,1,27,1,27,1,27,1,27,1,27,1,\n+        28,1,28,1,28,1,28,1,28,1,28,1,28,1,28,1,29,1,29,1,29,1,29,1,29,1,\n+        29,1,29,1,29,1,30,1,30,1,30,1,30,1,30,1,31,1,31,1,31,1,31,1,31,1,\n+        31,1,31,1,31,1,31,1,31,1,31,1,31,1,31,1,31,1,31,1,31,1,31,1,31,1,\n+        31,1,31,1,31,1,31,1,31,1,31,1,31,1,31,1,31,1,31,1,31,1,31,1,31,1,\n+        31,1,31,1,31,1,31,1,31,1,31,1,31,1,31,1,31,1,31,1,31,1,31,1,31,1,\n+        31,1,31,1,31,1,31,1,31,1,31,1,31,1,31,1,31,1,31,1,31,3,31,498,8,\n+        31,1,32,1,32,1,32,1,32,1,32,1,33,1,33,1,33,1,33,1,33,1,34,1,34,1,\n+        34,1,34,1,34,1,34,1,35,1,35,1,35,1,35,1,35,1,36,1,36,1,36,1,36,1,\n+        36,1,37,1,37,1,37,1,37,1,38,1,38,1,38,1,38,1,38,1,39,1,39,1,39,1,\n+        39,1,39,1,40,1,40,1,40,1,40,1,40,1,41,1,41,1,41,1,41,1,41,1,42,1,\n+        42,1,42,1,42,1,42,1,43,1,43,1,43,1,43,1,43,1,44,1,44,1,44,1,44,1,\n+        44,1,44,1,44,1,44,1,45,1,45,1,45,1,45,1,45,1,45,1,45,1,45,1,46,1,\n+        46,1,46,1,46,1,46,1,46,1,46,1,46,1,47,1,47,1,47,1,47,1,47,1,47,1,\n+        47,1,47,1,48,1,48,1,48,1,48,1,48,1,48,1,48,1,48,1,49,1,49,1,49,1,\n+        49,1,49,1,49,1,49,1,49,1,50,1,50,1,50,1,50,1,50,1,50,1,51,1,51,1,\n+        51,1,51,1,51,1,51,1,52,1,52,1,52,1,52,1,52,1,52,1,53,1,53,1,53,1,\n+        53,1,53,1,53,1,53,1,53,1,54,1,54,1,54,1,54,1,54,1,54,1,54,1,54,1,\n+        55,1,55,1,55,1,55,1,55,1,55,1,55,1,55,1,56,1,56,1,56,1,56,1,56,1,\n+        56,1,56,1,56,1,57,1,57,1,57,1,57,1,57,1,57,1,57,1,57,1,58,1,58,1,\n+        58,1,58,1,58,1,58,1,58,1,59,1,59,1,59,1,59,1,59,1,59,1,59,1,60,1,\n+        60,1,60,1,60,1,60,1,60,1,61,1,61,1,61,1,61,1,61,1,61,1,61,1,61,1,\n+        61,1,61,1,62,1,62,1,62,1,62,1,62,1,62,1,62,1,63,1,63,1,63,1,63,1,\n+        63,1,63,1,64,1,64,1,64,1,64,1,64,1,65,1,65,1,65,1,65,1,65,1,65,1,\n+        66,1,66,1,66,1,66,1,66,1,66,1,66,1,67,1,67,1,67,1,67,1,67,1,67,1,\n+        67,1,67,1,68,1,68,1,68,1,68,1,68,1,68,1,68,1,68,1,69,1,69,1,69,1,\n+        69,1,69,1,69,1,69,1,69,1,70,1,70,1,71,1,71,1,72,1,72,1,73,1,73,1,\n+        74,1,74,5,74,761,8,74,10,74,12,74,764,9,74,1,74,1,74,1,74,4,74,769,\n+        8,74,11,74,12,74,770,3,74,773,8,74,1,75,1,75,1,76,1,76,1,77,4,77,\n+        780,8,77,11,77,12,77,781,1,77,1,77,1,77,1,77,1,77,5,77,789,8,77,\n+        10,77,12,77,792,9,77,1,77,5,77,795,8,77,10,77,12,77,798,9,77,1,77,\n+        1,77,1,77,1,77,1,77,5,77,805,8,77,10,77,12,77,808,9,77,1,77,1,77,\n+        4,77,812,8,77,11,77,12,77,813,3,77,816,8,77,1,78,1,78,5,78,820,8,\n+        78,10,78,12,78,823,9,78,3,78,825,8,78,1,78,1,78,1,78,5,78,830,8,\n+        78,10,78,12,78,833,9,78,1,78,3,78,836,8,78,3,78,838,8,78,1,79,1,\n+        79,1,79,1,79,1,79,1,80,1,80,1,81,1,81,1,81,1,81,1,81,1,81,1,81,1,\n+        81,1,81,3,81,856,8,81,1,82,1,82,1,82,1,82,1,82,1,82,1,83,1,83,1,\n+        83,1,83,1,83,1,83,1,83,1,83,1,83,1,83,1,84,1,84,1,85,1,85,1,85,1,\n+        85,1,85,1,85,1,85,1,85,1,85,3,85,885,8,85,1,86,1,86,1,86,1,86,1,\n+        86,1,86,1,87,1,87,1,87,1,87,1,87,1,87,1,87,1,87,1,87,1,87,1,88,1,\n+        88,1,89,1,89,4,89,907,8,89,11,89,12,89,908,3,762,821,831,0,90,1,\n+        1,3,2,5,3,7,4,9,5,11,6,13,7,15,8,17,9,19,10,21,11,23,12,25,13,27,\n+        14,29,15,31,16,33,17,35,18,37,19,39,20,41,21,43,22,45,23,47,24,49,\n+        25,51,26,53,27,55,28,57,29,59,30,61,31,63,32,65,33,67,34,69,35,71,\n+        36,73,37,75,38,77,39,79,40,81,41,83,42,85,43,87,44,89,45,91,46,93,\n+        47,95,48,97,49,99,50,101,51,103,52,105,53,107,54,109,55,111,56,113,\n+        57,115,58,117,59,119,60,121,61,123,62,125,63,127,64,129,65,131,66,\n+        133,67,135,68,137,69,139,70,141,71,143,72,145,73,147,0,149,74,151,\n+        75,153,0,155,76,157,77,159,78,161,79,163,80,165,81,167,82,169,83,\n+        171,84,173,85,175,86,177,87,179,88,1,0,3,3,0,9,10,13,13,32,32,2,\n+        0,65,90,97,122,1,0,48,57,949,0,1,1,0,0,0,0,3,1,0,0,0,0,5,1,0,0,0,\n+        0,7,1,0,0,0,0,9,1,0,0,0,0,11,1,0,0,0,0,13,1,0,0,0,0,15,1,0,0,0,0,\n+        17,1,0,0,0,0,19,1,0,0,0,0,21,1,0,0,0,0,23,1,0,0,0,0,25,1,0,0,0,0,\n+        27,1,0,0,0,0,29,1,0,0,0,0,31,1,0,0,0,0,33,1,0,0,0,0,35,1,0,0,0,0,\n+        37,1,0,0,0,0,39,1,0,0,0,0,41,1,0,0,0,0,43,1,0,0,0,0,45,1,0,0,0,0,\n+        47,1,0,0,0,0,49,1,0,0,0,0,51,1,0,0,0,0,53,1,0,0,0,0,55,1,0,0,0,0,\n+        57,1,0,0,0,0,59,1,0,0,0,0,61,1,0,0,0,0,63,1,0,0,0,0,65,1,0,0,0,0,\n+        67,1,0,0,0,0,69,1,0,0,0,0,71,1,0,0,0,0,73,1,0,0,0,0,75,1,0,0,0,0,\n+        77,1,0,0,0,0,79,1,0,0,0,0,81,1,0,0,0,0,83,1,0,0,0,0,85,1,0,0,0,0,\n+        87,1,0,0,0,0,89,1,0,0,0,0,91,1,0,0,0,0,93,1,0,0,0,0,95,1,0,0,0,0,\n+        97,1,0,0,0,0,99,1,0,0,0,0,101,1,0,0,0,0,103,1,0,0,0,0,105,1,0,0,\n+        0,0,107,1,0,0,0,0,109,1,0,0,0,0,111,1,0,0,0,0,113,1,0,0,0,0,115,\n+        1,0,0,0,0,117,1,0,0,0,0,119,1,0,0,0,0,121,1,0,0,0,0,123,1,0,0,0,\n+        0,125,1,0,0,0,0,127,1,0,0,0,0,129,1,0,0,0,0,131,1,0,0,0,0,133,1,\n+        0,0,0,0,135,1,0,0,0,0,137,1,0,0,0,0,139,1,0,0,0,0,141,1,0,0,0,0,\n+        143,1,0,0,0,0,145,1,0,0,0,0,149,1,0,0,0,0,151,1,0,0,0,0,155,1,0,\n+        0,0,0,157,1,0,0,0,0,159,1,0,0,0,0,161,1,0,0,0,0,163,1,0,0,0,0,165,\n+        1,0,0,0,0,167,1,0,0,0,0,169,1,0,0,0,0,171,1,0,0,0,0,173,1,0,0,0,\n+        0,175,1,0,0,0,0,177,1,0,0,0,0,179,1,0,0,0,1,181,1,0,0,0,3,184,1,\n+        0,0,0,5,202,1,0,0,0,7,217,1,0,0,0,9,234,1,0,0,0,11,238,1,0,0,0,13,\n+        246,1,0,0,0,15,270,1,0,0,0,17,274,1,0,0,0,19,289,1,0,0,0,21,306,\n+        1,0,0,0,23,314,1,0,0,0,25,374,1,0,0,0,27,378,1,0,0,0,29,380,1,0,\n+        0,0,31,382,1,0,0,0,33,384,1,0,0,0,35,386,1,0,0,0,37,388,1,0,0,0,\n+        39,390,1,0,0,0,41,392,1,0,0,0,43,394,1,0,0,0,45,397,1,0,0,0,47,400,\n+        1,0,0,0,49,402,1,0,0,0,51,404,1,0,0,0,53,406,1,0,0,0,55,414,1,0,\n+        0,0,57,421,1,0,0,0,59,429,1,0,0,0,61,437,1,0,0,0,63,497,1,0,0,0,\n+        65,499,1,0,0,0,67,504,1,0,0,0,69,509,1,0,0,0,71,515,1,0,0,0,73,520,\n+        1,0,0,0,75,525,1,0,0,0,77,529,1,0,0,0,79,534,1,0,0,0,81,539,1,0,\n+        0,0,83,544,1,0,0,0,85,549,1,0,0,0,87,554,1,0,0,0,89,559,1,0,0,0,\n+        91,567,1,0,0,0,93,575,1,0,0,0,95,583,1,0,0,0,97,591,1,0,0,0,99,599,\n+        1,0,0,0,101,607,1,0,0,0,103,613,1,0,0,0,105,619,1,0,0,0,107,625,\n+        1,0,0,0,109,633,1,0,0,0,111,641,1,0,0,0,113,649,1,0,0,0,115,657,\n+        1,0,0,0,117,665,1,0,0,0,119,672,1,0,0,0,121,679,1,0,0,0,123,685,\n+        1,0,0,0,125,695,1,0,0,0,127,702,1,0,0,0,129,708,1,0,0,0,131,713,\n+        1,0,0,0,133,719,1,0,0,0,135,726,1,0,0,0,137,734,1,0,0,0,139,742,\n+        1,0,0,0,141,750,1,0,0,0,143,752,1,0,0,0,145,754,1,0,0,0,147,756,\n+        1,0,0,0,149,758,1,0,0,0,151,774,1,0,0,0,153,776,1,0,0,0,155,815,\n+        1,0,0,0,157,837,1,0,0,0,159,839,1,0,0,0,161,844,1,0,0,0,163,855,\n+        1,0,0,0,165,857,1,0,0,0,167,863,1,0,0,0,169,873,1,0,0,0,171,884,\n+        1,0,0,0,173,886,1,0,0,0,175,892,1,0,0,0,177,902,1,0,0,0,179,904,\n+        1,0,0,0,181,182,5,44,0,0,182,2,1,0,0,0,183,185,7,0,0,0,184,183,1,\n+        0,0,0,185,186,1,0,0,0,186,184,1,0,0,0,186,187,1,0,0,0,187,188,1,\n+        0,0,0,188,189,6,1,0,0,189,4,1,0,0,0,190,191,5,92,0,0,191,203,5,44,\n+        0,0,192,193,5,92,0,0,193,194,5,116,0,0,194,195,5,104,0,0,195,196,\n+        5,105,0,0,196,197,5,110,0,0,197,198,5,115,0,0,198,199,5,112,0,0,\n+        199,200,5,97,0,0,200,201,5,99,0,0,201,203,5,101,0,0,202,190,1,0,\n+        0,0,202,192,1,0,0,0,203,204,1,0,0,0,204,205,6,2,0,0,205,6,1,0,0,\n+        0,206,207,5,92,0,0,207,218,5,58,0,0,208,209,5,92,0,0,209,210,5,109,\n+        0,0,210,211,5,101,0,0,211,212,5,100,0,0,212,213,5,115,0,0,213,214,\n+        5,112,0,0,214,215,5,97,0,0,215,216,5,99,0,0,216,218,5,101,0,0,217,\n+        206,1,0,0,0,217,208,1,0,0,0,218,219,1,0,0,0,219,220,6,3,0,0,220,\n+        8,1,0,0,0,221,222,5,92,0,0,222,235,5,59,0,0,223,224,5,92,0,0,224,\n+        225,5,116,0,0,225,226,5,104,0,0,226,227,5,105,0,0,227,228,5,99,0,\n+        0,228,229,5,107,0,0,229,230,5,115,0,0,230,231,5,112,0,0,231,232,\n+        5,97,0,0,232,233,5,99,0,0,233,235,5,101,0,0,234,221,1,0,0,0,234,\n+        223,1,0,0,0,235,236,1,0,0,0,236,237,6,4,0,0,237,10,1,0,0,0,238,239,\n+        5,92,0,0,239,240,5,113,0,0,240,241,5,117,0,0,241,242,5,97,0,0,242,\n+        243,5,100,0,0,243,244,1,0,0,0,244,245,6,5,0,0,245,12,1,0,0,0,246,\n+        247,5,92,0,0,247,248,5,113,0,0,248,249,5,113,0,0,249,250,5,117,0,\n+        0,250,251,5,97,0,0,251,252,5,100,0,0,252,253,1,0,0,0,253,254,6,6,\n+        0,0,254,14,1,0,0,0,255,256,5,92,0,0,256,271,5,33,0,0,257,258,5,92,\n+        0,0,258,259,5,110,0,0,259,260,5,101,0,0,260,261,5,103,0,0,261,262,\n+        5,116,0,0,262,263,5,104,0,0,263,264,5,105,0,0,264,265,5,110,0,0,\n+        265,266,5,115,0,0,266,267,5,112,0,0,267,268,5,97,0,0,268,269,5,99,\n+        0,0,269,271,5,101,0,0,270,255,1,0,0,0,270,257,1,0,0,0,271,272,1,\n+        0,0,0,272,273,6,7,0,0,273,16,1,0,0,0,274,275,5,92,0,0,275,276,5,\n+        110,0,0,276,277,5,101,0,0,277,278,5,103,0,0,278,279,5,109,0,0,279,\n+        280,5,101,0,0,280,281,5,100,0,0,281,282,5,115,0,0,282,283,5,112,\n+        0,0,283,284,5,97,0,0,284,285,5,99,0,0,285,286,5,101,0,0,286,287,\n+        1,0,0,0,287,288,6,8,0,0,288,18,1,0,0,0,289,290,5,92,0,0,290,291,\n+        5,110,0,0,291,292,5,101,0,0,292,293,5,103,0,0,293,294,5,116,0,0,\n+        294,295,5,104,0,0,295,296,5,105,0,0,296,297,5,99,0,0,297,298,5,107,\n+        0,0,298,299,5,115,0,0,299,300,5,112,0,0,300,301,5,97,0,0,301,302,\n+        5,99,0,0,302,303,5,101,0,0,303,304,1,0,0,0,304,305,6,9,0,0,305,20,\n+        1,0,0,0,306,307,5,92,0,0,307,308,5,108,0,0,308,309,5,101,0,0,309,\n+        310,5,102,0,0,310,311,5,116,0,0,311,312,1,0,0,0,312,313,6,10,0,0,\n+        313,22,1,0,0,0,314,315,5,92,0,0,315,316,5,114,0,0,316,317,5,105,\n+        0,0,317,318,5,103,0,0,318,319,5,104,0,0,319,320,5,116,0,0,320,321,\n+        1,0,0,0,321,322,6,11,0,0,322,24,1,0,0,0,323,324,5,92,0,0,324,325,\n+        5,118,0,0,325,326,5,114,0,0,326,327,5,117,0,0,327,328,5,108,0,0,\n+        328,375,5,101,0,0,329,330,5,92,0,0,330,331,5,118,0,0,331,332,5,99,\n+        0,0,332,333,5,101,0,0,333,334,5,110,0,0,334,335,5,116,0,0,335,336,\n+        5,101,0,0,336,375,5,114,0,0,337,338,5,92,0,0,338,339,5,118,0,0,339,\n+        340,5,98,0,0,340,341,5,111,0,0,341,375,5,120,0,0,342,343,5,92,0,\n+        0,343,344,5,118,0,0,344,345,5,115,0,0,345,346,5,107,0,0,346,347,\n+        5,105,0,0,347,375,5,112,0,0,348,349,5,92,0,0,349,350,5,118,0,0,350,\n+        351,5,115,0,0,351,352,5,112,0,0,352,353,5,97,0,0,353,354,5,99,0,\n+        0,354,375,5,101,0,0,355,356,5,92,0,0,356,357,5,104,0,0,357,358,5,\n+        102,0,0,358,359,5,105,0,0,359,375,5,108,0,0,360,361,5,92,0,0,361,\n+        375,5,42,0,0,362,363,5,92,0,0,363,375,5,45,0,0,364,365,5,92,0,0,\n+        365,375,5,46,0,0,366,367,5,92,0,0,367,375,5,47,0,0,368,369,5,92,\n+        0,0,369,375,5,34,0,0,370,371,5,92,0,0,371,375,5,40,0,0,372,373,5,\n+        92,0,0,373,375,5,61,0,0,374,323,1,0,0,0,374,329,1,0,0,0,374,337,\n+        1,0,0,0,374,342,1,0,0,0,374,348,1,0,0,0,374,355,1,0,0,0,374,360,\n+        1,0,0,0,374,362,1,0,0,0,374,364,1,0,0,0,374,366,1,0,0,0,374,368,\n+        1,0,0,0,374,370,1,0,0,0,374,372,1,0,0,0,375,376,1,0,0,0,376,377,\n+        6,12,0,0,377,26,1,0,0,0,378,379,5,43,0,0,379,28,1,0,0,0,380,381,\n+        5,45,0,0,381,30,1,0,0,0,382,383,5,42,0,0,383,32,1,0,0,0,384,385,\n+        5,47,0,0,385,34,1,0,0,0,386,387,5,40,0,0,387,36,1,0,0,0,388,389,\n+        5,41,0,0,389,38,1,0,0,0,390,391,5,123,0,0,391,40,1,0,0,0,392,393,\n+        5,125,0,0,393,42,1,0,0,0,394,395,5,92,0,0,395,396,5,123,0,0,396,\n+        44,1,0,0,0,397,398,5,92,0,0,398,399,5,125,0,0,399,46,1,0,0,0,400,\n+        401,5,91,0,0,401,48,1,0,0,0,402,403,5,93,0,0,403,50,1,0,0,0,404,\n+        405,5,124,0,0,405,52,1,0,0,0,406,407,5,92,0,0,407,408,5,114,0,0,\n+        408,409,5,105,0,0,409,410,5,103,0,0,410,411,5,104,0,0,411,412,5,\n+        116,0,0,412,413,5,124,0,0,413,54,1,0,0,0,414,415,5,92,0,0,415,416,\n+        5,108,0,0,416,417,5,101,0,0,417,418,5,102,0,0,418,419,5,116,0,0,\n+        419,420,5,124,0,0,420,56,1,0,0,0,421,422,5,92,0,0,422,423,5,108,\n+        0,0,423,424,5,97,0,0,424,425,5,110,0,0,425,426,5,103,0,0,426,427,\n+        5,108,0,0,427,428,5,101,0,0,428,58,1,0,0,0,429,430,5,92,0,0,430,\n+        431,5,114,0,0,431,432,5,97,0,0,432,433,5,110,0,0,433,434,5,103,0,\n+        0,434,435,5,108,0,0,435,436,5,101,0,0,436,60,1,0,0,0,437,438,5,92,\n+        0,0,438,439,5,108,0,0,439,440,5,105,0,0,440,441,5,109,0,0,441,62,\n+        1,0,0,0,442,443,5,92,0,0,443,444,5,116,0,0,444,498,5,111,0,0,445,\n+        446,5,92,0,0,446,447,5,114,0,0,447,448,5,105,0,0,448,449,5,103,0,\n+        0,449,450,5,104,0,0,450,451,5,116,0,0,451,452,5,97,0,0,452,453,5,\n+        114,0,0,453,454,5,114,0,0,454,455,5,111,0,0,455,498,5,119,0,0,456,\n+        457,5,92,0,0,457,458,5,82,0,0,458,459,5,105,0,0,459,460,5,103,0,\n+        0,460,461,5,104,0,0,461,462,5,116,0,0,462,463,5,97,0,0,463,464,5,\n+        114,0,0,464,465,5,114,0,0,465,466,5,111,0,0,466,498,5,119,0,0,467,\n+        468,5,92,0,0,468,469,5,108,0,0,469,470,5,111,0,0,470,471,5,110,0,\n+        0,471,472,5,103,0,0,472,473,5,114,0,0,473,474,5,105,0,0,474,475,\n+        5,103,0,0,475,476,5,104,0,0,476,477,5,116,0,0,477,478,5,97,0,0,478,\n+        479,5,114,0,0,479,480,5,114,0,0,480,481,5,111,0,0,481,498,5,119,\n+        0,0,482,483,5,92,0,0,483,484,5,76,0,0,484,485,5,111,0,0,485,486,\n+        5,110,0,0,486,487,5,103,0,0,487,488,5,114,0,0,488,489,5,105,0,0,\n+        489,490,5,103,0,0,490,491,5,104,0,0,491,492,5,116,0,0,492,493,5,\n+        97,0,0,493,494,5,114,0,0,494,495,5,114,0,0,495,496,5,111,0,0,496,\n+        498,5,119,0,0,497,442,1,0,0,0,497,445,1,0,0,0,497,456,1,0,0,0,497,\n+        467,1,0,0,0,497,482,1,0,0,0,498,64,1,0,0,0,499,500,5,92,0,0,500,\n+        501,5,105,0,0,501,502,5,110,0,0,502,503,5,116,0,0,503,66,1,0,0,0,\n+        504,505,5,92,0,0,505,506,5,115,0,0,506,507,5,117,0,0,507,508,5,109,\n+        0,0,508,68,1,0,0,0,509,510,5,92,0,0,510,511,5,112,0,0,511,512,5,\n+        114,0,0,512,513,5,111,0,0,513,514,5,100,0,0,514,70,1,0,0,0,515,516,\n+        5,92,0,0,516,517,5,101,0,0,517,518,5,120,0,0,518,519,5,112,0,0,519,\n+        72,1,0,0,0,520,521,5,92,0,0,521,522,5,108,0,0,522,523,5,111,0,0,\n+        523,524,5,103,0,0,524,74,1,0,0,0,525,526,5,92,0,0,526,527,5,108,\n+        0,0,527,528,5,110,0,0,528,76,1,0,0,0,529,530,5,92,0,0,530,531,5,\n+        115,0,0,531,532,5,105,0,0,532,533,5,110,0,0,533,78,1,0,0,0,534,535,\n+        5,92,0,0,535,536,5,99,0,0,536,537,5,111,0,0,537,538,5,115,0,0,538,\n+        80,1,0,0,0,539,540,5,92,0,0,540,541,5,116,0,0,541,542,5,97,0,0,542,\n+        543,5,110,0,0,543,82,1,0,0,0,544,545,5,92,0,0,545,546,5,99,0,0,546,\n+        547,5,115,0,0,547,548,5,99,0,0,548,84,1,0,0,0,549,550,5,92,0,0,550,\n+        551,5,115,0,0,551,552,5,101,0,0,552,553,5,99,0,0,553,86,1,0,0,0,\n+        554,555,5,92,0,0,555,556,5,99,0,0,556,557,5,111,0,0,557,558,5,116,\n+        0,0,558,88,1,0,0,0,559,560,5,92,0,0,560,561,5,97,0,0,561,562,5,114,\n+        0,0,562,563,5,99,0,0,563,564,5,115,0,0,564,565,5,105,0,0,565,566,\n+        5,110,0,0,566,90,1,0,0,0,567,568,5,92,0,0,568,569,5,97,0,0,569,570,\n+        5,114,0,0,570,571,5,99,0,0,571,572,5,99,0,0,572,573,5,111,0,0,573,\n+        574,5,115,0,0,574,92,1,0,0,0,575,576,5,92,0,0,576,577,5,97,0,0,577,\n+        578,5,114,0,0,578,579,5,99,0,0,579,580,5,116,0,0,580,581,5,97,0,\n+        0,581,582,5,110,0,0,582,94,1,0,0,0,583,584,5,92,0,0,584,585,5,97,\n+        0,0,585,586,5,114,0,0,586,587,5,99,0,0,587,588,5,99,0,0,588,589,\n+        5,115,0,0,589,590,5,99,0,0,590,96,1,0,0,0,591,592,5,92,0,0,592,593,\n+        5,97,0,0,593,594,5,114,0,0,594,595,5,99,0,0,595,596,5,115,0,0,596,\n+        597,5,101,0,0,597,598,5,99,0,0,598,98,1,0,0,0,599,600,5,92,0,0,600,\n+        601,5,97,0,0,601,602,5,114,0,0,602,603,5,99,0,0,603,604,5,99,0,0,\n+        604,605,5,111,0,0,605,606,5,116,0,0,606,100,1,0,0,0,607,608,5,92,\n+        0,0,608,609,5,115,0,0,609,610,5,105,0,0,610,611,5,110,0,0,611,612,\n+        5,104,0,0,612,102,1,0,0,0,613,614,5,92,0,0,614,615,5,99,0,0,615,\n+        616,5,111,0,0,616,617,5,115,0,0,617,618,5,104,0,0,618,104,1,0,0,\n+        0,619,620,5,92,0,0,620,621,5,116,0,0,621,622,5,97,0,0,622,623,5,\n+        110,0,0,623,624,5,104,0,0,624,106,1,0,0,0,625,626,5,92,0,0,626,627,\n+        5,97,0,0,627,628,5,114,0,0,628,629,5,115,0,0,629,630,5,105,0,0,630,\n+        631,5,110,0,0,631,632,5,104,0,0,632,108,1,0,0,0,633,634,5,92,0,0,\n+        634,635,5,97,0,0,635,636,5,114,0,0,636,637,5,99,0,0,637,638,5,111,\n+        0,0,638,639,5,115,0,0,639,640,5,104,0,0,640,110,1,0,0,0,641,642,\n+        5,92,0,0,642,643,5,97,0,0,643,644,5,114,0,0,644,645,5,116,0,0,645,\n+        646,5,97,0,0,646,647,5,110,0,0,647,648,5,104,0,0,648,112,1,0,0,0,\n+        649,650,5,92,0,0,650,651,5,108,0,0,651,652,5,102,0,0,652,653,5,108,\n+        0,0,653,654,5,111,0,0,654,655,5,111,0,0,655,656,5,114,0,0,656,114,\n+        1,0,0,0,657,658,5,92,0,0,658,659,5,114,0,0,659,660,5,102,0,0,660,\n+        661,5,108,0,0,661,662,5,111,0,0,662,663,5,111,0,0,663,664,5,114,\n+        0,0,664,116,1,0,0,0,665,666,5,92,0,0,666,667,5,108,0,0,667,668,5,\n+        99,0,0,668,669,5,101,0,0,669,670,5,105,0,0,670,671,5,108,0,0,671,\n+        118,1,0,0,0,672,673,5,92,0,0,673,674,5,114,0,0,674,675,5,99,0,0,\n+        675,676,5,101,0,0,676,677,5,105,0,0,677,678,5,108,0,0,678,120,1,\n+        0,0,0,679,680,5,92,0,0,680,681,5,115,0,0,681,682,5,113,0,0,682,683,\n+        5,114,0,0,683,684,5,116,0,0,684,122,1,0,0,0,685,686,5,92,0,0,686,\n+        687,5,111,0,0,687,688,5,118,0,0,688,689,5,101,0,0,689,690,5,114,\n+        0,0,690,691,5,108,0,0,691,692,5,105,0,0,692,693,5,110,0,0,693,694,\n+        5,101,0,0,694,124,1,0,0,0,695,696,5,92,0,0,696,697,5,116,0,0,697,\n+        698,5,105,0,0,698,699,5,109,0,0,699,700,5,101,0,0,700,701,5,115,\n+        0,0,701,126,1,0,0,0,702,703,5,92,0,0,703,704,5,99,0,0,704,705,5,\n+        100,0,0,705,706,5,111,0,0,706,707,5,116,0,0,707,128,1,0,0,0,708,\n+        709,5,92,0,0,709,710,5,100,0,0,710,711,5,105,0,0,711,712,5,118,0,\n+        0,712,130,1,0,0,0,713,714,5,92,0,0,714,715,5,102,0,0,715,716,5,114,\n+        0,0,716,717,5,97,0,0,717,718,5,99,0,0,718,132,1,0,0,0,719,720,5,\n+        92,0,0,720,721,5,98,0,0,721,722,5,105,0,0,722,723,5,110,0,0,723,\n+        724,5,111,0,0,724,725,5,109,0,0,725,134,1,0,0,0,726,727,5,92,0,0,\n+        727,728,5,100,0,0,728,729,5,98,0,0,729,730,5,105,0,0,730,731,5,110,\n+        0,0,731,732,5,111,0,0,732,733,5,109,0,0,733,136,1,0,0,0,734,735,\n+        5,92,0,0,735,736,5,116,0,0,736,737,5,98,0,0,737,738,5,105,0,0,738,\n+        739,5,110,0,0,739,740,5,111,0,0,740,741,5,109,0,0,741,138,1,0,0,\n+        0,742,743,5,92,0,0,743,744,5,109,0,0,744,745,5,97,0,0,745,746,5,\n+        116,0,0,746,747,5,104,0,0,747,748,5,105,0,0,748,749,5,116,0,0,749,\n+        140,1,0,0,0,750,751,5,95,0,0,751,142,1,0,0,0,752,753,5,94,0,0,753,\n+        144,1,0,0,0,754,755,5,58,0,0,755,146,1,0,0,0,756,757,7,0,0,0,757,\n+        148,1,0,0,0,758,762,5,100,0,0,759,761,3,147,73,0,760,759,1,0,0,0,\n+        761,764,1,0,0,0,762,763,1,0,0,0,762,760,1,0,0,0,763,772,1,0,0,0,\n+        764,762,1,0,0,0,765,773,7,1,0,0,766,768,5,92,0,0,767,769,7,1,0,0,\n+        768,767,1,0,0,0,769,770,1,0,0,0,770,768,1,0,0,0,770,771,1,0,0,0,\n+        771,773,1,0,0,0,772,765,1,0,0,0,772,766,1,0,0,0,773,150,1,0,0,0,\n+        774,775,7,1,0,0,775,152,1,0,0,0,776,777,7,2,0,0,777,154,1,0,0,0,\n+        778,780,3,153,76,0,779,778,1,0,0,0,780,781,1,0,0,0,781,779,1,0,0,\n+        0,781,782,1,0,0,0,782,790,1,0,0,0,783,784,5,44,0,0,784,785,3,153,\n+        76,0,785,786,3,153,76,0,786,787,3,153,76,0,787,789,1,0,0,0,788,783,\n+        1,0,0,0,789,792,1,0,0,0,790,788,1,0,0,0,790,791,1,0,0,0,791,816,\n+        1,0,0,0,792,790,1,0,0,0,793,795,3,153,76,0,794,793,1,0,0,0,795,798,\n+        1,0,0,0,796,794,1,0,0,0,796,797,1,0,0,0,797,806,1,0,0,0,798,796,\n+        1,0,0,0,799,800,5,44,0,0,800,801,3,153,76,0,801,802,3,153,76,0,802,\n+        803,3,153,76,0,803,805,1,0,0,0,804,799,1,0,0,0,805,808,1,0,0,0,806,\n+        804,1,0,0,0,806,807,1,0,0,0,807,809,1,0,0,0,808,806,1,0,0,0,809,\n+        811,5,46,0,0,810,812,3,153,76,0,811,810,1,0,0,0,812,813,1,0,0,0,\n+        813,811,1,0,0,0,813,814,1,0,0,0,814,816,1,0,0,0,815,779,1,0,0,0,\n+        815,796,1,0,0,0,816,156,1,0,0,0,817,821,5,38,0,0,818,820,3,147,73,\n+        0,819,818,1,0,0,0,820,823,1,0,0,0,821,822,1,0,0,0,821,819,1,0,0,\n+        0,822,825,1,0,0,0,823,821,1,0,0,0,824,817,1,0,0,0,824,825,1,0,0,\n+        0,825,826,1,0,0,0,826,838,5,61,0,0,827,835,5,61,0,0,828,830,3,147,\n+        73,0,829,828,1,0,0,0,830,833,1,0,0,0,831,832,1,0,0,0,831,829,1,0,\n+        0,0,832,834,1,0,0,0,833,831,1,0,0,0,834,836,5,38,0,0,835,831,1,0,\n+        0,0,835,836,1,0,0,0,836,838,1,0,0,0,837,824,1,0,0,0,837,827,1,0,\n+        0,0,838,158,1,0,0,0,839,840,5,92,0,0,840,841,5,110,0,0,841,842,5,\n+        101,0,0,842,843,5,113,0,0,843,160,1,0,0,0,844,845,5,60,0,0,845,162,\n+        1,0,0,0,846,847,5,92,0,0,847,848,5,108,0,0,848,849,5,101,0,0,849,\n+        856,5,113,0,0,850,851,5,92,0,0,851,852,5,108,0,0,852,856,5,101,0,\n+        0,853,856,3,165,82,0,854,856,3,167,83,0,855,846,1,0,0,0,855,850,\n+        1,0,0,0,855,853,1,0,0,0,855,854,1,0,0,0,856,164,1,0,0,0,857,858,\n+        5,92,0,0,858,859,5,108,0,0,859,860,5,101,0,0,860,861,5,113,0,0,861,\n+        862,5,113,0,0,862,166,1,0,0,0,863,864,5,92,0,0,864,865,5,108,0,0,\n+        865,866,5,101,0,0,866,867,5,113,0,0,867,868,5,115,0,0,868,869,5,\n+        108,0,0,869,870,5,97,0,0,870,871,5,110,0,0,871,872,5,116,0,0,872,\n+        168,1,0,0,0,873,874,5,62,0,0,874,170,1,0,0,0,875,876,5,92,0,0,876,\n+        877,5,103,0,0,877,878,5,101,0,0,878,885,5,113,0,0,879,880,5,92,0,\n+        0,880,881,5,103,0,0,881,885,5,101,0,0,882,885,3,173,86,0,883,885,\n+        3,175,87,0,884,875,1,0,0,0,884,879,1,0,0,0,884,882,1,0,0,0,884,883,\n+        1,0,0,0,885,172,1,0,0,0,886,887,5,92,0,0,887,888,5,103,0,0,888,889,\n+        5,101,0,0,889,890,5,113,0,0,890,891,5,113,0,0,891,174,1,0,0,0,892,\n+        893,5,92,0,0,893,894,5,103,0,0,894,895,5,101,0,0,895,896,5,113,0,\n+        0,896,897,5,115,0,0,897,898,5,108,0,0,898,899,5,97,0,0,899,900,5,\n+        110,0,0,900,901,5,116,0,0,901,176,1,0,0,0,902,903,5,33,0,0,903,178,\n+        1,0,0,0,904,906,5,92,0,0,905,907,7,1,0,0,906,905,1,0,0,0,907,908,\n+        1,0,0,0,908,906,1,0,0,0,908,909,1,0,0,0,909,180,1,0,0,0,25,0,186,\n+        202,217,234,270,374,497,762,770,772,781,790,796,806,813,815,821,\n+        824,831,835,837,855,884,908,1,6,0,0\n+    ]\n \n class LaTeXLexer(Lexer):\n \n@@ -519,69 +456,65 @@ class LaTeXLexer(Lexer):\n \n     channelNames = [ u\"DEFAULT_TOKEN_CHANNEL\", u\"HIDDEN\" ]\n \n-    modeNames = [ u\"DEFAULT_MODE\" ]\n+    modeNames = [ \"DEFAULT_MODE\" ]\n \n-    literalNames = [ u\"<INVALID>\",\n-            u\"','\", u\"'\\\\quad'\", u\"'\\\\qquad'\", u\"'\\\\negmedspace'\", u\"'\\\\negthickspace'\",\n-            u\"'\\\\left'\", u\"'\\\\right'\", u\"'+'\", u\"'-'\", u\"'*'\", u\"'/'\", u\"'('\",\n-            u\"')'\", u\"'{'\", u\"'}'\", u\"'\\\\{'\", u\"'\\\\}'\", u\"'['\", u\"']'\",\n-            u\"'|'\", u\"'\\\\right|'\", u\"'\\\\left|'\", u\"'\\\\langle'\", u\"'\\\\rangle'\",\n-            u\"'\\\\lim'\", u\"'\\\\int'\", u\"'\\\\sum'\", u\"'\\\\prod'\", u\"'\\\\exp'\",\n-            u\"'\\\\log'\", u\"'\\\\ln'\", u\"'\\\\sin'\", u\"'\\\\cos'\", u\"'\\\\tan'\", u\"'\\\\csc'\",\n-            u\"'\\\\sec'\", u\"'\\\\cot'\", u\"'\\\\arcsin'\", u\"'\\\\arccos'\", u\"'\\\\arctan'\",\n-            u\"'\\\\arccsc'\", u\"'\\\\arcsec'\", u\"'\\\\arccot'\", u\"'\\\\sinh'\", u\"'\\\\cosh'\",\n-            u\"'\\\\tanh'\", u\"'\\\\arsinh'\", u\"'\\\\arcosh'\", u\"'\\\\artanh'\", u\"'\\\\lfloor'\",\n-            u\"'\\\\rfloor'\", u\"'\\\\lceil'\", u\"'\\\\rceil'\", u\"'\\\\sqrt'\", u\"'\\\\overline'\",\n-            u\"'\\\\times'\", u\"'\\\\cdot'\", u\"'\\\\div'\", u\"'\\\\frac'\", u\"'\\\\binom'\",\n-            u\"'\\\\dbinom'\", u\"'\\\\tbinom'\", u\"'\\\\mathit'\", u\"'_'\", u\"'^'\",\n-            u\"':'\", u\"'\\\\neq'\", u\"'<'\", u\"'\\\\leqq'\", u\"'\\\\leqslant'\", u\"'>'\",\n-            u\"'\\\\geqq'\", u\"'\\\\geqslant'\", u\"'!'\" ]\n+    literalNames = [ \"<INVALID>\",\n+            \"','\", \"'\\\\quad'\", \"'\\\\qquad'\", \"'\\\\negmedspace'\", \"'\\\\negthickspace'\",\n+            \"'\\\\left'\", \"'\\\\right'\", \"'+'\", \"'-'\", \"'*'\", \"'/'\", \"'('\",\n+            \"')'\", \"'{'\", \"'}'\", \"'\\\\{'\", \"'\\\\}'\", \"'['\", \"']'\", \"'|'\",\n+            \"'\\\\right|'\", \"'\\\\left|'\", \"'\\\\langle'\", \"'\\\\rangle'\", \"'\\\\lim'\",\n+            \"'\\\\int'\", \"'\\\\sum'\", \"'\\\\prod'\", \"'\\\\exp'\", \"'\\\\log'\", \"'\\\\ln'\",\n+            \"'\\\\sin'\", \"'\\\\cos'\", \"'\\\\tan'\", \"'\\\\csc'\", \"'\\\\sec'\", \"'\\\\cot'\",\n+            \"'\\\\arcsin'\", \"'\\\\arccos'\", \"'\\\\arctan'\", \"'\\\\arccsc'\", \"'\\\\arcsec'\",\n+            \"'\\\\arccot'\", \"'\\\\sinh'\", \"'\\\\cosh'\", \"'\\\\tanh'\", \"'\\\\arsinh'\",\n+            \"'\\\\arcosh'\", \"'\\\\artanh'\", \"'\\\\lfloor'\", \"'\\\\rfloor'\", \"'\\\\lceil'\",\n+            \"'\\\\rceil'\", \"'\\\\sqrt'\", \"'\\\\overline'\", \"'\\\\times'\", \"'\\\\cdot'\",\n+            \"'\\\\div'\", \"'\\\\frac'\", \"'\\\\binom'\", \"'\\\\dbinom'\", \"'\\\\tbinom'\",\n+            \"'\\\\mathit'\", \"'_'\", \"'^'\", \"':'\", \"'\\\\neq'\", \"'<'\", \"'\\\\leqq'\",\n+            \"'\\\\leqslant'\", \"'>'\", \"'\\\\geqq'\", \"'\\\\geqslant'\", \"'!'\" ]\n \n-    symbolicNames = [ u\"<INVALID>\",\n-            u\"WS\", u\"THINSPACE\", u\"MEDSPACE\", u\"THICKSPACE\", u\"QUAD\", u\"QQUAD\",\n-            u\"NEGTHINSPACE\", u\"NEGMEDSPACE\", u\"NEGTHICKSPACE\", u\"CMD_LEFT\",\n-            u\"CMD_RIGHT\", u\"IGNORE\", u\"ADD\", u\"SUB\", u\"MUL\", u\"DIV\", u\"L_PAREN\",\n-            u\"R_PAREN\", u\"L_BRACE\", u\"R_BRACE\", u\"L_BRACE_LITERAL\", u\"R_BRACE_LITERAL\",\n-            u\"L_BRACKET\", u\"R_BRACKET\", u\"BAR\", u\"R_BAR\", u\"L_BAR\", u\"L_ANGLE\",\n-            u\"R_ANGLE\", u\"FUNC_LIM\", u\"LIM_APPROACH_SYM\", u\"FUNC_INT\", u\"FUNC_SUM\",\n-            u\"FUNC_PROD\", u\"FUNC_EXP\", u\"FUNC_LOG\", u\"FUNC_LN\", u\"FUNC_SIN\",\n-            u\"FUNC_COS\", u\"FUNC_TAN\", u\"FUNC_CSC\", u\"FUNC_SEC\", u\"FUNC_COT\",\n-            u\"FUNC_ARCSIN\", u\"FUNC_ARCCOS\", u\"FUNC_ARCTAN\", u\"FUNC_ARCCSC\",\n-            u\"FUNC_ARCSEC\", u\"FUNC_ARCCOT\", u\"FUNC_SINH\", u\"FUNC_COSH\",\n-            u\"FUNC_TANH\", u\"FUNC_ARSINH\", u\"FUNC_ARCOSH\", u\"FUNC_ARTANH\",\n-            u\"L_FLOOR\", u\"R_FLOOR\", u\"L_CEIL\", u\"R_CEIL\", u\"FUNC_SQRT\",\n-            u\"FUNC_OVERLINE\", u\"CMD_TIMES\", u\"CMD_CDOT\", u\"CMD_DIV\", u\"CMD_FRAC\",\n-            u\"CMD_BINOM\", u\"CMD_DBINOM\", u\"CMD_TBINOM\", u\"CMD_MATHIT\", u\"UNDERSCORE\",\n-            u\"CARET\", u\"COLON\", u\"DIFFERENTIAL\", u\"LETTER\", u\"NUMBER\", u\"EQUAL\",\n-            u\"NEQ\", u\"LT\", u\"LTE\", u\"LTE_Q\", u\"LTE_S\", u\"GT\", u\"GTE\", u\"GTE_Q\",\n-            u\"GTE_S\", u\"BANG\", u\"SYMBOL\" ]\n+    symbolicNames = [ \"<INVALID>\",\n+            \"WS\", \"THINSPACE\", \"MEDSPACE\", \"THICKSPACE\", \"QUAD\", \"QQUAD\",\n+            \"NEGTHINSPACE\", \"NEGMEDSPACE\", \"NEGTHICKSPACE\", \"CMD_LEFT\",\n+            \"CMD_RIGHT\", \"IGNORE\", \"ADD\", \"SUB\", \"MUL\", \"DIV\", \"L_PAREN\",\n+            \"R_PAREN\", \"L_BRACE\", \"R_BRACE\", \"L_BRACE_LITERAL\", \"R_BRACE_LITERAL\",\n+            \"L_BRACKET\", \"R_BRACKET\", \"BAR\", \"R_BAR\", \"L_BAR\", \"L_ANGLE\",\n+            \"R_ANGLE\", \"FUNC_LIM\", \"LIM_APPROACH_SYM\", \"FUNC_INT\", \"FUNC_SUM\",\n+            \"FUNC_PROD\", \"FUNC_EXP\", \"FUNC_LOG\", \"FUNC_LN\", \"FUNC_SIN\",\n+            \"FUNC_COS\", \"FUNC_TAN\", \"FUNC_CSC\", \"FUNC_SEC\", \"FUNC_COT\",\n+            \"FUNC_ARCSIN\", \"FUNC_ARCCOS\", \"FUNC_ARCTAN\", \"FUNC_ARCCSC\",\n+            \"FUNC_ARCSEC\", \"FUNC_ARCCOT\", \"FUNC_SINH\", \"FUNC_COSH\", \"FUNC_TANH\",\n+            \"FUNC_ARSINH\", \"FUNC_ARCOSH\", \"FUNC_ARTANH\", \"L_FLOOR\", \"R_FLOOR\",\n+            \"L_CEIL\", \"R_CEIL\", \"FUNC_SQRT\", \"FUNC_OVERLINE\", \"CMD_TIMES\",\n+            \"CMD_CDOT\", \"CMD_DIV\", \"CMD_FRAC\", \"CMD_BINOM\", \"CMD_DBINOM\",\n+            \"CMD_TBINOM\", \"CMD_MATHIT\", \"UNDERSCORE\", \"CARET\", \"COLON\",\n+            \"DIFFERENTIAL\", \"LETTER\", \"NUMBER\", \"EQUAL\", \"NEQ\", \"LT\", \"LTE\",\n+            \"LTE_Q\", \"LTE_S\", \"GT\", \"GTE\", \"GTE_Q\", \"GTE_S\", \"BANG\", \"SYMBOL\" ]\n \n-    ruleNames = [ u\"T__0\", u\"WS\", u\"THINSPACE\", u\"MEDSPACE\", u\"THICKSPACE\",\n-                  u\"QUAD\", u\"QQUAD\", u\"NEGTHINSPACE\", u\"NEGMEDSPACE\", u\"NEGTHICKSPACE\",\n-                  u\"CMD_LEFT\", u\"CMD_RIGHT\", u\"IGNORE\", u\"ADD\", u\"SUB\",\n-                  u\"MUL\", u\"DIV\", u\"L_PAREN\", u\"R_PAREN\", u\"L_BRACE\", u\"R_BRACE\",\n-                  u\"L_BRACE_LITERAL\", u\"R_BRACE_LITERAL\", u\"L_BRACKET\",\n-                  u\"R_BRACKET\", u\"BAR\", u\"R_BAR\", u\"L_BAR\", u\"L_ANGLE\",\n-                  u\"R_ANGLE\", u\"FUNC_LIM\", u\"LIM_APPROACH_SYM\", u\"FUNC_INT\",\n-                  u\"FUNC_SUM\", u\"FUNC_PROD\", u\"FUNC_EXP\", u\"FUNC_LOG\", u\"FUNC_LN\",\n-                  u\"FUNC_SIN\", u\"FUNC_COS\", u\"FUNC_TAN\", u\"FUNC_CSC\", u\"FUNC_SEC\",\n-                  u\"FUNC_COT\", u\"FUNC_ARCSIN\", u\"FUNC_ARCCOS\", u\"FUNC_ARCTAN\",\n-                  u\"FUNC_ARCCSC\", u\"FUNC_ARCSEC\", u\"FUNC_ARCCOT\", u\"FUNC_SINH\",\n-                  u\"FUNC_COSH\", u\"FUNC_TANH\", u\"FUNC_ARSINH\", u\"FUNC_ARCOSH\",\n-                  u\"FUNC_ARTANH\", u\"L_FLOOR\", u\"R_FLOOR\", u\"L_CEIL\", u\"R_CEIL\",\n-                  u\"FUNC_SQRT\", u\"FUNC_OVERLINE\", u\"CMD_TIMES\", u\"CMD_CDOT\",\n-                  u\"CMD_DIV\", u\"CMD_FRAC\", u\"CMD_BINOM\", u\"CMD_DBINOM\",\n-                  u\"CMD_TBINOM\", u\"CMD_MATHIT\", u\"UNDERSCORE\", u\"CARET\",\n-                  u\"COLON\", u\"WS_CHAR\", u\"DIFFERENTIAL\", u\"LETTER\", u\"DIGIT\",\n-                  u\"NUMBER\", u\"EQUAL\", u\"NEQ\", u\"LT\", u\"LTE\", u\"LTE_Q\",\n-                  u\"LTE_S\", u\"GT\", u\"GTE\", u\"GTE_Q\", u\"GTE_S\", u\"BANG\",\n-                  u\"SYMBOL\" ]\n+    ruleNames = [ \"T__0\", \"WS\", \"THINSPACE\", \"MEDSPACE\", \"THICKSPACE\", \"QUAD\",\n+                  \"QQUAD\", \"NEGTHINSPACE\", \"NEGMEDSPACE\", \"NEGTHICKSPACE\",\n+                  \"CMD_LEFT\", \"CMD_RIGHT\", \"IGNORE\", \"ADD\", \"SUB\", \"MUL\",\n+                  \"DIV\", \"L_PAREN\", \"R_PAREN\", \"L_BRACE\", \"R_BRACE\", \"L_BRACE_LITERAL\",\n+                  \"R_BRACE_LITERAL\", \"L_BRACKET\", \"R_BRACKET\", \"BAR\", \"R_BAR\",\n+                  \"L_BAR\", \"L_ANGLE\", \"R_ANGLE\", \"FUNC_LIM\", \"LIM_APPROACH_SYM\",\n+                  \"FUNC_INT\", \"FUNC_SUM\", \"FUNC_PROD\", \"FUNC_EXP\", \"FUNC_LOG\",\n+                  \"FUNC_LN\", \"FUNC_SIN\", \"FUNC_COS\", \"FUNC_TAN\", \"FUNC_CSC\",\n+                  \"FUNC_SEC\", \"FUNC_COT\", \"FUNC_ARCSIN\", \"FUNC_ARCCOS\",\n+                  \"FUNC_ARCTAN\", \"FUNC_ARCCSC\", \"FUNC_ARCSEC\", \"FUNC_ARCCOT\",\n+                  \"FUNC_SINH\", \"FUNC_COSH\", \"FUNC_TANH\", \"FUNC_ARSINH\",\n+                  \"FUNC_ARCOSH\", \"FUNC_ARTANH\", \"L_FLOOR\", \"R_FLOOR\", \"L_CEIL\",\n+                  \"R_CEIL\", \"FUNC_SQRT\", \"FUNC_OVERLINE\", \"CMD_TIMES\", \"CMD_CDOT\",\n+                  \"CMD_DIV\", \"CMD_FRAC\", \"CMD_BINOM\", \"CMD_DBINOM\", \"CMD_TBINOM\",\n+                  \"CMD_MATHIT\", \"UNDERSCORE\", \"CARET\", \"COLON\", \"WS_CHAR\",\n+                  \"DIFFERENTIAL\", \"LETTER\", \"DIGIT\", \"NUMBER\", \"EQUAL\",\n+                  \"NEQ\", \"LT\", \"LTE\", \"LTE_Q\", \"LTE_S\", \"GT\", \"GTE\", \"GTE_Q\",\n+                  \"GTE_S\", \"BANG\", \"SYMBOL\" ]\n \n-    grammarFileName = u\"LaTeX.g4\"\n+    grammarFileName = \"LaTeX.g4\"\n \n-    def __init__(self, input=None, output=sys.stdout):\n-        super(LaTeXLexer, self).__init__(input, output=output)\n-        self.checkVersion(\"4.7.2\")\n+    def __init__(self, input=None, output:TextIO = sys.stdout):\n+        super().__init__(input, output)\n+        self.checkVersion(\"4.13.2\")\n         self._interp = LexerATNSimulator(self, self.atn, self.decisionsToDFA, PredictionContextCache())\n         self._actions = None\n         self._predicates = None\ndiff --git a/sympy/parsing/latex/_antlr/latexparser.py b/sympy/parsing/latex/_antlr/latexparser.py\nindex 0fc7e5a7a6..0e781a0a71 100644\n--- a/sympy/parsing/latex/_antlr/latexparser.py\n+++ b/sympy/parsing/latex/_antlr/latexparser.py\n@@ -10,238 +10,198 @@\n # Generated with antlr4\n #    antlr4 is licensed under the BSD-3-Clause License\n #    https://github.com/antlr/antlr4/blob/master/LICENSE.txt\n-from __future__ import print_function\n+# encoding: utf-8\n+\n+# *** GENERATED BY `setup.py antlr`, DO NOT EDIT BY HAND ***\n+#\n+# Generated from ../LaTeX.g4, derived from latex2sympy\n+#     latex2sympy is licensed under the MIT license\n+#     https://github.com/augustt198/latex2sympy/blob/master/LICENSE.txt\n+#\n+# Generated with antlr4\n+#    antlr4 is licensed under the BSD-3-Clause License\n+#    https://github.com/antlr/antlr4/blob/master/LICENSE.txt\n+# encoding: utf-8\n from antlr4 import *\n from io import StringIO\n import sys\n-\n+if sys.version_info[1] > 5:\n+\tfrom typing import TextIO\n+else:\n+\tfrom typing.io import TextIO\n \n def serializedATN():\n-    with StringIO() as buf:\n-        buf.write(u\"\\3\\u608b\\ua72a\\u8133\\ub9ed\\u417c\\u3be7\\u7786\\u5964\\3\")\n-        buf.write(u\"Z\\u01d5\\4\\2\\t\\2\\4\\3\\t\\3\\4\\4\\t\\4\\4\\5\\t\\5\\4\\6\\t\\6\\4\\7\\t\")\n-        buf.write(u\"\\7\\4\\b\\t\\b\\4\\t\\t\\t\\4\\n\\t\\n\\4\\13\\t\\13\\4\\f\\t\\f\\4\\r\\t\\r\")\n-        buf.write(u\"\\4\\16\\t\\16\\4\\17\\t\\17\\4\\20\\t\\20\\4\\21\\t\\21\\4\\22\\t\\22\\4\")\n-        buf.write(u\"\\23\\t\\23\\4\\24\\t\\24\\4\\25\\t\\25\\4\\26\\t\\26\\4\\27\\t\\27\\4\\30\")\n-        buf.write(u\"\\t\\30\\4\\31\\t\\31\\4\\32\\t\\32\\4\\33\\t\\33\\4\\34\\t\\34\\4\\35\\t\")\n-        buf.write(u\"\\35\\4\\36\\t\\36\\4\\37\\t\\37\\4 \\t \\4!\\t!\\4\\\"\\t\\\"\\4#\\t#\\4$\")\n-        buf.write(u\"\\t$\\4%\\t%\\4&\\t&\\4\\'\\t\\'\\4(\\t(\\4)\\t)\\3\\2\\3\\2\\3\\3\\3\\3\\3\")\n-        buf.write(u\"\\3\\3\\3\\3\\3\\3\\3\\7\\3[\\n\\3\\f\\3\\16\\3^\\13\\3\\3\\4\\3\\4\\3\\4\\3\")\n-        buf.write(u\"\\4\\3\\5\\3\\5\\3\\6\\3\\6\\3\\6\\3\\6\\3\\6\\3\\6\\7\\6l\\n\\6\\f\\6\\16\\6\")\n-        buf.write(u\"o\\13\\6\\3\\7\\3\\7\\3\\7\\3\\7\\3\\7\\3\\7\\7\\7w\\n\\7\\f\\7\\16\\7z\\13\")\n-        buf.write(u\"\\7\\3\\b\\3\\b\\3\\b\\3\\b\\3\\b\\3\\b\\7\\b\\u0082\\n\\b\\f\\b\\16\\b\\u0085\")\n-        buf.write(u\"\\13\\b\\3\\t\\3\\t\\3\\t\\6\\t\\u008a\\n\\t\\r\\t\\16\\t\\u008b\\5\\t\\u008e\")\n-        buf.write(u\"\\n\\t\\3\\n\\3\\n\\3\\n\\3\\n\\7\\n\\u0094\\n\\n\\f\\n\\16\\n\\u0097\\13\")\n-        buf.write(u\"\\n\\5\\n\\u0099\\n\\n\\3\\13\\3\\13\\7\\13\\u009d\\n\\13\\f\\13\\16\\13\")\n-        buf.write(u\"\\u00a0\\13\\13\\3\\f\\3\\f\\7\\f\\u00a4\\n\\f\\f\\f\\16\\f\\u00a7\\13\")\n-        buf.write(u\"\\f\\3\\r\\3\\r\\5\\r\\u00ab\\n\\r\\3\\16\\3\\16\\3\\16\\3\\16\\3\\16\\3\\16\")\n-        buf.write(u\"\\5\\16\\u00b3\\n\\16\\3\\17\\3\\17\\3\\17\\3\\17\\5\\17\\u00b9\\n\\17\")\n-        buf.write(u\"\\3\\17\\3\\17\\3\\20\\3\\20\\3\\20\\3\\20\\5\\20\\u00c1\\n\\20\\3\\20\\3\")\n-        buf.write(u\"\\20\\3\\21\\3\\21\\3\\21\\3\\21\\3\\21\\3\\21\\3\\21\\3\\21\\3\\21\\3\\21\")\n-        buf.write(u\"\\5\\21\\u00cf\\n\\21\\3\\21\\5\\21\\u00d2\\n\\21\\7\\21\\u00d4\\n\\21\")\n-        buf.write(u\"\\f\\21\\16\\21\\u00d7\\13\\21\\3\\22\\3\\22\\3\\22\\3\\22\\3\\22\\3\\22\")\n-        buf.write(u\"\\3\\22\\3\\22\\3\\22\\3\\22\\5\\22\\u00e3\\n\\22\\3\\22\\5\\22\\u00e6\")\n-        buf.write(u\"\\n\\22\\7\\22\\u00e8\\n\\22\\f\\22\\16\\22\\u00eb\\13\\22\\3\\23\\3\\23\")\n-        buf.write(u\"\\3\\23\\3\\23\\3\\23\\3\\23\\3\\23\\3\\23\\5\\23\\u00f5\\n\\23\\3\\24\\3\")\n-        buf.write(u\"\\24\\3\\24\\3\\24\\3\\24\\3\\24\\3\\24\\5\\24\\u00fe\\n\\24\\3\\25\\3\\25\")\n-        buf.write(u\"\\3\\25\\3\\25\\3\\25\\3\\25\\3\\25\\3\\25\\3\\25\\3\\25\\3\\25\\3\\25\\3\")\n-        buf.write(u\"\\25\\3\\25\\3\\25\\3\\25\\5\\25\\u0110\\n\\25\\3\\26\\3\\26\\3\\26\\3\\26\")\n-        buf.write(u\"\\3\\27\\3\\27\\5\\27\\u0118\\n\\27\\3\\27\\3\\27\\3\\27\\3\\27\\3\\27\\5\")\n-        buf.write(u\"\\27\\u011f\\n\\27\\3\\30\\3\\30\\3\\30\\3\\30\\3\\31\\3\\31\\3\\31\\3\\31\")\n-        buf.write(u\"\\3\\32\\3\\32\\3\\32\\3\\32\\3\\32\\3\\33\\7\\33\\u012f\\n\\33\\f\\33\\16\")\n-        buf.write(u\"\\33\\u0132\\13\\33\\3\\34\\3\\34\\3\\34\\3\\34\\3\\34\\3\\34\\3\\34\\3\")\n-        buf.write(u\"\\34\\3\\35\\3\\35\\3\\35\\3\\35\\3\\35\\3\\35\\3\\35\\3\\35\\3\\36\\3\\36\")\n-        buf.write(u\"\\3\\36\\3\\36\\3\\37\\3\\37\\3\\37\\3\\37\\3 \\3 \\3!\\3!\\5!\\u0150\\n\")\n-        buf.write(u\"!\\3!\\5!\\u0153\\n!\\3!\\5!\\u0156\\n!\\3!\\5!\\u0159\\n!\\5!\\u015b\")\n-        buf.write(u\"\\n!\\3!\\3!\\3!\\3!\\3!\\5!\\u0162\\n!\\3!\\3!\\5!\\u0166\\n!\\3!\\3\")\n-        buf.write(u\"!\\3!\\3!\\3!\\3!\\3!\\3!\\3!\\3!\\3!\\5!\\u0173\\n!\\3!\\5!\\u0176\")\n-        buf.write(u\"\\n!\\3!\\3!\\3!\\5!\\u017b\\n!\\3!\\3!\\3!\\3!\\3!\\5!\\u0182\\n!\\3\")\n-        buf.write(u\"!\\3!\\3!\\3!\\3!\\3!\\3!\\3!\\3!\\3!\\3!\\3!\\3!\\3!\\3!\\3!\\5!\\u0194\")\n-        buf.write(u\"\\n!\\3!\\3!\\3!\\3!\\3!\\3!\\5!\\u019c\\n!\\3\\\"\\3\\\"\\3\\\"\\3\\\"\\3\\\"\")\n-        buf.write(u\"\\5\\\"\\u01a3\\n\\\"\\3#\\3#\\3#\\3#\\3#\\3#\\3#\\3#\\3#\\5#\\u01ae\\n\")\n-        buf.write(u\"#\\3#\\3#\\3$\\3$\\3$\\3$\\3$\\5$\\u01b7\\n$\\3%\\3%\\3&\\3&\\3&\\3&\")\n-        buf.write(u\"\\3&\\3&\\5&\\u01c1\\n&\\3\\'\\3\\'\\3\\'\\3\\'\\3\\'\\3\\'\\5\\'\\u01c9\")\n-        buf.write(u\"\\n\\'\\3(\\3(\\3(\\3(\\3(\\3)\\3)\\3)\\3)\\3)\\3)\\2\\b\\4\\n\\f\\16 \\\"\")\n-        buf.write(u\"*\\2\\4\\6\\b\\n\\f\\16\\20\\22\\24\\26\\30\\32\\34\\36 \\\"$&(*,.\\60\")\n-        buf.write(u\"\\62\\64\\668:<>@BDFHJLNP\\2\\13\\4\\2ORUV\\3\\2\\20\\21\\5\\2\\22\")\n-        buf.write(u\"\\23ACKK\\4\\2MMZZ\\3\\2\\34\\35\\4\\2\\34\\34\\36\\36\\3\\2EG\\3\\2&\")\n-        buf.write(u\":\\3\\2$%\\2\\u01f1\\2R\\3\\2\\2\\2\\4T\\3\\2\\2\\2\\6_\\3\\2\\2\\2\\bc\\3\")\n-        buf.write(u\"\\2\\2\\2\\ne\\3\\2\\2\\2\\fp\\3\\2\\2\\2\\16{\\3\\2\\2\\2\\20\\u008d\\3\\2\")\n-        buf.write(u\"\\2\\2\\22\\u0098\\3\\2\\2\\2\\24\\u009a\\3\\2\\2\\2\\26\\u00a1\\3\\2\\2\")\n-        buf.write(u\"\\2\\30\\u00aa\\3\\2\\2\\2\\32\\u00ac\\3\\2\\2\\2\\34\\u00b4\\3\\2\\2\\2\")\n-        buf.write(u\"\\36\\u00bc\\3\\2\\2\\2 \\u00c4\\3\\2\\2\\2\\\"\\u00d8\\3\\2\\2\\2$\\u00f4\")\n-        buf.write(u\"\\3\\2\\2\\2&\\u00fd\\3\\2\\2\\2(\\u010f\\3\\2\\2\\2*\\u0111\\3\\2\\2\\2\")\n-        buf.write(u\",\\u011e\\3\\2\\2\\2.\\u0120\\3\\2\\2\\2\\60\\u0124\\3\\2\\2\\2\\62\\u0128\")\n-        buf.write(u\"\\3\\2\\2\\2\\64\\u0130\\3\\2\\2\\2\\66\\u0133\\3\\2\\2\\28\\u013b\\3\\2\")\n-        buf.write(u\"\\2\\2:\\u0143\\3\\2\\2\\2<\\u0147\\3\\2\\2\\2>\\u014b\\3\\2\\2\\2@\\u019b\")\n-        buf.write(u\"\\3\\2\\2\\2B\\u01a2\\3\\2\\2\\2D\\u01a4\\3\\2\\2\\2F\\u01b6\\3\\2\\2\\2\")\n-        buf.write(u\"H\\u01b8\\3\\2\\2\\2J\\u01ba\\3\\2\\2\\2L\\u01c2\\3\\2\\2\\2N\\u01ca\")\n-        buf.write(u\"\\3\\2\\2\\2P\\u01cf\\3\\2\\2\\2RS\\5\\4\\3\\2S\\3\\3\\2\\2\\2TU\\b\\3\\1\")\n-        buf.write(u\"\\2UV\\5\\b\\5\\2V\\\\\\3\\2\\2\\2WX\\f\\4\\2\\2XY\\t\\2\\2\\2Y[\\5\\4\\3\\5\")\n-        buf.write(u\"ZW\\3\\2\\2\\2[^\\3\\2\\2\\2\\\\Z\\3\\2\\2\\2\\\\]\\3\\2\\2\\2]\\5\\3\\2\\2\\2\")\n-        buf.write(u\"^\\\\\\3\\2\\2\\2_`\\5\\b\\5\\2`a\\7O\\2\\2ab\\5\\b\\5\\2b\\7\\3\\2\\2\\2c\")\n-        buf.write(u\"d\\5\\n\\6\\2d\\t\\3\\2\\2\\2ef\\b\\6\\1\\2fg\\5\\f\\7\\2gm\\3\\2\\2\\2hi\")\n-        buf.write(u\"\\f\\4\\2\\2ij\\t\\3\\2\\2jl\\5\\n\\6\\5kh\\3\\2\\2\\2lo\\3\\2\\2\\2mk\\3\")\n-        buf.write(u\"\\2\\2\\2mn\\3\\2\\2\\2n\\13\\3\\2\\2\\2om\\3\\2\\2\\2pq\\b\\7\\1\\2qr\\5\")\n-        buf.write(u\"\\20\\t\\2rx\\3\\2\\2\\2st\\f\\4\\2\\2tu\\t\\4\\2\\2uw\\5\\f\\7\\5vs\\3\\2\")\n-        buf.write(u\"\\2\\2wz\\3\\2\\2\\2xv\\3\\2\\2\\2xy\\3\\2\\2\\2y\\r\\3\\2\\2\\2zx\\3\\2\\2\")\n-        buf.write(u\"\\2{|\\b\\b\\1\\2|}\\5\\22\\n\\2}\\u0083\\3\\2\\2\\2~\\177\\f\\4\\2\\2\\177\")\n-        buf.write(u\"\\u0080\\t\\4\\2\\2\\u0080\\u0082\\5\\16\\b\\5\\u0081~\\3\\2\\2\\2\\u0082\")\n-        buf.write(u\"\\u0085\\3\\2\\2\\2\\u0083\\u0081\\3\\2\\2\\2\\u0083\\u0084\\3\\2\\2\")\n-        buf.write(u\"\\2\\u0084\\17\\3\\2\\2\\2\\u0085\\u0083\\3\\2\\2\\2\\u0086\\u0087\\t\")\n-        buf.write(u\"\\3\\2\\2\\u0087\\u008e\\5\\20\\t\\2\\u0088\\u008a\\5\\24\\13\\2\\u0089\")\n-        buf.write(u\"\\u0088\\3\\2\\2\\2\\u008a\\u008b\\3\\2\\2\\2\\u008b\\u0089\\3\\2\\2\")\n-        buf.write(u\"\\2\\u008b\\u008c\\3\\2\\2\\2\\u008c\\u008e\\3\\2\\2\\2\\u008d\\u0086\")\n-        buf.write(u\"\\3\\2\\2\\2\\u008d\\u0089\\3\\2\\2\\2\\u008e\\21\\3\\2\\2\\2\\u008f\\u0090\")\n-        buf.write(u\"\\t\\3\\2\\2\\u0090\\u0099\\5\\22\\n\\2\\u0091\\u0095\\5\\24\\13\\2\\u0092\")\n-        buf.write(u\"\\u0094\\5\\26\\f\\2\\u0093\\u0092\\3\\2\\2\\2\\u0094\\u0097\\3\\2\\2\")\n-        buf.write(u\"\\2\\u0095\\u0093\\3\\2\\2\\2\\u0095\\u0096\\3\\2\\2\\2\\u0096\\u0099\")\n-        buf.write(u\"\\3\\2\\2\\2\\u0097\\u0095\\3\\2\\2\\2\\u0098\\u008f\\3\\2\\2\\2\\u0098\")\n-        buf.write(u\"\\u0091\\3\\2\\2\\2\\u0099\\23\\3\\2\\2\\2\\u009a\\u009e\\5 \\21\\2\\u009b\")\n-        buf.write(u\"\\u009d\\5\\30\\r\\2\\u009c\\u009b\\3\\2\\2\\2\\u009d\\u00a0\\3\\2\\2\")\n-        buf.write(u\"\\2\\u009e\\u009c\\3\\2\\2\\2\\u009e\\u009f\\3\\2\\2\\2\\u009f\\25\\3\")\n-        buf.write(u\"\\2\\2\\2\\u00a0\\u009e\\3\\2\\2\\2\\u00a1\\u00a5\\5\\\"\\22\\2\\u00a2\")\n-        buf.write(u\"\\u00a4\\5\\30\\r\\2\\u00a3\\u00a2\\3\\2\\2\\2\\u00a4\\u00a7\\3\\2\\2\")\n-        buf.write(u\"\\2\\u00a5\\u00a3\\3\\2\\2\\2\\u00a5\\u00a6\\3\\2\\2\\2\\u00a6\\27\\3\")\n-        buf.write(u\"\\2\\2\\2\\u00a7\\u00a5\\3\\2\\2\\2\\u00a8\\u00ab\\7Y\\2\\2\\u00a9\\u00ab\")\n-        buf.write(u\"\\5\\32\\16\\2\\u00aa\\u00a8\\3\\2\\2\\2\\u00aa\\u00a9\\3\\2\\2\\2\\u00ab\")\n-        buf.write(u\"\\31\\3\\2\\2\\2\\u00ac\\u00b2\\7\\34\\2\\2\\u00ad\\u00b3\\5\\36\\20\")\n-        buf.write(u\"\\2\\u00ae\\u00b3\\5\\34\\17\\2\\u00af\\u00b0\\5\\36\\20\\2\\u00b0\")\n-        buf.write(u\"\\u00b1\\5\\34\\17\\2\\u00b1\\u00b3\\3\\2\\2\\2\\u00b2\\u00ad\\3\\2\")\n-        buf.write(u\"\\2\\2\\u00b2\\u00ae\\3\\2\\2\\2\\u00b2\\u00af\\3\\2\\2\\2\\u00b3\\33\")\n-        buf.write(u\"\\3\\2\\2\\2\\u00b4\\u00b5\\7I\\2\\2\\u00b5\\u00b8\\7\\26\\2\\2\\u00b6\")\n-        buf.write(u\"\\u00b9\\5\\b\\5\\2\\u00b7\\u00b9\\5\\6\\4\\2\\u00b8\\u00b6\\3\\2\\2\")\n-        buf.write(u\"\\2\\u00b8\\u00b7\\3\\2\\2\\2\\u00b9\\u00ba\\3\\2\\2\\2\\u00ba\\u00bb\")\n-        buf.write(u\"\\7\\27\\2\\2\\u00bb\\35\\3\\2\\2\\2\\u00bc\\u00bd\\7J\\2\\2\\u00bd\\u00c0\")\n-        buf.write(u\"\\7\\26\\2\\2\\u00be\\u00c1\\5\\b\\5\\2\\u00bf\\u00c1\\5\\6\\4\\2\\u00c0\")\n-        buf.write(u\"\\u00be\\3\\2\\2\\2\\u00c0\\u00bf\\3\\2\\2\\2\\u00c1\\u00c2\\3\\2\\2\")\n-        buf.write(u\"\\2\\u00c2\\u00c3\\7\\27\\2\\2\\u00c3\\37\\3\\2\\2\\2\\u00c4\\u00c5\")\n-        buf.write(u\"\\b\\21\\1\\2\\u00c5\\u00c6\\5$\\23\\2\\u00c6\\u00d5\\3\\2\\2\\2\\u00c7\")\n-        buf.write(u\"\\u00c8\\f\\4\\2\\2\\u00c8\\u00ce\\7J\\2\\2\\u00c9\\u00cf\\5,\\27\\2\")\n-        buf.write(u\"\\u00ca\\u00cb\\7\\26\\2\\2\\u00cb\\u00cc\\5\\b\\5\\2\\u00cc\\u00cd\")\n-        buf.write(u\"\\7\\27\\2\\2\\u00cd\\u00cf\\3\\2\\2\\2\\u00ce\\u00c9\\3\\2\\2\\2\\u00ce\")\n-        buf.write(u\"\\u00ca\\3\\2\\2\\2\\u00cf\\u00d1\\3\\2\\2\\2\\u00d0\\u00d2\\5J&\\2\")\n-        buf.write(u\"\\u00d1\\u00d0\\3\\2\\2\\2\\u00d1\\u00d2\\3\\2\\2\\2\\u00d2\\u00d4\")\n-        buf.write(u\"\\3\\2\\2\\2\\u00d3\\u00c7\\3\\2\\2\\2\\u00d4\\u00d7\\3\\2\\2\\2\\u00d5\")\n-        buf.write(u\"\\u00d3\\3\\2\\2\\2\\u00d5\\u00d6\\3\\2\\2\\2\\u00d6!\\3\\2\\2\\2\\u00d7\")\n-        buf.write(u\"\\u00d5\\3\\2\\2\\2\\u00d8\\u00d9\\b\\22\\1\\2\\u00d9\\u00da\\5&\\24\")\n-        buf.write(u\"\\2\\u00da\\u00e9\\3\\2\\2\\2\\u00db\\u00dc\\f\\4\\2\\2\\u00dc\\u00e2\")\n-        buf.write(u\"\\7J\\2\\2\\u00dd\\u00e3\\5,\\27\\2\\u00de\\u00df\\7\\26\\2\\2\\u00df\")\n-        buf.write(u\"\\u00e0\\5\\b\\5\\2\\u00e0\\u00e1\\7\\27\\2\\2\\u00e1\\u00e3\\3\\2\\2\")\n-        buf.write(u\"\\2\\u00e2\\u00dd\\3\\2\\2\\2\\u00e2\\u00de\\3\\2\\2\\2\\u00e3\\u00e5\")\n-        buf.write(u\"\\3\\2\\2\\2\\u00e4\\u00e6\\5J&\\2\\u00e5\\u00e4\\3\\2\\2\\2\\u00e5\")\n-        buf.write(u\"\\u00e6\\3\\2\\2\\2\\u00e6\\u00e8\\3\\2\\2\\2\\u00e7\\u00db\\3\\2\\2\")\n-        buf.write(u\"\\2\\u00e8\\u00eb\\3\\2\\2\\2\\u00e9\\u00e7\\3\\2\\2\\2\\u00e9\\u00ea\")\n-        buf.write(u\"\\3\\2\\2\\2\\u00ea#\\3\\2\\2\\2\\u00eb\\u00e9\\3\\2\\2\\2\\u00ec\\u00f5\")\n-        buf.write(u\"\\5(\\25\\2\\u00ed\\u00f5\\5*\\26\\2\\u00ee\\u00f5\\5@!\\2\\u00ef\")\n-        buf.write(u\"\\u00f5\\5,\\27\\2\\u00f0\\u00f5\\5\\66\\34\\2\\u00f1\\u00f5\\58\\35\")\n-        buf.write(u\"\\2\\u00f2\\u00f5\\5:\\36\\2\\u00f3\\u00f5\\5<\\37\\2\\u00f4\\u00ec\")\n-        buf.write(u\"\\3\\2\\2\\2\\u00f4\\u00ed\\3\\2\\2\\2\\u00f4\\u00ee\\3\\2\\2\\2\\u00f4\")\n-        buf.write(u\"\\u00ef\\3\\2\\2\\2\\u00f4\\u00f0\\3\\2\\2\\2\\u00f4\\u00f1\\3\\2\\2\")\n-        buf.write(u\"\\2\\u00f4\\u00f2\\3\\2\\2\\2\\u00f4\\u00f3\\3\\2\\2\\2\\u00f5%\\3\\2\")\n-        buf.write(u\"\\2\\2\\u00f6\\u00fe\\5(\\25\\2\\u00f7\\u00fe\\5*\\26\\2\\u00f8\\u00fe\")\n-        buf.write(u\"\\5,\\27\\2\\u00f9\\u00fe\\5\\66\\34\\2\\u00fa\\u00fe\\58\\35\\2\\u00fb\")\n-        buf.write(u\"\\u00fe\\5:\\36\\2\\u00fc\\u00fe\\5<\\37\\2\\u00fd\\u00f6\\3\\2\\2\")\n-        buf.write(u\"\\2\\u00fd\\u00f7\\3\\2\\2\\2\\u00fd\\u00f8\\3\\2\\2\\2\\u00fd\\u00f9\")\n-        buf.write(u\"\\3\\2\\2\\2\\u00fd\\u00fa\\3\\2\\2\\2\\u00fd\\u00fb\\3\\2\\2\\2\\u00fd\")\n-        buf.write(u\"\\u00fc\\3\\2\\2\\2\\u00fe\\'\\3\\2\\2\\2\\u00ff\\u0100\\7\\24\\2\\2\\u0100\")\n-        buf.write(u\"\\u0101\\5\\b\\5\\2\\u0101\\u0102\\7\\25\\2\\2\\u0102\\u0110\\3\\2\\2\")\n-        buf.write(u\"\\2\\u0103\\u0104\\7\\32\\2\\2\\u0104\\u0105\\5\\b\\5\\2\\u0105\\u0106\")\n-        buf.write(u\"\\7\\33\\2\\2\\u0106\\u0110\\3\\2\\2\\2\\u0107\\u0108\\7\\26\\2\\2\\u0108\")\n-        buf.write(u\"\\u0109\\5\\b\\5\\2\\u0109\\u010a\\7\\27\\2\\2\\u010a\\u0110\\3\\2\\2\")\n-        buf.write(u\"\\2\\u010b\\u010c\\7\\30\\2\\2\\u010c\\u010d\\5\\b\\5\\2\\u010d\\u010e\")\n-        buf.write(u\"\\7\\31\\2\\2\\u010e\\u0110\\3\\2\\2\\2\\u010f\\u00ff\\3\\2\\2\\2\\u010f\")\n-        buf.write(u\"\\u0103\\3\\2\\2\\2\\u010f\\u0107\\3\\2\\2\\2\\u010f\\u010b\\3\\2\\2\")\n-        buf.write(u\"\\2\\u0110)\\3\\2\\2\\2\\u0111\\u0112\\7\\34\\2\\2\\u0112\\u0113\\5\")\n-        buf.write(u\"\\b\\5\\2\\u0113\\u0114\\7\\34\\2\\2\\u0114+\\3\\2\\2\\2\\u0115\\u0117\")\n-        buf.write(u\"\\t\\5\\2\\2\\u0116\\u0118\\5J&\\2\\u0117\\u0116\\3\\2\\2\\2\\u0117\")\n-        buf.write(u\"\\u0118\\3\\2\\2\\2\\u0118\\u011f\\3\\2\\2\\2\\u0119\\u011f\\7N\\2\\2\")\n-        buf.write(u\"\\u011a\\u011f\\7L\\2\\2\\u011b\\u011f\\5\\62\\32\\2\\u011c\\u011f\")\n-        buf.write(u\"\\5.\\30\\2\\u011d\\u011f\\5\\60\\31\\2\\u011e\\u0115\\3\\2\\2\\2\\u011e\")\n-        buf.write(u\"\\u0119\\3\\2\\2\\2\\u011e\\u011a\\3\\2\\2\\2\\u011e\\u011b\\3\\2\\2\")\n-        buf.write(u\"\\2\\u011e\\u011c\\3\\2\\2\\2\\u011e\\u011d\\3\\2\\2\\2\\u011f-\\3\\2\")\n-        buf.write(u\"\\2\\2\\u0120\\u0121\\7\\37\\2\\2\\u0121\\u0122\\5\\b\\5\\2\\u0122\\u0123\")\n-        buf.write(u\"\\t\\6\\2\\2\\u0123/\\3\\2\\2\\2\\u0124\\u0125\\t\\7\\2\\2\\u0125\\u0126\")\n-        buf.write(u\"\\5\\b\\5\\2\\u0126\\u0127\\7 \\2\\2\\u0127\\61\\3\\2\\2\\2\\u0128\\u0129\")\n-        buf.write(u\"\\7H\\2\\2\\u0129\\u012a\\7\\26\\2\\2\\u012a\\u012b\\5\\64\\33\\2\\u012b\")\n-        buf.write(u\"\\u012c\\7\\27\\2\\2\\u012c\\63\\3\\2\\2\\2\\u012d\\u012f\\7M\\2\\2\\u012e\")\n-        buf.write(u\"\\u012d\\3\\2\\2\\2\\u012f\\u0132\\3\\2\\2\\2\\u0130\\u012e\\3\\2\\2\")\n-        buf.write(u\"\\2\\u0130\\u0131\\3\\2\\2\\2\\u0131\\65\\3\\2\\2\\2\\u0132\\u0130\\3\")\n-        buf.write(u\"\\2\\2\\2\\u0133\\u0134\\7D\\2\\2\\u0134\\u0135\\7\\26\\2\\2\\u0135\")\n-        buf.write(u\"\\u0136\\5\\b\\5\\2\\u0136\\u0137\\7\\27\\2\\2\\u0137\\u0138\\7\\26\")\n-        buf.write(u\"\\2\\2\\u0138\\u0139\\5\\b\\5\\2\\u0139\\u013a\\7\\27\\2\\2\\u013a\\67\")\n-        buf.write(u\"\\3\\2\\2\\2\\u013b\\u013c\\t\\b\\2\\2\\u013c\\u013d\\7\\26\\2\\2\\u013d\")\n-        buf.write(u\"\\u013e\\5\\b\\5\\2\\u013e\\u013f\\7\\27\\2\\2\\u013f\\u0140\\7\\26\")\n-        buf.write(u\"\\2\\2\\u0140\\u0141\\5\\b\\5\\2\\u0141\\u0142\\7\\27\\2\\2\\u01429\")\n-        buf.write(u\"\\3\\2\\2\\2\\u0143\\u0144\\7;\\2\\2\\u0144\\u0145\\5\\b\\5\\2\\u0145\")\n-        buf.write(u\"\\u0146\\7<\\2\\2\\u0146;\\3\\2\\2\\2\\u0147\\u0148\\7=\\2\\2\\u0148\")\n-        buf.write(u\"\\u0149\\5\\b\\5\\2\\u0149\\u014a\\7>\\2\\2\\u014a=\\3\\2\\2\\2\\u014b\")\n-        buf.write(u\"\\u014c\\t\\t\\2\\2\\u014c?\\3\\2\\2\\2\\u014d\\u015a\\5> \\2\\u014e\")\n-        buf.write(u\"\\u0150\\5J&\\2\\u014f\\u014e\\3\\2\\2\\2\\u014f\\u0150\\3\\2\\2\\2\")\n-        buf.write(u\"\\u0150\\u0152\\3\\2\\2\\2\\u0151\\u0153\\5L\\'\\2\\u0152\\u0151\\3\")\n-        buf.write(u\"\\2\\2\\2\\u0152\\u0153\\3\\2\\2\\2\\u0153\\u015b\\3\\2\\2\\2\\u0154\")\n-        buf.write(u\"\\u0156\\5L\\'\\2\\u0155\\u0154\\3\\2\\2\\2\\u0155\\u0156\\3\\2\\2\\2\")\n-        buf.write(u\"\\u0156\\u0158\\3\\2\\2\\2\\u0157\\u0159\\5J&\\2\\u0158\\u0157\\3\")\n-        buf.write(u\"\\2\\2\\2\\u0158\\u0159\\3\\2\\2\\2\\u0159\\u015b\\3\\2\\2\\2\\u015a\")\n-        buf.write(u\"\\u014f\\3\\2\\2\\2\\u015a\\u0155\\3\\2\\2\\2\\u015b\\u0161\\3\\2\\2\")\n-        buf.write(u\"\\2\\u015c\\u015d\\7\\24\\2\\2\\u015d\\u015e\\5F$\\2\\u015e\\u015f\")\n-        buf.write(u\"\\7\\25\\2\\2\\u015f\\u0162\\3\\2\\2\\2\\u0160\\u0162\\5H%\\2\\u0161\")\n-        buf.write(u\"\\u015c\\3\\2\\2\\2\\u0161\\u0160\\3\\2\\2\\2\\u0162\\u019c\\3\\2\\2\")\n-        buf.write(u\"\\2\\u0163\\u0165\\t\\5\\2\\2\\u0164\\u0166\\5J&\\2\\u0165\\u0164\")\n-        buf.write(u\"\\3\\2\\2\\2\\u0165\\u0166\\3\\2\\2\\2\\u0166\\u0167\\3\\2\\2\\2\\u0167\")\n-        buf.write(u\"\\u0168\\7\\24\\2\\2\\u0168\\u0169\\5B\\\"\\2\\u0169\\u016a\\7\\25\\2\")\n-        buf.write(u\"\\2\\u016a\\u019c\\3\\2\\2\\2\\u016b\\u0172\\7#\\2\\2\\u016c\\u016d\")\n-        buf.write(u\"\\5J&\\2\\u016d\\u016e\\5L\\'\\2\\u016e\\u0173\\3\\2\\2\\2\\u016f\\u0170\")\n-        buf.write(u\"\\5L\\'\\2\\u0170\\u0171\\5J&\\2\\u0171\\u0173\\3\\2\\2\\2\\u0172\\u016c\")\n-        buf.write(u\"\\3\\2\\2\\2\\u0172\\u016f\\3\\2\\2\\2\\u0172\\u0173\\3\\2\\2\\2\\u0173\")\n-        buf.write(u\"\\u017a\\3\\2\\2\\2\\u0174\\u0176\\5\\n\\6\\2\\u0175\\u0174\\3\\2\\2\")\n-        buf.write(u\"\\2\\u0175\\u0176\\3\\2\\2\\2\\u0176\\u0177\\3\\2\\2\\2\\u0177\\u017b\")\n-        buf.write(u\"\\7L\\2\\2\\u0178\\u017b\\5\\66\\34\\2\\u0179\\u017b\\5\\n\\6\\2\\u017a\")\n-        buf.write(u\"\\u0175\\3\\2\\2\\2\\u017a\\u0178\\3\\2\\2\\2\\u017a\\u0179\\3\\2\\2\")\n-        buf.write(u\"\\2\\u017b\\u019c\\3\\2\\2\\2\\u017c\\u0181\\7?\\2\\2\\u017d\\u017e\")\n-        buf.write(u\"\\7\\32\\2\\2\\u017e\\u017f\\5\\b\\5\\2\\u017f\\u0180\\7\\33\\2\\2\\u0180\")\n-        buf.write(u\"\\u0182\\3\\2\\2\\2\\u0181\\u017d\\3\\2\\2\\2\\u0181\\u0182\\3\\2\\2\")\n-        buf.write(u\"\\2\\u0182\\u0183\\3\\2\\2\\2\\u0183\\u0184\\7\\26\\2\\2\\u0184\\u0185\")\n-        buf.write(u\"\\5\\b\\5\\2\\u0185\\u0186\\7\\27\\2\\2\\u0186\\u019c\\3\\2\\2\\2\\u0187\")\n-        buf.write(u\"\\u0188\\7@\\2\\2\\u0188\\u0189\\7\\26\\2\\2\\u0189\\u018a\\5\\b\\5\")\n-        buf.write(u\"\\2\\u018a\\u018b\\7\\27\\2\\2\\u018b\\u019c\\3\\2\\2\\2\\u018c\\u0193\")\n-        buf.write(u\"\\t\\n\\2\\2\\u018d\\u018e\\5N(\\2\\u018e\\u018f\\5L\\'\\2\\u018f\\u0194\")\n-        buf.write(u\"\\3\\2\\2\\2\\u0190\\u0191\\5L\\'\\2\\u0191\\u0192\\5N(\\2\\u0192\\u0194\")\n-        buf.write(u\"\\3\\2\\2\\2\\u0193\\u018d\\3\\2\\2\\2\\u0193\\u0190\\3\\2\\2\\2\\u0194\")\n-        buf.write(u\"\\u0195\\3\\2\\2\\2\\u0195\\u0196\\5\\f\\7\\2\\u0196\\u019c\\3\\2\\2\")\n-        buf.write(u\"\\2\\u0197\\u0198\\7!\\2\\2\\u0198\\u0199\\5D#\\2\\u0199\\u019a\\5\")\n-        buf.write(u\"\\f\\7\\2\\u019a\\u019c\\3\\2\\2\\2\\u019b\\u014d\\3\\2\\2\\2\\u019b\")\n-        buf.write(u\"\\u0163\\3\\2\\2\\2\\u019b\\u016b\\3\\2\\2\\2\\u019b\\u017c\\3\\2\\2\")\n-        buf.write(u\"\\2\\u019b\\u0187\\3\\2\\2\\2\\u019b\\u018c\\3\\2\\2\\2\\u019b\\u0197\")\n-        buf.write(u\"\\3\\2\\2\\2\\u019cA\\3\\2\\2\\2\\u019d\\u019e\\5\\b\\5\\2\\u019e\\u019f\")\n-        buf.write(u\"\\7\\3\\2\\2\\u019f\\u01a0\\5B\\\"\\2\\u01a0\\u01a3\\3\\2\\2\\2\\u01a1\")\n-        buf.write(u\"\\u01a3\\5\\b\\5\\2\\u01a2\\u019d\\3\\2\\2\\2\\u01a2\\u01a1\\3\\2\\2\")\n-        buf.write(u\"\\2\\u01a3C\\3\\2\\2\\2\\u01a4\\u01a5\\7I\\2\\2\\u01a5\\u01a6\\7\\26\")\n-        buf.write(u\"\\2\\2\\u01a6\\u01a7\\t\\5\\2\\2\\u01a7\\u01a8\\7\\\"\\2\\2\\u01a8\\u01ad\")\n-        buf.write(u\"\\5\\b\\5\\2\\u01a9\\u01aa\\7J\\2\\2\\u01aa\\u01ab\\7\\26\\2\\2\\u01ab\")\n-        buf.write(u\"\\u01ac\\t\\3\\2\\2\\u01ac\\u01ae\\7\\27\\2\\2\\u01ad\\u01a9\\3\\2\\2\")\n-        buf.write(u\"\\2\\u01ad\\u01ae\\3\\2\\2\\2\\u01ae\\u01af\\3\\2\\2\\2\\u01af\\u01b0\")\n-        buf.write(u\"\\7\\27\\2\\2\\u01b0E\\3\\2\\2\\2\\u01b1\\u01b7\\5\\b\\5\\2\\u01b2\\u01b3\")\n-        buf.write(u\"\\5\\b\\5\\2\\u01b3\\u01b4\\7\\3\\2\\2\\u01b4\\u01b5\\5F$\\2\\u01b5\")\n-        buf.write(u\"\\u01b7\\3\\2\\2\\2\\u01b6\\u01b1\\3\\2\\2\\2\\u01b6\\u01b2\\3\\2\\2\")\n-        buf.write(u\"\\2\\u01b7G\\3\\2\\2\\2\\u01b8\\u01b9\\5\\16\\b\\2\\u01b9I\\3\\2\\2\\2\")\n-        buf.write(u\"\\u01ba\\u01c0\\7I\\2\\2\\u01bb\\u01c1\\5,\\27\\2\\u01bc\\u01bd\\7\")\n-        buf.write(u\"\\26\\2\\2\\u01bd\\u01be\\5\\b\\5\\2\\u01be\\u01bf\\7\\27\\2\\2\\u01bf\")\n-        buf.write(u\"\\u01c1\\3\\2\\2\\2\\u01c0\\u01bb\\3\\2\\2\\2\\u01c0\\u01bc\\3\\2\\2\")\n-        buf.write(u\"\\2\\u01c1K\\3\\2\\2\\2\\u01c2\\u01c8\\7J\\2\\2\\u01c3\\u01c9\\5,\\27\")\n-        buf.write(u\"\\2\\u01c4\\u01c5\\7\\26\\2\\2\\u01c5\\u01c6\\5\\b\\5\\2\\u01c6\\u01c7\")\n-        buf.write(u\"\\7\\27\\2\\2\\u01c7\\u01c9\\3\\2\\2\\2\\u01c8\\u01c3\\3\\2\\2\\2\\u01c8\")\n-        buf.write(u\"\\u01c4\\3\\2\\2\\2\\u01c9M\\3\\2\\2\\2\\u01ca\\u01cb\\7I\\2\\2\\u01cb\")\n-        buf.write(u\"\\u01cc\\7\\26\\2\\2\\u01cc\\u01cd\\5\\6\\4\\2\\u01cd\\u01ce\\7\\27\")\n-        buf.write(u\"\\2\\2\\u01ceO\\3\\2\\2\\2\\u01cf\\u01d0\\7I\\2\\2\\u01d0\\u01d1\\7\")\n-        buf.write(u\"\\26\\2\\2\\u01d1\\u01d2\\5\\6\\4\\2\\u01d2\\u01d3\\7\\27\\2\\2\\u01d3\")\n-        buf.write(u\"Q\\3\\2\\2\\2.\\\\mx\\u0083\\u008b\\u008d\\u0095\\u0098\\u009e\\u00a5\")\n-        buf.write(u\"\\u00aa\\u00b2\\u00b8\\u00c0\\u00ce\\u00d1\\u00d5\\u00e2\\u00e5\")\n-        buf.write(u\"\\u00e9\\u00f4\\u00fd\\u010f\\u0117\\u011e\\u0130\\u014f\\u0152\")\n-        buf.write(u\"\\u0155\\u0158\\u015a\\u0161\\u0165\\u0172\\u0175\\u017a\\u0181\")\n-        buf.write(u\"\\u0193\\u019b\\u01a2\\u01ad\\u01b6\\u01c0\\u01c8\")\n-        return buf.getvalue()\n-\n+    return [\n+        4,1,88,467,2,0,7,0,2,1,7,1,2,2,7,2,2,3,7,3,2,4,7,4,2,5,7,5,2,6,7,\n+        6,2,7,7,7,2,8,7,8,2,9,7,9,2,10,7,10,2,11,7,11,2,12,7,12,2,13,7,13,\n+        2,14,7,14,2,15,7,15,2,16,7,16,2,17,7,17,2,18,7,18,2,19,7,19,2,20,\n+        7,20,2,21,7,21,2,22,7,22,2,23,7,23,2,24,7,24,2,25,7,25,2,26,7,26,\n+        2,27,7,27,2,28,7,28,2,29,7,29,2,30,7,30,2,31,7,31,2,32,7,32,2,33,\n+        7,33,2,34,7,34,2,35,7,35,2,36,7,36,2,37,7,37,2,38,7,38,2,39,7,39,\n+        1,0,1,0,1,1,1,1,1,1,1,1,1,1,1,1,5,1,89,8,1,10,1,12,1,92,9,1,1,2,\n+        1,2,1,2,1,2,1,3,1,3,1,4,1,4,1,4,1,4,1,4,1,4,5,4,106,8,4,10,4,12,\n+        4,109,9,4,1,5,1,5,1,5,1,5,1,5,1,5,5,5,117,8,5,10,5,12,5,120,9,5,\n+        1,6,1,6,1,6,1,6,1,6,1,6,5,6,128,8,6,10,6,12,6,131,9,6,1,7,1,7,1,\n+        7,4,7,136,8,7,11,7,12,7,137,3,7,140,8,7,1,8,1,8,1,8,1,8,5,8,146,\n+        8,8,10,8,12,8,149,9,8,3,8,151,8,8,1,9,1,9,5,9,155,8,9,10,9,12,9,\n+        158,9,9,1,10,1,10,5,10,162,8,10,10,10,12,10,165,9,10,1,11,1,11,3,\n+        11,169,8,11,1,12,1,12,1,12,1,12,1,12,1,12,3,12,177,8,12,1,13,1,13,\n+        1,13,1,13,3,13,183,8,13,1,13,1,13,1,14,1,14,1,14,1,14,3,14,191,8,\n+        14,1,14,1,14,1,15,1,15,1,15,1,15,1,15,1,15,1,15,1,15,1,15,1,15,3,\n+        15,205,8,15,1,15,3,15,208,8,15,5,15,210,8,15,10,15,12,15,213,9,15,\n+        1,16,1,16,1,16,1,16,1,16,1,16,1,16,1,16,1,16,1,16,3,16,225,8,16,\n+        1,16,3,16,228,8,16,5,16,230,8,16,10,16,12,16,233,9,16,1,17,1,17,\n+        1,17,1,17,1,17,1,17,1,17,1,17,3,17,243,8,17,1,18,1,18,1,18,1,18,\n+        1,18,1,18,1,18,3,18,252,8,18,1,19,1,19,1,19,1,19,1,19,1,19,1,19,\n+        1,19,1,19,1,19,1,19,1,19,1,19,1,19,1,19,1,19,3,19,270,8,19,1,20,\n+        1,20,1,20,1,20,1,21,1,21,3,21,278,8,21,1,21,1,21,1,21,1,21,1,21,\n+        3,21,285,8,21,1,22,1,22,1,22,1,22,1,23,1,23,1,23,1,23,1,24,1,24,\n+        1,24,1,24,1,24,1,25,5,25,301,8,25,10,25,12,25,304,9,25,1,26,1,26,\n+        1,26,1,26,1,26,1,26,1,26,1,26,1,27,1,27,1,27,1,27,1,27,1,27,1,27,\n+        1,27,1,28,1,28,1,28,1,28,1,29,1,29,1,29,1,29,1,30,1,30,1,31,1,31,\n+        3,31,334,8,31,1,31,3,31,337,8,31,1,31,3,31,340,8,31,1,31,3,31,343,\n+        8,31,3,31,345,8,31,1,31,1,31,1,31,1,31,1,31,3,31,352,8,31,1,31,1,\n+        31,3,31,356,8,31,1,31,1,31,1,31,1,31,1,31,1,31,1,31,1,31,1,31,1,\n+        31,1,31,3,31,369,8,31,1,31,3,31,372,8,31,1,31,1,31,1,31,3,31,377,\n+        8,31,1,31,1,31,1,31,1,31,1,31,3,31,384,8,31,1,31,1,31,1,31,1,31,\n+        1,31,1,31,1,31,1,31,1,31,1,31,1,31,1,31,1,31,1,31,1,31,1,31,3,31,\n+        402,8,31,1,31,1,31,1,31,1,31,1,31,1,31,3,31,410,8,31,1,32,1,32,1,\n+        32,1,32,1,32,3,32,417,8,32,1,33,1,33,1,33,1,33,1,33,1,33,1,33,1,\n+        33,1,33,3,33,428,8,33,1,33,1,33,1,34,1,34,1,34,1,34,1,34,3,34,437,\n+        8,34,1,35,1,35,1,36,1,36,1,36,1,36,1,36,1,36,3,36,447,8,36,1,37,\n+        1,37,1,37,1,37,1,37,1,37,3,37,455,8,37,1,38,1,38,1,38,1,38,1,38,\n+        1,39,1,39,1,39,1,39,1,39,1,39,0,6,2,8,10,12,30,32,40,0,2,4,6,8,10,\n+        12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48,50,52,54,\n+        56,58,60,62,64,66,68,70,72,74,76,78,0,9,2,0,77,80,83,84,1,0,14,15,\n+        3,0,16,17,63,65,73,73,2,0,75,75,88,88,1,0,26,27,2,0,26,26,28,28,\n+        1,0,67,69,1,0,36,56,1,0,34,35,495,0,80,1,0,0,0,2,82,1,0,0,0,4,93,\n+        1,0,0,0,6,97,1,0,0,0,8,99,1,0,0,0,10,110,1,0,0,0,12,121,1,0,0,0,\n+        14,139,1,0,0,0,16,150,1,0,0,0,18,152,1,0,0,0,20,159,1,0,0,0,22,168,\n+        1,0,0,0,24,170,1,0,0,0,26,178,1,0,0,0,28,186,1,0,0,0,30,194,1,0,\n+        0,0,32,214,1,0,0,0,34,242,1,0,0,0,36,251,1,0,0,0,38,269,1,0,0,0,\n+        40,271,1,0,0,0,42,284,1,0,0,0,44,286,1,0,0,0,46,290,1,0,0,0,48,294,\n+        1,0,0,0,50,302,1,0,0,0,52,305,1,0,0,0,54,313,1,0,0,0,56,321,1,0,\n+        0,0,58,325,1,0,0,0,60,329,1,0,0,0,62,409,1,0,0,0,64,416,1,0,0,0,\n+        66,418,1,0,0,0,68,436,1,0,0,0,70,438,1,0,0,0,72,440,1,0,0,0,74,448,\n+        1,0,0,0,76,456,1,0,0,0,78,461,1,0,0,0,80,81,3,2,1,0,81,1,1,0,0,0,\n+        82,83,6,1,-1,0,83,84,3,6,3,0,84,90,1,0,0,0,85,86,10,2,0,0,86,87,\n+        7,0,0,0,87,89,3,2,1,3,88,85,1,0,0,0,89,92,1,0,0,0,90,88,1,0,0,0,\n+        90,91,1,0,0,0,91,3,1,0,0,0,92,90,1,0,0,0,93,94,3,6,3,0,94,95,5,77,\n+        0,0,95,96,3,6,3,0,96,5,1,0,0,0,97,98,3,8,4,0,98,7,1,0,0,0,99,100,\n+        6,4,-1,0,100,101,3,10,5,0,101,107,1,0,0,0,102,103,10,2,0,0,103,104,\n+        7,1,0,0,104,106,3,8,4,3,105,102,1,0,0,0,106,109,1,0,0,0,107,105,\n+        1,0,0,0,107,108,1,0,0,0,108,9,1,0,0,0,109,107,1,0,0,0,110,111,6,\n+        5,-1,0,111,112,3,14,7,0,112,118,1,0,0,0,113,114,10,2,0,0,114,115,\n+        7,2,0,0,115,117,3,10,5,3,116,113,1,0,0,0,117,120,1,0,0,0,118,116,\n+        1,0,0,0,118,119,1,0,0,0,119,11,1,0,0,0,120,118,1,0,0,0,121,122,6,\n+        6,-1,0,122,123,3,16,8,0,123,129,1,0,0,0,124,125,10,2,0,0,125,126,\n+        7,2,0,0,126,128,3,12,6,3,127,124,1,0,0,0,128,131,1,0,0,0,129,127,\n+        1,0,0,0,129,130,1,0,0,0,130,13,1,0,0,0,131,129,1,0,0,0,132,133,7,\n+        1,0,0,133,140,3,14,7,0,134,136,3,18,9,0,135,134,1,0,0,0,136,137,\n+        1,0,0,0,137,135,1,0,0,0,137,138,1,0,0,0,138,140,1,0,0,0,139,132,\n+        1,0,0,0,139,135,1,0,0,0,140,15,1,0,0,0,141,142,7,1,0,0,142,151,3,\n+        16,8,0,143,147,3,18,9,0,144,146,3,20,10,0,145,144,1,0,0,0,146,149,\n+        1,0,0,0,147,145,1,0,0,0,147,148,1,0,0,0,148,151,1,0,0,0,149,147,\n+        1,0,0,0,150,141,1,0,0,0,150,143,1,0,0,0,151,17,1,0,0,0,152,156,3,\n+        30,15,0,153,155,3,22,11,0,154,153,1,0,0,0,155,158,1,0,0,0,156,154,\n+        1,0,0,0,156,157,1,0,0,0,157,19,1,0,0,0,158,156,1,0,0,0,159,163,3,\n+        32,16,0,160,162,3,22,11,0,161,160,1,0,0,0,162,165,1,0,0,0,163,161,\n+        1,0,0,0,163,164,1,0,0,0,164,21,1,0,0,0,165,163,1,0,0,0,166,169,5,\n+        87,0,0,167,169,3,24,12,0,168,166,1,0,0,0,168,167,1,0,0,0,169,23,\n+        1,0,0,0,170,176,5,26,0,0,171,177,3,28,14,0,172,177,3,26,13,0,173,\n+        174,3,28,14,0,174,175,3,26,13,0,175,177,1,0,0,0,176,171,1,0,0,0,\n+        176,172,1,0,0,0,176,173,1,0,0,0,177,25,1,0,0,0,178,179,5,71,0,0,\n+        179,182,5,20,0,0,180,183,3,6,3,0,181,183,3,4,2,0,182,180,1,0,0,0,\n+        182,181,1,0,0,0,183,184,1,0,0,0,184,185,5,21,0,0,185,27,1,0,0,0,\n+        186,187,5,72,0,0,187,190,5,20,0,0,188,191,3,6,3,0,189,191,3,4,2,\n+        0,190,188,1,0,0,0,190,189,1,0,0,0,191,192,1,0,0,0,192,193,5,21,0,\n+        0,193,29,1,0,0,0,194,195,6,15,-1,0,195,196,3,34,17,0,196,211,1,0,\n+        0,0,197,198,10,2,0,0,198,204,5,72,0,0,199,205,3,42,21,0,200,201,\n+        5,20,0,0,201,202,3,6,3,0,202,203,5,21,0,0,203,205,1,0,0,0,204,199,\n+        1,0,0,0,204,200,1,0,0,0,205,207,1,0,0,0,206,208,3,72,36,0,207,206,\n+        1,0,0,0,207,208,1,0,0,0,208,210,1,0,0,0,209,197,1,0,0,0,210,213,\n+        1,0,0,0,211,209,1,0,0,0,211,212,1,0,0,0,212,31,1,0,0,0,213,211,1,\n+        0,0,0,214,215,6,16,-1,0,215,216,3,36,18,0,216,231,1,0,0,0,217,218,\n+        10,2,0,0,218,224,5,72,0,0,219,225,3,42,21,0,220,221,5,20,0,0,221,\n+        222,3,6,3,0,222,223,5,21,0,0,223,225,1,0,0,0,224,219,1,0,0,0,224,\n+        220,1,0,0,0,225,227,1,0,0,0,226,228,3,72,36,0,227,226,1,0,0,0,227,\n+        228,1,0,0,0,228,230,1,0,0,0,229,217,1,0,0,0,230,233,1,0,0,0,231,\n+        229,1,0,0,0,231,232,1,0,0,0,232,33,1,0,0,0,233,231,1,0,0,0,234,243,\n+        3,38,19,0,235,243,3,40,20,0,236,243,3,62,31,0,237,243,3,42,21,0,\n+        238,243,3,52,26,0,239,243,3,54,27,0,240,243,3,56,28,0,241,243,3,\n+        58,29,0,242,234,1,0,0,0,242,235,1,0,0,0,242,236,1,0,0,0,242,237,\n+        1,0,0,0,242,238,1,0,0,0,242,239,1,0,0,0,242,240,1,0,0,0,242,241,\n+        1,0,0,0,243,35,1,0,0,0,244,252,3,38,19,0,245,252,3,40,20,0,246,252,\n+        3,42,21,0,247,252,3,52,26,0,248,252,3,54,27,0,249,252,3,56,28,0,\n+        250,252,3,58,29,0,251,244,1,0,0,0,251,245,1,0,0,0,251,246,1,0,0,\n+        0,251,247,1,0,0,0,251,248,1,0,0,0,251,249,1,0,0,0,251,250,1,0,0,\n+        0,252,37,1,0,0,0,253,254,5,18,0,0,254,255,3,6,3,0,255,256,5,19,0,\n+        0,256,270,1,0,0,0,257,258,5,24,0,0,258,259,3,6,3,0,259,260,5,25,\n+        0,0,260,270,1,0,0,0,261,262,5,20,0,0,262,263,3,6,3,0,263,264,5,21,\n+        0,0,264,270,1,0,0,0,265,266,5,22,0,0,266,267,3,6,3,0,267,268,5,23,\n+        0,0,268,270,1,0,0,0,269,253,1,0,0,0,269,257,1,0,0,0,269,261,1,0,\n+        0,0,269,265,1,0,0,0,270,39,1,0,0,0,271,272,5,26,0,0,272,273,3,6,\n+        3,0,273,274,5,26,0,0,274,41,1,0,0,0,275,277,7,3,0,0,276,278,3,72,\n+        36,0,277,276,1,0,0,0,277,278,1,0,0,0,278,285,1,0,0,0,279,285,5,76,\n+        0,0,280,285,5,74,0,0,281,285,3,48,24,0,282,285,3,44,22,0,283,285,\n+        3,46,23,0,284,275,1,0,0,0,284,279,1,0,0,0,284,280,1,0,0,0,284,281,\n+        1,0,0,0,284,282,1,0,0,0,284,283,1,0,0,0,285,43,1,0,0,0,286,287,5,\n+        29,0,0,287,288,3,6,3,0,288,289,7,4,0,0,289,45,1,0,0,0,290,291,7,\n+        5,0,0,291,292,3,6,3,0,292,293,5,30,0,0,293,47,1,0,0,0,294,295,5,\n+        70,0,0,295,296,5,20,0,0,296,297,3,50,25,0,297,298,5,21,0,0,298,49,\n+        1,0,0,0,299,301,5,75,0,0,300,299,1,0,0,0,301,304,1,0,0,0,302,300,\n+        1,0,0,0,302,303,1,0,0,0,303,51,1,0,0,0,304,302,1,0,0,0,305,306,5,\n+        66,0,0,306,307,5,20,0,0,307,308,3,6,3,0,308,309,5,21,0,0,309,310,\n+        5,20,0,0,310,311,3,6,3,0,311,312,5,21,0,0,312,53,1,0,0,0,313,314,\n+        7,6,0,0,314,315,5,20,0,0,315,316,3,6,3,0,316,317,5,21,0,0,317,318,\n+        5,20,0,0,318,319,3,6,3,0,319,320,5,21,0,0,320,55,1,0,0,0,321,322,\n+        5,57,0,0,322,323,3,6,3,0,323,324,5,58,0,0,324,57,1,0,0,0,325,326,\n+        5,59,0,0,326,327,3,6,3,0,327,328,5,60,0,0,328,59,1,0,0,0,329,330,\n+        7,7,0,0,330,61,1,0,0,0,331,344,3,60,30,0,332,334,3,72,36,0,333,332,\n+        1,0,0,0,333,334,1,0,0,0,334,336,1,0,0,0,335,337,3,74,37,0,336,335,\n+        1,0,0,0,336,337,1,0,0,0,337,345,1,0,0,0,338,340,3,74,37,0,339,338,\n+        1,0,0,0,339,340,1,0,0,0,340,342,1,0,0,0,341,343,3,72,36,0,342,341,\n+        1,0,0,0,342,343,1,0,0,0,343,345,1,0,0,0,344,333,1,0,0,0,344,339,\n+        1,0,0,0,345,351,1,0,0,0,346,347,5,18,0,0,347,348,3,68,34,0,348,349,\n+        5,19,0,0,349,352,1,0,0,0,350,352,3,70,35,0,351,346,1,0,0,0,351,350,\n+        1,0,0,0,352,410,1,0,0,0,353,355,7,3,0,0,354,356,3,72,36,0,355,354,\n+        1,0,0,0,355,356,1,0,0,0,356,357,1,0,0,0,357,358,5,18,0,0,358,359,\n+        3,64,32,0,359,360,5,19,0,0,360,410,1,0,0,0,361,368,5,33,0,0,362,\n+        363,3,72,36,0,363,364,3,74,37,0,364,369,1,0,0,0,365,366,3,74,37,\n+        0,366,367,3,72,36,0,367,369,1,0,0,0,368,362,1,0,0,0,368,365,1,0,\n+        0,0,368,369,1,0,0,0,369,376,1,0,0,0,370,372,3,8,4,0,371,370,1,0,\n+        0,0,371,372,1,0,0,0,372,373,1,0,0,0,373,377,5,74,0,0,374,377,3,52,\n+        26,0,375,377,3,8,4,0,376,371,1,0,0,0,376,374,1,0,0,0,376,375,1,0,\n+        0,0,377,410,1,0,0,0,378,383,5,61,0,0,379,380,5,24,0,0,380,381,3,\n+        6,3,0,381,382,5,25,0,0,382,384,1,0,0,0,383,379,1,0,0,0,383,384,1,\n+        0,0,0,384,385,1,0,0,0,385,386,5,20,0,0,386,387,3,6,3,0,387,388,5,\n+        21,0,0,388,410,1,0,0,0,389,390,5,62,0,0,390,391,5,20,0,0,391,392,\n+        3,6,3,0,392,393,5,21,0,0,393,410,1,0,0,0,394,401,7,8,0,0,395,396,\n+        3,76,38,0,396,397,3,74,37,0,397,402,1,0,0,0,398,399,3,74,37,0,399,\n+        400,3,76,38,0,400,402,1,0,0,0,401,395,1,0,0,0,401,398,1,0,0,0,402,\n+        403,1,0,0,0,403,404,3,10,5,0,404,410,1,0,0,0,405,406,5,31,0,0,406,\n+        407,3,66,33,0,407,408,3,10,5,0,408,410,1,0,0,0,409,331,1,0,0,0,409,\n+        353,1,0,0,0,409,361,1,0,0,0,409,378,1,0,0,0,409,389,1,0,0,0,409,\n+        394,1,0,0,0,409,405,1,0,0,0,410,63,1,0,0,0,411,412,3,6,3,0,412,413,\n+        5,1,0,0,413,414,3,64,32,0,414,417,1,0,0,0,415,417,3,6,3,0,416,411,\n+        1,0,0,0,416,415,1,0,0,0,417,65,1,0,0,0,418,419,5,71,0,0,419,420,\n+        5,20,0,0,420,421,7,3,0,0,421,422,5,32,0,0,422,427,3,6,3,0,423,424,\n+        5,72,0,0,424,425,5,20,0,0,425,426,7,1,0,0,426,428,5,21,0,0,427,423,\n+        1,0,0,0,427,428,1,0,0,0,428,429,1,0,0,0,429,430,5,21,0,0,430,67,\n+        1,0,0,0,431,437,3,6,3,0,432,433,3,6,3,0,433,434,5,1,0,0,434,435,\n+        3,68,34,0,435,437,1,0,0,0,436,431,1,0,0,0,436,432,1,0,0,0,437,69,\n+        1,0,0,0,438,439,3,12,6,0,439,71,1,0,0,0,440,446,5,71,0,0,441,447,\n+        3,42,21,0,442,443,5,20,0,0,443,444,3,6,3,0,444,445,5,21,0,0,445,\n+        447,1,0,0,0,446,441,1,0,0,0,446,442,1,0,0,0,447,73,1,0,0,0,448,454,\n+        5,72,0,0,449,455,3,42,21,0,450,451,5,20,0,0,451,452,3,6,3,0,452,\n+        453,5,21,0,0,453,455,1,0,0,0,454,449,1,0,0,0,454,450,1,0,0,0,455,\n+        75,1,0,0,0,456,457,5,71,0,0,457,458,5,20,0,0,458,459,3,4,2,0,459,\n+        460,5,21,0,0,460,77,1,0,0,0,461,462,5,71,0,0,462,463,5,20,0,0,463,\n+        464,3,4,2,0,464,465,5,21,0,0,465,79,1,0,0,0,44,90,107,118,129,137,\n+        139,147,150,156,163,168,176,182,190,204,207,211,224,227,231,242,\n+        251,269,277,284,302,333,336,339,342,344,351,355,368,371,376,383,\n+        401,409,416,427,436,446,454\n+    ]\n \n class LaTeXParser ( Parser ):\n \n@@ -253,47 +213,45 @@ class LaTeXParser ( Parser ):\n \n     sharedContextCache = PredictionContextCache()\n \n-    literalNames = [ u\"<INVALID>\", u\"','\", u\"<INVALID>\", u\"<INVALID>\", u\"<INVALID>\",\n-                     u\"<INVALID>\", u\"'\\\\quad'\", u\"'\\\\qquad'\", u\"<INVALID>\",\n-                     u\"'\\\\negmedspace'\", u\"'\\\\negthickspace'\", u\"'\\\\left'\",\n-                     u\"'\\\\right'\", u\"<INVALID>\", u\"'+'\", u\"'-'\", u\"'*'\",\n-                     u\"'/'\", u\"'('\", u\"')'\", u\"'{'\", u\"'}'\", u\"'\\\\{'\", u\"'\\\\}'\",\n-                     u\"'['\", u\"']'\", u\"'|'\", u\"'\\\\right|'\", u\"'\\\\left|'\",\n-                     u\"'\\\\langle'\", u\"'\\\\rangle'\", u\"'\\\\lim'\", u\"<INVALID>\",\n-                     u\"'\\\\int'\", u\"'\\\\sum'\", u\"'\\\\prod'\", u\"'\\\\exp'\", u\"'\\\\log'\",\n-                     u\"'\\\\ln'\", u\"'\\\\sin'\", u\"'\\\\cos'\", u\"'\\\\tan'\", u\"'\\\\csc'\",\n-                     u\"'\\\\sec'\", u\"'\\\\cot'\", u\"'\\\\arcsin'\", u\"'\\\\arccos'\",\n-                     u\"'\\\\arctan'\", u\"'\\\\arccsc'\", u\"'\\\\arcsec'\", u\"'\\\\arccot'\",\n-                     u\"'\\\\sinh'\", u\"'\\\\cosh'\", u\"'\\\\tanh'\", u\"'\\\\arsinh'\",\n-                     u\"'\\\\arcosh'\", u\"'\\\\artanh'\", u\"'\\\\lfloor'\", u\"'\\\\rfloor'\",\n-                     u\"'\\\\lceil'\", u\"'\\\\rceil'\", u\"'\\\\sqrt'\", u\"'\\\\overline'\",\n-                     u\"'\\\\times'\", u\"'\\\\cdot'\", u\"'\\\\div'\", u\"'\\\\frac'\",\n-                     u\"'\\\\binom'\", u\"'\\\\dbinom'\", u\"'\\\\tbinom'\", u\"'\\\\mathit'\",\n-                     u\"'_'\", u\"'^'\", u\"':'\", u\"<INVALID>\", u\"<INVALID>\",\n-                     u\"<INVALID>\", u\"<INVALID>\", u\"'\\\\neq'\", u\"'<'\", u\"<INVALID>\",\n-                     u\"'\\\\leqq'\", u\"'\\\\leqslant'\", u\"'>'\", u\"<INVALID>\",\n-                     u\"'\\\\geqq'\", u\"'\\\\geqslant'\", u\"'!'\" ]\n-\n-    symbolicNames = [ u\"<INVALID>\", u\"<INVALID>\", u\"WS\", u\"THINSPACE\", u\"MEDSPACE\",\n-                      u\"THICKSPACE\", u\"QUAD\", u\"QQUAD\", u\"NEGTHINSPACE\",\n-                      u\"NEGMEDSPACE\", u\"NEGTHICKSPACE\", u\"CMD_LEFT\", u\"CMD_RIGHT\",\n-                      u\"IGNORE\", u\"ADD\", u\"SUB\", u\"MUL\", u\"DIV\", u\"L_PAREN\",\n-                      u\"R_PAREN\", u\"L_BRACE\", u\"R_BRACE\", u\"L_BRACE_LITERAL\",\n-                      u\"R_BRACE_LITERAL\", u\"L_BRACKET\", u\"R_BRACKET\", u\"BAR\",\n-                      u\"R_BAR\", u\"L_BAR\", u\"L_ANGLE\", u\"R_ANGLE\", u\"FUNC_LIM\",\n-                      u\"LIM_APPROACH_SYM\", u\"FUNC_INT\", u\"FUNC_SUM\", u\"FUNC_PROD\",\n-                      u\"FUNC_EXP\", u\"FUNC_LOG\", u\"FUNC_LN\", u\"FUNC_SIN\",\n-                      u\"FUNC_COS\", u\"FUNC_TAN\", u\"FUNC_CSC\", u\"FUNC_SEC\",\n-                      u\"FUNC_COT\", u\"FUNC_ARCSIN\", u\"FUNC_ARCCOS\", u\"FUNC_ARCTAN\",\n-                      u\"FUNC_ARCCSC\", u\"FUNC_ARCSEC\", u\"FUNC_ARCCOT\", u\"FUNC_SINH\",\n-                      u\"FUNC_COSH\", u\"FUNC_TANH\", u\"FUNC_ARSINH\", u\"FUNC_ARCOSH\",\n-                      u\"FUNC_ARTANH\", u\"L_FLOOR\", u\"R_FLOOR\", u\"L_CEIL\",\n-                      u\"R_CEIL\", u\"FUNC_SQRT\", u\"FUNC_OVERLINE\", u\"CMD_TIMES\",\n-                      u\"CMD_CDOT\", u\"CMD_DIV\", u\"CMD_FRAC\", u\"CMD_BINOM\",\n-                      u\"CMD_DBINOM\", u\"CMD_TBINOM\", u\"CMD_MATHIT\", u\"UNDERSCORE\",\n-                      u\"CARET\", u\"COLON\", u\"DIFFERENTIAL\", u\"LETTER\", u\"NUMBER\",\n-                      u\"EQUAL\", u\"NEQ\", u\"LT\", u\"LTE\", u\"LTE_Q\", u\"LTE_S\",\n-                      u\"GT\", u\"GTE\", u\"GTE_Q\", u\"GTE_S\", u\"BANG\", u\"SYMBOL\" ]\n+    literalNames = [ \"<INVALID>\", \"','\", \"<INVALID>\", \"<INVALID>\", \"<INVALID>\",\n+                     \"<INVALID>\", \"'\\\\quad'\", \"'\\\\qquad'\", \"<INVALID>\",\n+                     \"'\\\\negmedspace'\", \"'\\\\negthickspace'\", \"'\\\\left'\",\n+                     \"'\\\\right'\", \"<INVALID>\", \"'+'\", \"'-'\", \"'*'\", \"'/'\",\n+                     \"'('\", \"')'\", \"'{'\", \"'}'\", \"'\\\\{'\", \"'\\\\}'\", \"'['\",\n+                     \"']'\", \"'|'\", \"'\\\\right|'\", \"'\\\\left|'\", \"'\\\\langle'\",\n+                     \"'\\\\rangle'\", \"'\\\\lim'\", \"<INVALID>\", \"'\\\\int'\", \"'\\\\sum'\",\n+                     \"'\\\\prod'\", \"'\\\\exp'\", \"'\\\\log'\", \"'\\\\ln'\", \"'\\\\sin'\",\n+                     \"'\\\\cos'\", \"'\\\\tan'\", \"'\\\\csc'\", \"'\\\\sec'\", \"'\\\\cot'\",\n+                     \"'\\\\arcsin'\", \"'\\\\arccos'\", \"'\\\\arctan'\", \"'\\\\arccsc'\",\n+                     \"'\\\\arcsec'\", \"'\\\\arccot'\", \"'\\\\sinh'\", \"'\\\\cosh'\",\n+                     \"'\\\\tanh'\", \"'\\\\arsinh'\", \"'\\\\arcosh'\", \"'\\\\artanh'\",\n+                     \"'\\\\lfloor'\", \"'\\\\rfloor'\", \"'\\\\lceil'\", \"'\\\\rceil'\",\n+                     \"'\\\\sqrt'\", \"'\\\\overline'\", \"'\\\\times'\", \"'\\\\cdot'\",\n+                     \"'\\\\div'\", \"'\\\\frac'\", \"'\\\\binom'\", \"'\\\\dbinom'\", \"'\\\\tbinom'\",\n+                     \"'\\\\mathit'\", \"'_'\", \"'^'\", \"':'\", \"<INVALID>\", \"<INVALID>\",\n+                     \"<INVALID>\", \"<INVALID>\", \"'\\\\neq'\", \"'<'\", \"<INVALID>\",\n+                     \"'\\\\leqq'\", \"'\\\\leqslant'\", \"'>'\", \"<INVALID>\", \"'\\\\geqq'\",\n+                     \"'\\\\geqslant'\", \"'!'\" ]\n+\n+    symbolicNames = [ \"<INVALID>\", \"<INVALID>\", \"WS\", \"THINSPACE\", \"MEDSPACE\",\n+                      \"THICKSPACE\", \"QUAD\", \"QQUAD\", \"NEGTHINSPACE\", \"NEGMEDSPACE\",\n+                      \"NEGTHICKSPACE\", \"CMD_LEFT\", \"CMD_RIGHT\", \"IGNORE\",\n+                      \"ADD\", \"SUB\", \"MUL\", \"DIV\", \"L_PAREN\", \"R_PAREN\",\n+                      \"L_BRACE\", \"R_BRACE\", \"L_BRACE_LITERAL\", \"R_BRACE_LITERAL\",\n+                      \"L_BRACKET\", \"R_BRACKET\", \"BAR\", \"R_BAR\", \"L_BAR\",\n+                      \"L_ANGLE\", \"R_ANGLE\", \"FUNC_LIM\", \"LIM_APPROACH_SYM\",\n+                      \"FUNC_INT\", \"FUNC_SUM\", \"FUNC_PROD\", \"FUNC_EXP\", \"FUNC_LOG\",\n+                      \"FUNC_LN\", \"FUNC_SIN\", \"FUNC_COS\", \"FUNC_TAN\", \"FUNC_CSC\",\n+                      \"FUNC_SEC\", \"FUNC_COT\", \"FUNC_ARCSIN\", \"FUNC_ARCCOS\",\n+                      \"FUNC_ARCTAN\", \"FUNC_ARCCSC\", \"FUNC_ARCSEC\", \"FUNC_ARCCOT\",\n+                      \"FUNC_SINH\", \"FUNC_COSH\", \"FUNC_TANH\", \"FUNC_ARSINH\",\n+                      \"FUNC_ARCOSH\", \"FUNC_ARTANH\", \"L_FLOOR\", \"R_FLOOR\",\n+                      \"L_CEIL\", \"R_CEIL\", \"FUNC_SQRT\", \"FUNC_OVERLINE\",\n+                      \"CMD_TIMES\", \"CMD_CDOT\", \"CMD_DIV\", \"CMD_FRAC\", \"CMD_BINOM\",\n+                      \"CMD_DBINOM\", \"CMD_TBINOM\", \"CMD_MATHIT\", \"UNDERSCORE\",\n+                      \"CARET\", \"COLON\", \"DIFFERENTIAL\", \"LETTER\", \"NUMBER\",\n+                      \"EQUAL\", \"NEQ\", \"LT\", \"LTE\", \"LTE_Q\", \"LTE_S\", \"GT\",\n+                      \"GTE\", \"GTE_Q\", \"GTE_S\", \"BANG\", \"SYMBOL\" ]\n \n     RULE_math = 0\n     RULE_relation = 1\n@@ -336,15 +294,14 @@ class LaTeXParser ( Parser ):\n     RULE_subeq = 38\n     RULE_supeq = 39\n \n-    ruleNames =  [ u\"math\", u\"relation\", u\"equality\", u\"expr\", u\"additive\",\n-                   u\"mp\", u\"mp_nofunc\", u\"unary\", u\"unary_nofunc\", u\"postfix\",\n-                   u\"postfix_nofunc\", u\"postfix_op\", u\"eval_at\", u\"eval_at_sub\",\n-                   u\"eval_at_sup\", u\"exp\", u\"exp_nofunc\", u\"comp\", u\"comp_nofunc\",\n-                   u\"group\", u\"abs_group\", u\"atom\", u\"bra\", u\"ket\", u\"mathit\",\n-                   u\"mathit_text\", u\"frac\", u\"binom\", u\"floor\", u\"ceil\",\n-                   u\"func_normal\", u\"func\", u\"args\", u\"limit_sub\", u\"func_arg\",\n-                   u\"func_arg_noparens\", u\"subexpr\", u\"supexpr\", u\"subeq\",\n-                   u\"supeq\" ]\n+    ruleNames =  [ \"math\", \"relation\", \"equality\", \"expr\", \"additive\", \"mp\",\n+                   \"mp_nofunc\", \"unary\", \"unary_nofunc\", \"postfix\", \"postfix_nofunc\",\n+                   \"postfix_op\", \"eval_at\", \"eval_at_sub\", \"eval_at_sup\",\n+                   \"exp\", \"exp_nofunc\", \"comp\", \"comp_nofunc\", \"group\",\n+                   \"abs_group\", \"atom\", \"bra\", \"ket\", \"mathit\", \"mathit_text\",\n+                   \"frac\", \"binom\", \"floor\", \"ceil\", \"func_normal\", \"func\",\n+                   \"args\", \"limit_sub\", \"func_arg\", \"func_arg_noparens\",\n+                   \"subexpr\", \"supexpr\", \"subeq\", \"supeq\" ]\n \n     EOF = Token.EOF\n     T__0=1\n@@ -436,9 +393,9 @@ class LaTeXParser ( Parser ):\n     BANG=87\n     SYMBOL=88\n \n-    def __init__(self, input, output=sys.stdout):\n-        super(LaTeXParser, self).__init__(input, output=output)\n-        self.checkVersion(\"4.7.2\")\n+    def __init__(self, input:TokenStream, output:TextIO = sys.stdout):\n+        super().__init__(input, output)\n+        self.checkVersion(\"4.13.2\")\n         self._interp = ParserATNSimulator(self, self.atn, self.decisionsToDFA, self.sharedContextCache)\n         self._predicates = None\n \n@@ -446,9 +403,10 @@ def __init__(self, input, output=sys.stdout):\n \n \n     class MathContext(ParserRuleContext):\n+        __slots__ = 'parser'\n \n-        def __init__(self, parser, parent=None, invokingState=-1):\n-            super(LaTeXParser.MathContext, self).__init__(parent, invokingState)\n+        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):\n+            super().__init__(parent, invokingState)\n             self.parser = parser\n \n         def relation(self):\n@@ -479,16 +437,17 @@ def math(self):\n \n \n     class RelationContext(ParserRuleContext):\n+        __slots__ = 'parser'\n \n-        def __init__(self, parser, parent=None, invokingState=-1):\n-            super(LaTeXParser.RelationContext, self).__init__(parent, invokingState)\n+        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):\n+            super().__init__(parent, invokingState)\n             self.parser = parser\n \n         def expr(self):\n             return self.getTypedRuleContext(LaTeXParser.ExprContext,0)\n \n \n-        def relation(self, i=None):\n+        def relation(self, i:int=None):\n             if i is None:\n                 return self.getTypedRuleContexts(LaTeXParser.RelationContext)\n             else:\n@@ -518,7 +477,7 @@ def getRuleIndex(self):\n \n \n \n-    def relation(self, _p=0):\n+    def relation(self, _p:int=0):\n         _parentctx = self._ctx\n         _parentState = self.state\n         localctx = LaTeXParser.RelationContext(self, self._ctx, _parentState)\n@@ -547,7 +506,7 @@ def relation(self, _p=0):\n                         raise FailedPredicateException(self, \"self.precpred(self._ctx, 2)\")\n                     self.state = 86\n                     _la = self._input.LA(1)\n-                    if not(((((_la - 77)) & ~0x3f) == 0 and ((1 << (_la - 77)) & ((1 << (LaTeXParser.EQUAL - 77)) | (1 << (LaTeXParser.NEQ - 77)) | (1 << (LaTeXParser.LT - 77)) | (1 << (LaTeXParser.LTE - 77)) | (1 << (LaTeXParser.GT - 77)) | (1 << (LaTeXParser.GTE - 77)))) != 0)):\n+                    if not(((((_la - 77)) & ~0x3f) == 0 and ((1 << (_la - 77)) & 207) != 0)):\n                         self._errHandler.recoverInline(self)\n                     else:\n                         self._errHandler.reportMatch(self)\n@@ -568,12 +527,13 @@ def relation(self, _p=0):\n \n \n     class EqualityContext(ParserRuleContext):\n+        __slots__ = 'parser'\n \n-        def __init__(self, parser, parent=None, invokingState=-1):\n-            super(LaTeXParser.EqualityContext, self).__init__(parent, invokingState)\n+        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):\n+            super().__init__(parent, invokingState)\n             self.parser = parser\n \n-        def expr(self, i=None):\n+        def expr(self, i:int=None):\n             if i is None:\n                 return self.getTypedRuleContexts(LaTeXParser.ExprContext)\n             else:\n@@ -611,9 +571,10 @@ def equality(self):\n \n \n     class ExprContext(ParserRuleContext):\n+        __slots__ = 'parser'\n \n-        def __init__(self, parser, parent=None, invokingState=-1):\n-            super(LaTeXParser.ExprContext, self).__init__(parent, invokingState)\n+        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):\n+            super().__init__(parent, invokingState)\n             self.parser = parser\n \n         def additive(self):\n@@ -644,16 +605,17 @@ def expr(self):\n \n \n     class AdditiveContext(ParserRuleContext):\n+        __slots__ = 'parser'\n \n-        def __init__(self, parser, parent=None, invokingState=-1):\n-            super(LaTeXParser.AdditiveContext, self).__init__(parent, invokingState)\n+        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):\n+            super().__init__(parent, invokingState)\n             self.parser = parser\n \n         def mp(self):\n             return self.getTypedRuleContext(LaTeXParser.MpContext,0)\n \n \n-        def additive(self, i=None):\n+        def additive(self, i:int=None):\n             if i is None:\n                 return self.getTypedRuleContexts(LaTeXParser.AdditiveContext)\n             else:\n@@ -671,7 +633,7 @@ def getRuleIndex(self):\n \n \n \n-    def additive(self, _p=0):\n+    def additive(self, _p:int=0):\n         _parentctx = self._ctx\n         _parentState = self.state\n         localctx = LaTeXParser.AdditiveContext(self, self._ctx, _parentState)\n@@ -700,7 +662,7 @@ def additive(self, _p=0):\n                         raise FailedPredicateException(self, \"self.precpred(self._ctx, 2)\")\n                     self.state = 103\n                     _la = self._input.LA(1)\n-                    if not(_la==LaTeXParser.ADD or _la==LaTeXParser.SUB):\n+                    if not(_la==14 or _la==15):\n                         self._errHandler.recoverInline(self)\n                     else:\n                         self._errHandler.reportMatch(self)\n@@ -721,16 +683,17 @@ def additive(self, _p=0):\n \n \n     class MpContext(ParserRuleContext):\n+        __slots__ = 'parser'\n \n-        def __init__(self, parser, parent=None, invokingState=-1):\n-            super(LaTeXParser.MpContext, self).__init__(parent, invokingState)\n+        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):\n+            super().__init__(parent, invokingState)\n             self.parser = parser\n \n         def unary(self):\n             return self.getTypedRuleContext(LaTeXParser.UnaryContext,0)\n \n \n-        def mp(self, i=None):\n+        def mp(self, i:int=None):\n             if i is None:\n                 return self.getTypedRuleContexts(LaTeXParser.MpContext)\n             else:\n@@ -760,7 +723,7 @@ def getRuleIndex(self):\n \n \n \n-    def mp(self, _p=0):\n+    def mp(self, _p:int=0):\n         _parentctx = self._ctx\n         _parentState = self.state\n         localctx = LaTeXParser.MpContext(self, self._ctx, _parentState)\n@@ -789,7 +752,7 @@ def mp(self, _p=0):\n                         raise FailedPredicateException(self, \"self.precpred(self._ctx, 2)\")\n                     self.state = 114\n                     _la = self._input.LA(1)\n-                    if not(((((_la - 16)) & ~0x3f) == 0 and ((1 << (_la - 16)) & ((1 << (LaTeXParser.MUL - 16)) | (1 << (LaTeXParser.DIV - 16)) | (1 << (LaTeXParser.CMD_TIMES - 16)) | (1 << (LaTeXParser.CMD_CDOT - 16)) | (1 << (LaTeXParser.CMD_DIV - 16)) | (1 << (LaTeXParser.COLON - 16)))) != 0)):\n+                    if not(((((_la - 16)) & ~0x3f) == 0 and ((1 << (_la - 16)) & 145100350494343171) != 0)):\n                         self._errHandler.recoverInline(self)\n                     else:\n                         self._errHandler.reportMatch(self)\n@@ -810,16 +773,17 @@ def mp(self, _p=0):\n \n \n     class Mp_nofuncContext(ParserRuleContext):\n+        __slots__ = 'parser'\n \n-        def __init__(self, parser, parent=None, invokingState=-1):\n-            super(LaTeXParser.Mp_nofuncContext, self).__init__(parent, invokingState)\n+        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):\n+            super().__init__(parent, invokingState)\n             self.parser = parser\n \n         def unary_nofunc(self):\n             return self.getTypedRuleContext(LaTeXParser.Unary_nofuncContext,0)\n \n \n-        def mp_nofunc(self, i=None):\n+        def mp_nofunc(self, i:int=None):\n             if i is None:\n                 return self.getTypedRuleContexts(LaTeXParser.Mp_nofuncContext)\n             else:\n@@ -849,7 +813,7 @@ def getRuleIndex(self):\n \n \n \n-    def mp_nofunc(self, _p=0):\n+    def mp_nofunc(self, _p:int=0):\n         _parentctx = self._ctx\n         _parentState = self.state\n         localctx = LaTeXParser.Mp_nofuncContext(self, self._ctx, _parentState)\n@@ -878,7 +842,7 @@ def mp_nofunc(self, _p=0):\n                         raise FailedPredicateException(self, \"self.precpred(self._ctx, 2)\")\n                     self.state = 125\n                     _la = self._input.LA(1)\n-                    if not(((((_la - 16)) & ~0x3f) == 0 and ((1 << (_la - 16)) & ((1 << (LaTeXParser.MUL - 16)) | (1 << (LaTeXParser.DIV - 16)) | (1 << (LaTeXParser.CMD_TIMES - 16)) | (1 << (LaTeXParser.CMD_CDOT - 16)) | (1 << (LaTeXParser.CMD_DIV - 16)) | (1 << (LaTeXParser.COLON - 16)))) != 0)):\n+                    if not(((((_la - 16)) & ~0x3f) == 0 and ((1 << (_la - 16)) & 145100350494343171) != 0)):\n                         self._errHandler.recoverInline(self)\n                     else:\n                         self._errHandler.reportMatch(self)\n@@ -899,9 +863,10 @@ def mp_nofunc(self, _p=0):\n \n \n     class UnaryContext(ParserRuleContext):\n+        __slots__ = 'parser'\n \n-        def __init__(self, parser, parent=None, invokingState=-1):\n-            super(LaTeXParser.UnaryContext, self).__init__(parent, invokingState)\n+        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):\n+            super().__init__(parent, invokingState)\n             self.parser = parser\n \n         def unary(self):\n@@ -914,7 +879,7 @@ def ADD(self):\n         def SUB(self):\n             return self.getToken(LaTeXParser.SUB, 0)\n \n-        def postfix(self, i=None):\n+        def postfix(self, i:int=None):\n             if i is None:\n                 return self.getTypedRuleContexts(LaTeXParser.PostfixContext)\n             else:\n@@ -936,11 +901,11 @@ def unary(self):\n             self.state = 139\n             self._errHandler.sync(self)\n             token = self._input.LA(1)\n-            if token in [LaTeXParser.ADD, LaTeXParser.SUB]:\n+            if token in [14, 15]:\n                 self.enterOuterAlt(localctx, 1)\n                 self.state = 132\n                 _la = self._input.LA(1)\n-                if not(_la==LaTeXParser.ADD or _la==LaTeXParser.SUB):\n+                if not(_la==14 or _la==15):\n                     self._errHandler.recoverInline(self)\n                 else:\n                     self._errHandler.reportMatch(self)\n@@ -948,7 +913,7 @@ def unary(self):\n                 self.state = 133\n                 self.unary()\n                 pass\n-            elif token in [LaTeXParser.L_PAREN, LaTeXParser.L_BRACE, LaTeXParser.L_BRACE_LITERAL, LaTeXParser.L_BRACKET, LaTeXParser.BAR, LaTeXParser.L_BAR, LaTeXParser.L_ANGLE, LaTeXParser.FUNC_LIM, LaTeXParser.FUNC_INT, LaTeXParser.FUNC_SUM, LaTeXParser.FUNC_PROD, LaTeXParser.FUNC_EXP, LaTeXParser.FUNC_LOG, LaTeXParser.FUNC_LN, LaTeXParser.FUNC_SIN, LaTeXParser.FUNC_COS, LaTeXParser.FUNC_TAN, LaTeXParser.FUNC_CSC, LaTeXParser.FUNC_SEC, LaTeXParser.FUNC_COT, LaTeXParser.FUNC_ARCSIN, LaTeXParser.FUNC_ARCCOS, LaTeXParser.FUNC_ARCTAN, LaTeXParser.FUNC_ARCCSC, LaTeXParser.FUNC_ARCSEC, LaTeXParser.FUNC_ARCCOT, LaTeXParser.FUNC_SINH, LaTeXParser.FUNC_COSH, LaTeXParser.FUNC_TANH, LaTeXParser.FUNC_ARSINH, LaTeXParser.FUNC_ARCOSH, LaTeXParser.FUNC_ARTANH, LaTeXParser.L_FLOOR, LaTeXParser.L_CEIL, LaTeXParser.FUNC_SQRT, LaTeXParser.FUNC_OVERLINE, LaTeXParser.CMD_FRAC, LaTeXParser.CMD_BINOM, LaTeXParser.CMD_DBINOM, LaTeXParser.CMD_TBINOM, LaTeXParser.CMD_MATHIT, LaTeXParser.DIFFERENTIAL, LaTeXParser.LETTER, LaTeXParser.NUMBER, LaTeXParser.SYMBOL]:\n+            elif token in [18, 20, 22, 24, 26, 28, 29, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 61, 62, 66, 67, 68, 69, 70, 74, 75, 76, 88]:\n                 self.enterOuterAlt(localctx, 2)\n                 self.state = 135\n                 self._errHandler.sync(self)\n@@ -978,9 +943,10 @@ def unary(self):\n \n \n     class Unary_nofuncContext(ParserRuleContext):\n+        __slots__ = 'parser'\n \n-        def __init__(self, parser, parent=None, invokingState=-1):\n-            super(LaTeXParser.Unary_nofuncContext, self).__init__(parent, invokingState)\n+        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):\n+            super().__init__(parent, invokingState)\n             self.parser = parser\n \n         def unary_nofunc(self):\n@@ -997,7 +963,7 @@ def postfix(self):\n             return self.getTypedRuleContext(LaTeXParser.PostfixContext,0)\n \n \n-        def postfix_nofunc(self, i=None):\n+        def postfix_nofunc(self, i:int=None):\n             if i is None:\n                 return self.getTypedRuleContexts(LaTeXParser.Postfix_nofuncContext)\n             else:\n@@ -1019,11 +985,11 @@ def unary_nofunc(self):\n             self.state = 150\n             self._errHandler.sync(self)\n             token = self._input.LA(1)\n-            if token in [LaTeXParser.ADD, LaTeXParser.SUB]:\n+            if token in [14, 15]:\n                 self.enterOuterAlt(localctx, 1)\n                 self.state = 141\n                 _la = self._input.LA(1)\n-                if not(_la==LaTeXParser.ADD or _la==LaTeXParser.SUB):\n+                if not(_la==14 or _la==15):\n                     self._errHandler.recoverInline(self)\n                 else:\n                     self._errHandler.reportMatch(self)\n@@ -1031,7 +997,7 @@ def unary_nofunc(self):\n                 self.state = 142\n                 self.unary_nofunc()\n                 pass\n-            elif token in [LaTeXParser.L_PAREN, LaTeXParser.L_BRACE, LaTeXParser.L_BRACE_LITERAL, LaTeXParser.L_BRACKET, LaTeXParser.BAR, LaTeXParser.L_BAR, LaTeXParser.L_ANGLE, LaTeXParser.FUNC_LIM, LaTeXParser.FUNC_INT, LaTeXParser.FUNC_SUM, LaTeXParser.FUNC_PROD, LaTeXParser.FUNC_EXP, LaTeXParser.FUNC_LOG, LaTeXParser.FUNC_LN, LaTeXParser.FUNC_SIN, LaTeXParser.FUNC_COS, LaTeXParser.FUNC_TAN, LaTeXParser.FUNC_CSC, LaTeXParser.FUNC_SEC, LaTeXParser.FUNC_COT, LaTeXParser.FUNC_ARCSIN, LaTeXParser.FUNC_ARCCOS, LaTeXParser.FUNC_ARCTAN, LaTeXParser.FUNC_ARCCSC, LaTeXParser.FUNC_ARCSEC, LaTeXParser.FUNC_ARCCOT, LaTeXParser.FUNC_SINH, LaTeXParser.FUNC_COSH, LaTeXParser.FUNC_TANH, LaTeXParser.FUNC_ARSINH, LaTeXParser.FUNC_ARCOSH, LaTeXParser.FUNC_ARTANH, LaTeXParser.L_FLOOR, LaTeXParser.L_CEIL, LaTeXParser.FUNC_SQRT, LaTeXParser.FUNC_OVERLINE, LaTeXParser.CMD_FRAC, LaTeXParser.CMD_BINOM, LaTeXParser.CMD_DBINOM, LaTeXParser.CMD_TBINOM, LaTeXParser.CMD_MATHIT, LaTeXParser.DIFFERENTIAL, LaTeXParser.LETTER, LaTeXParser.NUMBER, LaTeXParser.SYMBOL]:\n+            elif token in [18, 20, 22, 24, 26, 28, 29, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 61, 62, 66, 67, 68, 69, 70, 74, 75, 76, 88]:\n                 self.enterOuterAlt(localctx, 2)\n                 self.state = 143\n                 self.postfix()\n@@ -1060,16 +1026,17 @@ def unary_nofunc(self):\n \n \n     class PostfixContext(ParserRuleContext):\n+        __slots__ = 'parser'\n \n-        def __init__(self, parser, parent=None, invokingState=-1):\n-            super(LaTeXParser.PostfixContext, self).__init__(parent, invokingState)\n+        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):\n+            super().__init__(parent, invokingState)\n             self.parser = parser\n \n         def exp(self):\n             return self.getTypedRuleContext(LaTeXParser.ExpContext,0)\n \n \n-        def postfix_op(self, i=None):\n+        def postfix_op(self, i:int=None):\n             if i is None:\n                 return self.getTypedRuleContexts(LaTeXParser.Postfix_opContext)\n             else:\n@@ -1111,16 +1078,17 @@ def postfix(self):\n \n \n     class Postfix_nofuncContext(ParserRuleContext):\n+        __slots__ = 'parser'\n \n-        def __init__(self, parser, parent=None, invokingState=-1):\n-            super(LaTeXParser.Postfix_nofuncContext, self).__init__(parent, invokingState)\n+        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):\n+            super().__init__(parent, invokingState)\n             self.parser = parser\n \n         def exp_nofunc(self):\n             return self.getTypedRuleContext(LaTeXParser.Exp_nofuncContext,0)\n \n \n-        def postfix_op(self, i=None):\n+        def postfix_op(self, i:int=None):\n             if i is None:\n                 return self.getTypedRuleContexts(LaTeXParser.Postfix_opContext)\n             else:\n@@ -1162,9 +1130,10 @@ def postfix_nofunc(self):\n \n \n     class Postfix_opContext(ParserRuleContext):\n+        __slots__ = 'parser'\n \n-        def __init__(self, parser, parent=None, invokingState=-1):\n-            super(LaTeXParser.Postfix_opContext, self).__init__(parent, invokingState)\n+        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):\n+            super().__init__(parent, invokingState)\n             self.parser = parser\n \n         def BANG(self):\n@@ -1188,12 +1157,12 @@ def postfix_op(self):\n             self.state = 168\n             self._errHandler.sync(self)\n             token = self._input.LA(1)\n-            if token in [LaTeXParser.BANG]:\n+            if token in [87]:\n                 self.enterOuterAlt(localctx, 1)\n                 self.state = 166\n                 self.match(LaTeXParser.BANG)\n                 pass\n-            elif token in [LaTeXParser.BAR]:\n+            elif token in [26]:\n                 self.enterOuterAlt(localctx, 2)\n                 self.state = 167\n                 self.eval_at()\n@@ -1211,9 +1180,10 @@ def postfix_op(self):\n \n \n     class Eval_atContext(ParserRuleContext):\n+        __slots__ = 'parser'\n \n-        def __init__(self, parser, parent=None, invokingState=-1):\n-            super(LaTeXParser.Eval_atContext, self).__init__(parent, invokingState)\n+        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):\n+            super().__init__(parent, invokingState)\n             self.parser = parser\n \n         def BAR(self):\n@@ -1272,9 +1242,10 @@ def eval_at(self):\n \n \n     class Eval_at_subContext(ParserRuleContext):\n+        __slots__ = 'parser'\n \n-        def __init__(self, parser, parent=None, invokingState=-1):\n-            super(LaTeXParser.Eval_at_subContext, self).__init__(parent, invokingState)\n+        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):\n+            super().__init__(parent, invokingState)\n             self.parser = parser\n \n         def UNDERSCORE(self):\n@@ -1336,9 +1307,10 @@ def eval_at_sub(self):\n \n \n     class Eval_at_supContext(ParserRuleContext):\n+        __slots__ = 'parser'\n \n-        def __init__(self, parser, parent=None, invokingState=-1):\n-            super(LaTeXParser.Eval_at_supContext, self).__init__(parent, invokingState)\n+        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):\n+            super().__init__(parent, invokingState)\n             self.parser = parser\n \n         def CARET(self):\n@@ -1400,9 +1372,10 @@ def eval_at_sup(self):\n \n \n     class ExpContext(ParserRuleContext):\n+        __slots__ = 'parser'\n \n-        def __init__(self, parser, parent=None, invokingState=-1):\n-            super(LaTeXParser.ExpContext, self).__init__(parent, invokingState)\n+        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):\n+            super().__init__(parent, invokingState)\n             self.parser = parser\n \n         def comp(self):\n@@ -1439,7 +1412,7 @@ def getRuleIndex(self):\n \n \n \n-    def exp(self, _p=0):\n+    def exp(self, _p:int=0):\n         _parentctx = self._ctx\n         _parentState = self.state\n         localctx = LaTeXParser.ExpContext(self, self._ctx, _parentState)\n@@ -1470,11 +1443,11 @@ def exp(self, _p=0):\n                     self.state = 204\n                     self._errHandler.sync(self)\n                     token = self._input.LA(1)\n-                    if token in [LaTeXParser.BAR, LaTeXParser.L_BAR, LaTeXParser.L_ANGLE, LaTeXParser.CMD_MATHIT, LaTeXParser.DIFFERENTIAL, LaTeXParser.LETTER, LaTeXParser.NUMBER, LaTeXParser.SYMBOL]:\n+                    if token in [26, 28, 29, 70, 74, 75, 76, 88]:\n                         self.state = 199\n                         self.atom()\n                         pass\n-                    elif token in [LaTeXParser.L_BRACE]:\n+                    elif token in [20]:\n                         self.state = 200\n                         self.match(LaTeXParser.L_BRACE)\n                         self.state = 201\n@@ -1507,9 +1480,10 @@ def exp(self, _p=0):\n \n \n     class Exp_nofuncContext(ParserRuleContext):\n+        __slots__ = 'parser'\n \n-        def __init__(self, parser, parent=None, invokingState=-1):\n-            super(LaTeXParser.Exp_nofuncContext, self).__init__(parent, invokingState)\n+        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):\n+            super().__init__(parent, invokingState)\n             self.parser = parser\n \n         def comp_nofunc(self):\n@@ -1546,7 +1520,7 @@ def getRuleIndex(self):\n \n \n \n-    def exp_nofunc(self, _p=0):\n+    def exp_nofunc(self, _p:int=0):\n         _parentctx = self._ctx\n         _parentState = self.state\n         localctx = LaTeXParser.Exp_nofuncContext(self, self._ctx, _parentState)\n@@ -1577,11 +1551,11 @@ def exp_nofunc(self, _p=0):\n                     self.state = 224\n                     self._errHandler.sync(self)\n                     token = self._input.LA(1)\n-                    if token in [LaTeXParser.BAR, LaTeXParser.L_BAR, LaTeXParser.L_ANGLE, LaTeXParser.CMD_MATHIT, LaTeXParser.DIFFERENTIAL, LaTeXParser.LETTER, LaTeXParser.NUMBER, LaTeXParser.SYMBOL]:\n+                    if token in [26, 28, 29, 70, 74, 75, 76, 88]:\n                         self.state = 219\n                         self.atom()\n                         pass\n-                    elif token in [LaTeXParser.L_BRACE]:\n+                    elif token in [20]:\n                         self.state = 220\n                         self.match(LaTeXParser.L_BRACE)\n                         self.state = 221\n@@ -1614,9 +1588,10 @@ def exp_nofunc(self, _p=0):\n \n \n     class CompContext(ParserRuleContext):\n+        __slots__ = 'parser'\n \n-        def __init__(self, parser, parent=None, invokingState=-1):\n-            super(LaTeXParser.CompContext, self).__init__(parent, invokingState)\n+        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):\n+            super().__init__(parent, invokingState)\n             self.parser = parser\n \n         def group(self):\n@@ -1724,9 +1699,10 @@ def comp(self):\n \n \n     class Comp_nofuncContext(ParserRuleContext):\n+        __slots__ = 'parser'\n \n-        def __init__(self, parser, parent=None, invokingState=-1):\n-            super(LaTeXParser.Comp_nofuncContext, self).__init__(parent, invokingState)\n+        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):\n+            super().__init__(parent, invokingState)\n             self.parser = parser\n \n         def group(self):\n@@ -1824,9 +1800,10 @@ def comp_nofunc(self):\n \n \n     class GroupContext(ParserRuleContext):\n+        __slots__ = 'parser'\n \n-        def __init__(self, parser, parent=None, invokingState=-1):\n-            super(LaTeXParser.GroupContext, self).__init__(parent, invokingState)\n+        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):\n+            super().__init__(parent, invokingState)\n             self.parser = parser\n \n         def L_PAREN(self):\n@@ -1871,7 +1848,7 @@ def group(self):\n             self.state = 269\n             self._errHandler.sync(self)\n             token = self._input.LA(1)\n-            if token in [LaTeXParser.L_PAREN]:\n+            if token in [18]:\n                 self.enterOuterAlt(localctx, 1)\n                 self.state = 253\n                 self.match(LaTeXParser.L_PAREN)\n@@ -1880,7 +1857,7 @@ def group(self):\n                 self.state = 255\n                 self.match(LaTeXParser.R_PAREN)\n                 pass\n-            elif token in [LaTeXParser.L_BRACKET]:\n+            elif token in [24]:\n                 self.enterOuterAlt(localctx, 2)\n                 self.state = 257\n                 self.match(LaTeXParser.L_BRACKET)\n@@ -1889,7 +1866,7 @@ def group(self):\n                 self.state = 259\n                 self.match(LaTeXParser.R_BRACKET)\n                 pass\n-            elif token in [LaTeXParser.L_BRACE]:\n+            elif token in [20]:\n                 self.enterOuterAlt(localctx, 3)\n                 self.state = 261\n                 self.match(LaTeXParser.L_BRACE)\n@@ -1898,7 +1875,7 @@ def group(self):\n                 self.state = 263\n                 self.match(LaTeXParser.R_BRACE)\n                 pass\n-            elif token in [LaTeXParser.L_BRACE_LITERAL]:\n+            elif token in [22]:\n                 self.enterOuterAlt(localctx, 4)\n                 self.state = 265\n                 self.match(LaTeXParser.L_BRACE_LITERAL)\n@@ -1920,12 +1897,13 @@ def group(self):\n \n \n     class Abs_groupContext(ParserRuleContext):\n+        __slots__ = 'parser'\n \n-        def __init__(self, parser, parent=None, invokingState=-1):\n-            super(LaTeXParser.Abs_groupContext, self).__init__(parent, invokingState)\n+        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):\n+            super().__init__(parent, invokingState)\n             self.parser = parser\n \n-        def BAR(self, i=None):\n+        def BAR(self, i:int=None):\n             if i is None:\n                 return self.getTokens(LaTeXParser.BAR)\n             else:\n@@ -1963,9 +1941,10 @@ def abs_group(self):\n \n \n     class AtomContext(ParserRuleContext):\n+        __slots__ = 'parser'\n \n-        def __init__(self, parser, parent=None, invokingState=-1):\n-            super(LaTeXParser.AtomContext, self).__init__(parent, invokingState)\n+        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):\n+            super().__init__(parent, invokingState)\n             self.parser = parser\n \n         def LETTER(self):\n@@ -2011,11 +1990,11 @@ def atom(self):\n             self.state = 284\n             self._errHandler.sync(self)\n             token = self._input.LA(1)\n-            if token in [LaTeXParser.LETTER, LaTeXParser.SYMBOL]:\n+            if token in [75, 88]:\n                 self.enterOuterAlt(localctx, 1)\n                 self.state = 275\n                 _la = self._input.LA(1)\n-                if not(_la==LaTeXParser.LETTER or _la==LaTeXParser.SYMBOL):\n+                if not(_la==75 or _la==88):\n                     self._errHandler.recoverInline(self)\n                 else:\n                     self._errHandler.reportMatch(self)\n@@ -2029,27 +2008,27 @@ def atom(self):\n \n \n                 pass\n-            elif token in [LaTeXParser.NUMBER]:\n+            elif token in [76]:\n                 self.enterOuterAlt(localctx, 2)\n                 self.state = 279\n                 self.match(LaTeXParser.NUMBER)\n                 pass\n-            elif token in [LaTeXParser.DIFFERENTIAL]:\n+            elif token in [74]:\n                 self.enterOuterAlt(localctx, 3)\n                 self.state = 280\n                 self.match(LaTeXParser.DIFFERENTIAL)\n                 pass\n-            elif token in [LaTeXParser.CMD_MATHIT]:\n+            elif token in [70]:\n                 self.enterOuterAlt(localctx, 4)\n                 self.state = 281\n                 self.mathit()\n                 pass\n-            elif token in [LaTeXParser.L_ANGLE]:\n+            elif token in [29]:\n                 self.enterOuterAlt(localctx, 5)\n                 self.state = 282\n                 self.bra()\n                 pass\n-            elif token in [LaTeXParser.BAR, LaTeXParser.L_BAR]:\n+            elif token in [26, 28]:\n                 self.enterOuterAlt(localctx, 6)\n                 self.state = 283\n                 self.ket()\n@@ -2067,9 +2046,10 @@ def atom(self):\n \n \n     class BraContext(ParserRuleContext):\n+        __slots__ = 'parser'\n \n-        def __init__(self, parser, parent=None, invokingState=-1):\n-            super(LaTeXParser.BraContext, self).__init__(parent, invokingState)\n+        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):\n+            super().__init__(parent, invokingState)\n             self.parser = parser\n \n         def L_ANGLE(self):\n@@ -2104,7 +2084,7 @@ def bra(self):\n             self.expr()\n             self.state = 288\n             _la = self._input.LA(1)\n-            if not(_la==LaTeXParser.BAR or _la==LaTeXParser.R_BAR):\n+            if not(_la==26 or _la==27):\n                 self._errHandler.recoverInline(self)\n             else:\n                 self._errHandler.reportMatch(self)\n@@ -2119,9 +2099,10 @@ def bra(self):\n \n \n     class KetContext(ParserRuleContext):\n+        __slots__ = 'parser'\n \n-        def __init__(self, parser, parent=None, invokingState=-1):\n-            super(LaTeXParser.KetContext, self).__init__(parent, invokingState)\n+        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):\n+            super().__init__(parent, invokingState)\n             self.parser = parser\n \n         def expr(self):\n@@ -2152,7 +2133,7 @@ def ket(self):\n             self.enterOuterAlt(localctx, 1)\n             self.state = 290\n             _la = self._input.LA(1)\n-            if not(_la==LaTeXParser.BAR or _la==LaTeXParser.L_BAR):\n+            if not(_la==26 or _la==28):\n                 self._errHandler.recoverInline(self)\n             else:\n                 self._errHandler.reportMatch(self)\n@@ -2171,9 +2152,10 @@ def ket(self):\n \n \n     class MathitContext(ParserRuleContext):\n+        __slots__ = 'parser'\n \n-        def __init__(self, parser, parent=None, invokingState=-1):\n-            super(LaTeXParser.MathitContext, self).__init__(parent, invokingState)\n+        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):\n+            super().__init__(parent, invokingState)\n             self.parser = parser\n \n         def CMD_MATHIT(self):\n@@ -2219,12 +2201,13 @@ def mathit(self):\n \n \n     class Mathit_textContext(ParserRuleContext):\n+        __slots__ = 'parser'\n \n-        def __init__(self, parser, parent=None, invokingState=-1):\n-            super(LaTeXParser.Mathit_textContext, self).__init__(parent, invokingState)\n+        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):\n+            super().__init__(parent, invokingState)\n             self.parser = parser\n \n-        def LETTER(self, i=None):\n+        def LETTER(self, i:int=None):\n             if i is None:\n                 return self.getTokens(LaTeXParser.LETTER)\n             else:\n@@ -2246,7 +2229,7 @@ def mathit_text(self):\n             self.state = 302\n             self._errHandler.sync(self)\n             _la = self._input.LA(1)\n-            while _la==LaTeXParser.LETTER:\n+            while _la==75:\n                 self.state = 299\n                 self.match(LaTeXParser.LETTER)\n                 self.state = 304\n@@ -2263,9 +2246,10 @@ def mathit_text(self):\n \n \n     class FracContext(ParserRuleContext):\n+        __slots__ = 'parser'\n \n-        def __init__(self, parser, parent=None, invokingState=-1):\n-            super(LaTeXParser.FracContext, self).__init__(parent, invokingState)\n+        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):\n+            super().__init__(parent, invokingState)\n             self.parser = parser\n             self.upper = None # ExprContext\n             self.lower = None # ExprContext\n@@ -2273,19 +2257,19 @@ def __init__(self, parser, parent=None, invokingState=-1):\n         def CMD_FRAC(self):\n             return self.getToken(LaTeXParser.CMD_FRAC, 0)\n \n-        def L_BRACE(self, i=None):\n+        def L_BRACE(self, i:int=None):\n             if i is None:\n                 return self.getTokens(LaTeXParser.L_BRACE)\n             else:\n                 return self.getToken(LaTeXParser.L_BRACE, i)\n \n-        def R_BRACE(self, i=None):\n+        def R_BRACE(self, i:int=None):\n             if i is None:\n                 return self.getTokens(LaTeXParser.R_BRACE)\n             else:\n                 return self.getToken(LaTeXParser.R_BRACE, i)\n \n-        def expr(self, i=None):\n+        def expr(self, i:int=None):\n             if i is None:\n                 return self.getTypedRuleContexts(LaTeXParser.ExprContext)\n             else:\n@@ -2328,20 +2312,21 @@ def frac(self):\n \n \n     class BinomContext(ParserRuleContext):\n+        __slots__ = 'parser'\n \n-        def __init__(self, parser, parent=None, invokingState=-1):\n-            super(LaTeXParser.BinomContext, self).__init__(parent, invokingState)\n+        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):\n+            super().__init__(parent, invokingState)\n             self.parser = parser\n             self.n = None # ExprContext\n             self.k = None # ExprContext\n \n-        def L_BRACE(self, i=None):\n+        def L_BRACE(self, i:int=None):\n             if i is None:\n                 return self.getTokens(LaTeXParser.L_BRACE)\n             else:\n                 return self.getToken(LaTeXParser.L_BRACE, i)\n \n-        def R_BRACE(self, i=None):\n+        def R_BRACE(self, i:int=None):\n             if i is None:\n                 return self.getTokens(LaTeXParser.R_BRACE)\n             else:\n@@ -2356,7 +2341,7 @@ def CMD_DBINOM(self):\n         def CMD_TBINOM(self):\n             return self.getToken(LaTeXParser.CMD_TBINOM, 0)\n \n-        def expr(self, i=None):\n+        def expr(self, i:int=None):\n             if i is None:\n                 return self.getTypedRuleContexts(LaTeXParser.ExprContext)\n             else:\n@@ -2378,7 +2363,7 @@ def binom(self):\n             self.enterOuterAlt(localctx, 1)\n             self.state = 313\n             _la = self._input.LA(1)\n-            if not(((((_la - 67)) & ~0x3f) == 0 and ((1 << (_la - 67)) & ((1 << (LaTeXParser.CMD_BINOM - 67)) | (1 << (LaTeXParser.CMD_DBINOM - 67)) | (1 << (LaTeXParser.CMD_TBINOM - 67)))) != 0)):\n+            if not(((((_la - 67)) & ~0x3f) == 0 and ((1 << (_la - 67)) & 7) != 0)):\n                 self._errHandler.recoverInline(self)\n             else:\n                 self._errHandler.reportMatch(self)\n@@ -2405,9 +2390,10 @@ def binom(self):\n \n \n     class FloorContext(ParserRuleContext):\n+        __slots__ = 'parser'\n \n-        def __init__(self, parser, parent=None, invokingState=-1):\n-            super(LaTeXParser.FloorContext, self).__init__(parent, invokingState)\n+        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):\n+            super().__init__(parent, invokingState)\n             self.parser = parser\n             self.val = None # ExprContext\n \n@@ -2449,9 +2435,10 @@ def floor(self):\n \n \n     class CeilContext(ParserRuleContext):\n+        __slots__ = 'parser'\n \n-        def __init__(self, parser, parent=None, invokingState=-1):\n-            super(LaTeXParser.CeilContext, self).__init__(parent, invokingState)\n+        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):\n+            super().__init__(parent, invokingState)\n             self.parser = parser\n             self.val = None # ExprContext\n \n@@ -2493,9 +2480,10 @@ def ceil(self):\n \n \n     class Func_normalContext(ParserRuleContext):\n+        __slots__ = 'parser'\n \n-        def __init__(self, parser, parent=None, invokingState=-1):\n-            super(LaTeXParser.Func_normalContext, self).__init__(parent, invokingState)\n+        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):\n+            super().__init__(parent, invokingState)\n             self.parser = parser\n \n         def FUNC_EXP(self):\n@@ -2576,7 +2564,7 @@ def func_normal(self):\n             self.enterOuterAlt(localctx, 1)\n             self.state = 329\n             _la = self._input.LA(1)\n-            if not((((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << LaTeXParser.FUNC_EXP) | (1 << LaTeXParser.FUNC_LOG) | (1 << LaTeXParser.FUNC_LN) | (1 << LaTeXParser.FUNC_SIN) | (1 << LaTeXParser.FUNC_COS) | (1 << LaTeXParser.FUNC_TAN) | (1 << LaTeXParser.FUNC_CSC) | (1 << LaTeXParser.FUNC_SEC) | (1 << LaTeXParser.FUNC_COT) | (1 << LaTeXParser.FUNC_ARCSIN) | (1 << LaTeXParser.FUNC_ARCCOS) | (1 << LaTeXParser.FUNC_ARCTAN) | (1 << LaTeXParser.FUNC_ARCCSC) | (1 << LaTeXParser.FUNC_ARCSEC) | (1 << LaTeXParser.FUNC_ARCCOT) | (1 << LaTeXParser.FUNC_SINH) | (1 << LaTeXParser.FUNC_COSH) | (1 << LaTeXParser.FUNC_TANH) | (1 << LaTeXParser.FUNC_ARSINH) | (1 << LaTeXParser.FUNC_ARCOSH) | (1 << LaTeXParser.FUNC_ARTANH))) != 0)):\n+            if not((((_la) & ~0x3f) == 0 and ((1 << _la) & 144115119356379136) != 0)):\n                 self._errHandler.recoverInline(self)\n             else:\n                 self._errHandler.reportMatch(self)\n@@ -2591,9 +2579,10 @@ def func_normal(self):\n \n \n     class FuncContext(ParserRuleContext):\n+        __slots__ = 'parser'\n \n-        def __init__(self, parser, parent=None, invokingState=-1):\n-            super(LaTeXParser.FuncContext, self).__init__(parent, invokingState)\n+        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):\n+            super().__init__(parent, invokingState)\n             self.parser = parser\n             self.root = None # ExprContext\n             self.base = None # ExprContext\n@@ -2657,7 +2646,7 @@ def L_BRACE(self):\n         def R_BRACE(self):\n             return self.getToken(LaTeXParser.R_BRACE, 0)\n \n-        def expr(self, i=None):\n+        def expr(self, i:int=None):\n             if i is None:\n                 return self.getTypedRuleContexts(LaTeXParser.ExprContext)\n             else:\n@@ -2709,7 +2698,7 @@ def func(self):\n             self.state = 409\n             self._errHandler.sync(self)\n             token = self._input.LA(1)\n-            if token in [LaTeXParser.FUNC_EXP, LaTeXParser.FUNC_LOG, LaTeXParser.FUNC_LN, LaTeXParser.FUNC_SIN, LaTeXParser.FUNC_COS, LaTeXParser.FUNC_TAN, LaTeXParser.FUNC_CSC, LaTeXParser.FUNC_SEC, LaTeXParser.FUNC_COT, LaTeXParser.FUNC_ARCSIN, LaTeXParser.FUNC_ARCCOS, LaTeXParser.FUNC_ARCTAN, LaTeXParser.FUNC_ARCCSC, LaTeXParser.FUNC_ARCSEC, LaTeXParser.FUNC_ARCCOT, LaTeXParser.FUNC_SINH, LaTeXParser.FUNC_COSH, LaTeXParser.FUNC_TANH, LaTeXParser.FUNC_ARSINH, LaTeXParser.FUNC_ARCOSH, LaTeXParser.FUNC_ARTANH]:\n+            if token in [36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56]:\n                 self.enterOuterAlt(localctx, 1)\n                 self.state = 331\n                 self.func_normal()\n@@ -2720,7 +2709,7 @@ def func(self):\n                     self.state = 333\n                     self._errHandler.sync(self)\n                     _la = self._input.LA(1)\n-                    if _la==LaTeXParser.UNDERSCORE:\n+                    if _la==71:\n                         self.state = 332\n                         self.subexpr()\n \n@@ -2728,7 +2717,7 @@ def func(self):\n                     self.state = 336\n                     self._errHandler.sync(self)\n                     _la = self._input.LA(1)\n-                    if _la==LaTeXParser.CARET:\n+                    if _la==72:\n                         self.state = 335\n                         self.supexpr()\n \n@@ -2739,7 +2728,7 @@ def func(self):\n                     self.state = 339\n                     self._errHandler.sync(self)\n                     _la = self._input.LA(1)\n-                    if _la==LaTeXParser.CARET:\n+                    if _la==72:\n                         self.state = 338\n                         self.supexpr()\n \n@@ -2747,7 +2736,7 @@ def func(self):\n                     self.state = 342\n                     self._errHandler.sync(self)\n                     _la = self._input.LA(1)\n-                    if _la==LaTeXParser.UNDERSCORE:\n+                    if _la==71:\n                         self.state = 341\n                         self.subexpr()\n \n@@ -2774,11 +2763,11 @@ def func(self):\n \n \n                 pass\n-            elif token in [LaTeXParser.LETTER, LaTeXParser.SYMBOL]:\n+            elif token in [75, 88]:\n                 self.enterOuterAlt(localctx, 2)\n                 self.state = 353\n                 _la = self._input.LA(1)\n-                if not(_la==LaTeXParser.LETTER or _la==LaTeXParser.SYMBOL):\n+                if not(_la==75 or _la==88):\n                     self._errHandler.recoverInline(self)\n                 else:\n                     self._errHandler.reportMatch(self)\n@@ -2786,7 +2775,7 @@ def func(self):\n                 self.state = 355\n                 self._errHandler.sync(self)\n                 _la = self._input.LA(1)\n-                if _la==LaTeXParser.UNDERSCORE:\n+                if _la==71:\n                     self.state = 354\n                     self.subexpr()\n \n@@ -2798,26 +2787,26 @@ def func(self):\n                 self.state = 359\n                 self.match(LaTeXParser.R_PAREN)\n                 pass\n-            elif token in [LaTeXParser.FUNC_INT]:\n+            elif token in [33]:\n                 self.enterOuterAlt(localctx, 3)\n                 self.state = 361\n                 self.match(LaTeXParser.FUNC_INT)\n                 self.state = 368\n                 self._errHandler.sync(self)\n                 token = self._input.LA(1)\n-                if token in [LaTeXParser.UNDERSCORE]:\n+                if token in [71]:\n                     self.state = 362\n                     self.subexpr()\n                     self.state = 363\n                     self.supexpr()\n                     pass\n-                elif token in [LaTeXParser.CARET]:\n+                elif token in [72]:\n                     self.state = 365\n                     self.supexpr()\n                     self.state = 366\n                     self.subexpr()\n                     pass\n-                elif token in [LaTeXParser.ADD, LaTeXParser.SUB, LaTeXParser.L_PAREN, LaTeXParser.L_BRACE, LaTeXParser.L_BRACE_LITERAL, LaTeXParser.L_BRACKET, LaTeXParser.BAR, LaTeXParser.L_BAR, LaTeXParser.L_ANGLE, LaTeXParser.FUNC_LIM, LaTeXParser.FUNC_INT, LaTeXParser.FUNC_SUM, LaTeXParser.FUNC_PROD, LaTeXParser.FUNC_EXP, LaTeXParser.FUNC_LOG, LaTeXParser.FUNC_LN, LaTeXParser.FUNC_SIN, LaTeXParser.FUNC_COS, LaTeXParser.FUNC_TAN, LaTeXParser.FUNC_CSC, LaTeXParser.FUNC_SEC, LaTeXParser.FUNC_COT, LaTeXParser.FUNC_ARCSIN, LaTeXParser.FUNC_ARCCOS, LaTeXParser.FUNC_ARCTAN, LaTeXParser.FUNC_ARCCSC, LaTeXParser.FUNC_ARCSEC, LaTeXParser.FUNC_ARCCOT, LaTeXParser.FUNC_SINH, LaTeXParser.FUNC_COSH, LaTeXParser.FUNC_TANH, LaTeXParser.FUNC_ARSINH, LaTeXParser.FUNC_ARCOSH, LaTeXParser.FUNC_ARTANH, LaTeXParser.L_FLOOR, LaTeXParser.L_CEIL, LaTeXParser.FUNC_SQRT, LaTeXParser.FUNC_OVERLINE, LaTeXParser.CMD_FRAC, LaTeXParser.CMD_BINOM, LaTeXParser.CMD_DBINOM, LaTeXParser.CMD_TBINOM, LaTeXParser.CMD_MATHIT, LaTeXParser.DIFFERENTIAL, LaTeXParser.LETTER, LaTeXParser.NUMBER, LaTeXParser.SYMBOL]:\n+                elif token in [14, 15, 18, 20, 22, 24, 26, 28, 29, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 61, 62, 66, 67, 68, 69, 70, 74, 75, 76, 88]:\n                     pass\n                 else:\n                     pass\n@@ -2849,14 +2838,14 @@ def func(self):\n \n \n                 pass\n-            elif token in [LaTeXParser.FUNC_SQRT]:\n+            elif token in [61]:\n                 self.enterOuterAlt(localctx, 4)\n                 self.state = 378\n                 self.match(LaTeXParser.FUNC_SQRT)\n                 self.state = 383\n                 self._errHandler.sync(self)\n                 _la = self._input.LA(1)\n-                if _la==LaTeXParser.L_BRACKET:\n+                if _la==24:\n                     self.state = 379\n                     self.match(LaTeXParser.L_BRACKET)\n                     self.state = 380\n@@ -2872,7 +2861,7 @@ def func(self):\n                 self.state = 387\n                 self.match(LaTeXParser.R_BRACE)\n                 pass\n-            elif token in [LaTeXParser.FUNC_OVERLINE]:\n+            elif token in [62]:\n                 self.enterOuterAlt(localctx, 5)\n                 self.state = 389\n                 self.match(LaTeXParser.FUNC_OVERLINE)\n@@ -2883,11 +2872,11 @@ def func(self):\n                 self.state = 392\n                 self.match(LaTeXParser.R_BRACE)\n                 pass\n-            elif token in [LaTeXParser.FUNC_SUM, LaTeXParser.FUNC_PROD]:\n+            elif token in [34, 35]:\n                 self.enterOuterAlt(localctx, 6)\n                 self.state = 394\n                 _la = self._input.LA(1)\n-                if not(_la==LaTeXParser.FUNC_SUM or _la==LaTeXParser.FUNC_PROD):\n+                if not(_la==34 or _la==35):\n                     self._errHandler.recoverInline(self)\n                 else:\n                     self._errHandler.reportMatch(self)\n@@ -2895,13 +2884,13 @@ def func(self):\n                 self.state = 401\n                 self._errHandler.sync(self)\n                 token = self._input.LA(1)\n-                if token in [LaTeXParser.UNDERSCORE]:\n+                if token in [71]:\n                     self.state = 395\n                     self.subeq()\n                     self.state = 396\n                     self.supexpr()\n                     pass\n-                elif token in [LaTeXParser.CARET]:\n+                elif token in [72]:\n                     self.state = 398\n                     self.supexpr()\n                     self.state = 399\n@@ -2913,7 +2902,7 @@ def func(self):\n                 self.state = 403\n                 self.mp(0)\n                 pass\n-            elif token in [LaTeXParser.FUNC_LIM]:\n+            elif token in [31]:\n                 self.enterOuterAlt(localctx, 7)\n                 self.state = 405\n                 self.match(LaTeXParser.FUNC_LIM)\n@@ -2935,9 +2924,10 @@ def func(self):\n \n \n     class ArgsContext(ParserRuleContext):\n+        __slots__ = 'parser'\n \n-        def __init__(self, parser, parent=None, invokingState=-1):\n-            super(LaTeXParser.ArgsContext, self).__init__(parent, invokingState)\n+        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):\n+            super().__init__(parent, invokingState)\n             self.parser = parser\n \n         def expr(self):\n@@ -2989,15 +2979,16 @@ def args(self):\n \n \n     class Limit_subContext(ParserRuleContext):\n+        __slots__ = 'parser'\n \n-        def __init__(self, parser, parent=None, invokingState=-1):\n-            super(LaTeXParser.Limit_subContext, self).__init__(parent, invokingState)\n+        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):\n+            super().__init__(parent, invokingState)\n             self.parser = parser\n \n         def UNDERSCORE(self):\n             return self.getToken(LaTeXParser.UNDERSCORE, 0)\n \n-        def L_BRACE(self, i=None):\n+        def L_BRACE(self, i:int=None):\n             if i is None:\n                 return self.getTokens(LaTeXParser.L_BRACE)\n             else:\n@@ -3010,7 +3001,7 @@ def expr(self):\n             return self.getTypedRuleContext(LaTeXParser.ExprContext,0)\n \n \n-        def R_BRACE(self, i=None):\n+        def R_BRACE(self, i:int=None):\n             if i is None:\n                 return self.getTokens(LaTeXParser.R_BRACE)\n             else:\n@@ -3050,7 +3041,7 @@ def limit_sub(self):\n             self.match(LaTeXParser.L_BRACE)\n             self.state = 420\n             _la = self._input.LA(1)\n-            if not(_la==LaTeXParser.LETTER or _la==LaTeXParser.SYMBOL):\n+            if not(_la==75 or _la==88):\n                 self._errHandler.recoverInline(self)\n             else:\n                 self._errHandler.reportMatch(self)\n@@ -3062,14 +3053,14 @@ def limit_sub(self):\n             self.state = 427\n             self._errHandler.sync(self)\n             _la = self._input.LA(1)\n-            if _la==LaTeXParser.CARET:\n+            if _la==72:\n                 self.state = 423\n                 self.match(LaTeXParser.CARET)\n                 self.state = 424\n                 self.match(LaTeXParser.L_BRACE)\n                 self.state = 425\n                 _la = self._input.LA(1)\n-                if not(_la==LaTeXParser.ADD or _la==LaTeXParser.SUB):\n+                if not(_la==14 or _la==15):\n                     self._errHandler.recoverInline(self)\n                 else:\n                     self._errHandler.reportMatch(self)\n@@ -3090,9 +3081,10 @@ def limit_sub(self):\n \n \n     class Func_argContext(ParserRuleContext):\n+        __slots__ = 'parser'\n \n-        def __init__(self, parser, parent=None, invokingState=-1):\n-            super(LaTeXParser.Func_argContext, self).__init__(parent, invokingState)\n+        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):\n+            super().__init__(parent, invokingState)\n             self.parser = parser\n \n         def expr(self):\n@@ -3144,9 +3136,10 @@ def func_arg(self):\n \n \n     class Func_arg_noparensContext(ParserRuleContext):\n+        __slots__ = 'parser'\n \n-        def __init__(self, parser, parent=None, invokingState=-1):\n-            super(LaTeXParser.Func_arg_noparensContext, self).__init__(parent, invokingState)\n+        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):\n+            super().__init__(parent, invokingState)\n             self.parser = parser\n \n         def mp_nofunc(self):\n@@ -3177,9 +3170,10 @@ def func_arg_noparens(self):\n \n \n     class SubexprContext(ParserRuleContext):\n+        __slots__ = 'parser'\n \n-        def __init__(self, parser, parent=None, invokingState=-1):\n-            super(LaTeXParser.SubexprContext, self).__init__(parent, invokingState)\n+        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):\n+            super().__init__(parent, invokingState)\n             self.parser = parser\n \n         def UNDERSCORE(self):\n@@ -3216,11 +3210,11 @@ def subexpr(self):\n             self.state = 446\n             self._errHandler.sync(self)\n             token = self._input.LA(1)\n-            if token in [LaTeXParser.BAR, LaTeXParser.L_BAR, LaTeXParser.L_ANGLE, LaTeXParser.CMD_MATHIT, LaTeXParser.DIFFERENTIAL, LaTeXParser.LETTER, LaTeXParser.NUMBER, LaTeXParser.SYMBOL]:\n+            if token in [26, 28, 29, 70, 74, 75, 76, 88]:\n                 self.state = 441\n                 self.atom()\n                 pass\n-            elif token in [LaTeXParser.L_BRACE]:\n+            elif token in [20]:\n                 self.state = 442\n                 self.match(LaTeXParser.L_BRACE)\n                 self.state = 443\n@@ -3241,9 +3235,10 @@ def subexpr(self):\n \n \n     class SupexprContext(ParserRuleContext):\n+        __slots__ = 'parser'\n \n-        def __init__(self, parser, parent=None, invokingState=-1):\n-            super(LaTeXParser.SupexprContext, self).__init__(parent, invokingState)\n+        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):\n+            super().__init__(parent, invokingState)\n             self.parser = parser\n \n         def CARET(self):\n@@ -3280,11 +3275,11 @@ def supexpr(self):\n             self.state = 454\n             self._errHandler.sync(self)\n             token = self._input.LA(1)\n-            if token in [LaTeXParser.BAR, LaTeXParser.L_BAR, LaTeXParser.L_ANGLE, LaTeXParser.CMD_MATHIT, LaTeXParser.DIFFERENTIAL, LaTeXParser.LETTER, LaTeXParser.NUMBER, LaTeXParser.SYMBOL]:\n+            if token in [26, 28, 29, 70, 74, 75, 76, 88]:\n                 self.state = 449\n                 self.atom()\n                 pass\n-            elif token in [LaTeXParser.L_BRACE]:\n+            elif token in [20]:\n                 self.state = 450\n                 self.match(LaTeXParser.L_BRACE)\n                 self.state = 451\n@@ -3305,9 +3300,10 @@ def supexpr(self):\n \n \n     class SubeqContext(ParserRuleContext):\n+        __slots__ = 'parser'\n \n-        def __init__(self, parser, parent=None, invokingState=-1):\n-            super(LaTeXParser.SubeqContext, self).__init__(parent, invokingState)\n+        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):\n+            super().__init__(parent, invokingState)\n             self.parser = parser\n \n         def UNDERSCORE(self):\n@@ -3353,9 +3349,10 @@ def subeq(self):\n \n \n     class SupeqContext(ParserRuleContext):\n+        __slots__ = 'parser'\n \n-        def __init__(self, parser, parent=None, invokingState=-1):\n-            super(LaTeXParser.SupeqContext, self).__init__(parent, invokingState)\n+        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):\n+            super().__init__(parent, invokingState)\n             self.parser = parser\n \n         def UNDERSCORE(self):\n@@ -3401,7 +3398,7 @@ def supeq(self):\n \n \n \n-    def sempred(self, localctx, ruleIndex, predIndex):\n+    def sempred(self, localctx:RuleContext, ruleIndex:int, predIndex:int):\n         if self._predicates == None:\n             self._predicates = dict()\n         self._predicates[1] = self.relation_sempred\n@@ -3416,32 +3413,32 @@ def sempred(self, localctx, ruleIndex, predIndex):\n         else:\n             return pred(localctx, predIndex)\n \n-    def relation_sempred(self, localctx, predIndex):\n+    def relation_sempred(self, localctx:RelationContext, predIndex:int):\n             if predIndex == 0:\n                 return self.precpred(self._ctx, 2)\n \n \n-    def additive_sempred(self, localctx, predIndex):\n+    def additive_sempred(self, localctx:AdditiveContext, predIndex:int):\n             if predIndex == 1:\n                 return self.precpred(self._ctx, 2)\n \n \n-    def mp_sempred(self, localctx, predIndex):\n+    def mp_sempred(self, localctx:MpContext, predIndex:int):\n             if predIndex == 2:\n                 return self.precpred(self._ctx, 2)\n \n \n-    def mp_nofunc_sempred(self, localctx, predIndex):\n+    def mp_nofunc_sempred(self, localctx:Mp_nofuncContext, predIndex:int):\n             if predIndex == 3:\n                 return self.precpred(self._ctx, 2)\n \n \n-    def exp_sempred(self, localctx, predIndex):\n+    def exp_sempred(self, localctx:ExpContext, predIndex:int):\n             if predIndex == 4:\n                 return self.precpred(self._ctx, 2)\n \n \n-    def exp_nofunc_sempred(self, localctx, predIndex):\n+    def exp_nofunc_sempred(self, localctx:Exp_nofuncContext, predIndex:int):\n             if predIndex == 5:\n                 return self.precpred(self._ctx, 2)\n \ndiff --git a/sympy/parsing/latex/_build_latex_antlr.py b/sympy/parsing/latex/_build_latex_antlr.py\nindex bd780e2661..8562107119 100644\n--- a/sympy/parsing/latex/_build_latex_antlr.py\n+++ b/sympy/parsing/latex/_build_latex_antlr.py\n@@ -52,6 +52,7 @@ def build_parser(output_dir=dir_latex_antlr):\n         \"antlr4\",\n         grammar_file,\n         \"-o\", output_dir,\n+        \"-Dlanguage=Python3\",  # Explicitly specify Python3 target\n         # for now, not generating these as latex2sympy did not use them\n         \"-no-visitor\",\n         \"-no-listener\",\n@@ -78,9 +79,12 @@ def build_parser(output_dir=dir_latex_antlr):\n         os.unlink(path)\n \n         with open(new_path, \"w\") as out_file:\n-            offset = 2\n             out_file.write(header)\n-            out_file.writelines(lines[offset:])\n+            # Skip the first line (ANTLR comment) but preserve imports\n+            for i, line in enumerate(lines):\n+                if i == 0:  # Skip \"# Generated from LaTeX.g4 by ANTLR ...\"\n+                    continue\n+                out_file.write(line)\n \n         debug(\"\\t{}\".format(new_path))\n \ndiff --git a/sympy/parsing/latex/_parse_latex_antlr.py b/sympy/parsing/latex/_parse_latex_antlr.py\nindex 2e4a45ad20..50fb7eb906 100644\n--- a/sympy/parsing/latex/_parse_latex_antlr.py\n+++ b/sympy/parsing/latex/_parse_latex_antlr.py\n@@ -67,6 +67,23 @@ def parse_latex(sympy):\n                           \" antlr4-python3-runtime) or\"\n                           \" conda (antlr-python-runtime)\")\n \n+    if None in [LaTeXLexer, LaTeXParser]:\n+        raise ImportError(\"LaTeX parsing is not available due to an ANTLR version \"\n+                          \"compatibility issue. The generated ANTLR files are from \"\n+                          \"ANTLR version 3, but the installed antlr4 runtime requires \"\n+                          \"version 4. Please regenerate the ANTLR files by running \"\n+                          \"'python setup.py antlr' in the SymPy root directory, or \"\n+                          \"install a compatible version of the antlr4 runtime.\")\n+\n+    # Check if LaTeX ANTLR classes are available\n+    if None in [LaTeXLexer, LaTeXParser]:\n+        raise ImportError(\"LaTeX parsing is not available due to an ANTLR version \"\n+                          \"compatibility issue. The generated ANTLR files are from \"\n+                          \"ANTLR version 3, but the installed antlr4 runtime requires \"\n+                          \"version 4. Please regenerate the ANTLR files by running \"\n+                          \"'python setup.py antlr' in the SymPy root directory, or \"\n+                          \"install a compatible version of the antlr4 runtime.\")\n+\n     matherror = MathErrorListener(sympy)\n \n     stream = antlr4.InputStream(sympy)\n@@ -382,11 +399,35 @@ def convert_frac(frac):\n \n     expr_top = convert_expr(frac.upper)\n     expr_bot = convert_expr(frac.lower)\n-    inverse_denom = sympy.Pow(expr_bot, -1, evaluate=False)\n+    \n+    # Handle fractions with proper precedence\n+    # For nested fractions, we need to ensure proper parenthesization\n+    \n+    # Check if the denominator is a fraction (Pow with exp=-1) that needs special handling\n+    is_fraction_denom = (isinstance(expr_bot, sympy.Pow) and expr_bot.exp == -1)\n+    \n     if expr_top == 1:\n-        return inverse_denom\n+        # For simple 1/x cases, use Pow directly to maintain compatibility\n+        # But for complex denominators, use Mul for proper grouping\n+        is_complex_denom = (isinstance(expr_bot, sympy.Mul) or \n+                           (is_fraction_denom and not expr_bot.base.is_Symbol))\n+        \n+        if is_complex_denom:\n+            # Complex denominator (Mul) or nested fraction (Pow with exp=-1 and complex base)\n+            # Use Mul to ensure proper parenthesization\n+            return sympy.Mul(1, sympy.Pow(expr_bot, -1, evaluate=False), evaluate=False)\n+        else:\n+            # Simple denominator - use Pow directly for compatibility\n+            return sympy.Pow(expr_bot, -1, evaluate=False)\n     else:\n-        return sympy.Mul(expr_top, inverse_denom, evaluate=False)\n+        # For non-unity numerators, we need to handle fraction denominators specially\n+        if is_fraction_denom:\n+            # When the denominator is itself a fraction, we need to ensure proper grouping\n+            # Use the reciprocal directly to avoid double inversion\n+            return sympy.Mul(expr_top, expr_bot.base, evaluate=False)\n+        else:\n+            # Standard case\n+            return sympy.Mul(expr_top, sympy.Pow(expr_bot, -1, evaluate=False), evaluate=False)\n \n def convert_binom(binom):\n     expr_n = convert_expr(binom.n)\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "django__django-13401", "model_patch": "diff --git a/django/db/models/fields/__init__.py b/django/db/models/fields/__init__.py\nindex 28374272f4..adf106f7e4 100644\n--- a/django/db/models/fields/__init__.py\n+++ b/django/db/models/fields/__init__.py\n@@ -516,17 +516,32 @@ class Field(RegisterLookupMixin):\n     def __eq__(self, other):\n         # Needed for @total_ordering\n         if isinstance(other, Field):\n-            return self.creation_counter == other.creation_counter\n+            return (self.creation_counter == other.creation_counter and\n+                    getattr(self, 'model', None) == getattr(other, 'model', None))\n         return NotImplemented\n \n     def __lt__(self, other):\n         # This is needed because bisect does not take a comparison function.\n+        # Order by creation_counter first to preserve existing behavior,\n+        # then by model to ensure consistent ordering when counters are equal.\n         if isinstance(other, Field):\n-            return self.creation_counter < other.creation_counter\n+            if self.creation_counter != other.creation_counter:\n+                return self.creation_counter < other.creation_counter\n+            # When creation_counters are equal, order by model\n+            self_model = getattr(self, 'model', None)\n+            other_model = getattr(other, 'model', None)\n+            if self_model is None and other_model is None:\n+                return False  # Both are None, consider equal for ordering\n+            if self_model is None:\n+                return True   # None comes before any model\n+            if other_model is None:\n+                return False  # Any model comes after None\n+            # Compare model names for consistent ordering\n+            return (self_model._meta.label_lower < other_model._meta.label_lower)\n         return NotImplemented\n \n     def __hash__(self):\n-        return hash(self.creation_counter)\n+        return hash((self.creation_counter, getattr(self, 'model', None)))\n \n     def __deepcopy__(self, memodict):\n         # We don't have to deepcopy very much here, since most things are not\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "sympy__sympy-13647", "model_patch": "diff --git a/sympy/matrices/common.py b/sympy/matrices/common.py\nindex 056d9bc497..4aa75e4d77 100644\n--- a/sympy/matrices/common.py\n+++ b/sympy/matrices/common.py\n@@ -86,7 +86,7 @@ def entry(i, j):\n                 return self[i, j]\n             elif pos <= j < pos + other.cols:\n                 return other[i, j - pos]\n-            return self[i, j - pos - other.cols]\n+            return self[i, j - other.cols]\n \n         return self._new(self.rows, self.cols + other.cols,\n                          lambda i, j: entry(i, j))\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "django__django-14017", "model_patch": "diff --git a/django/db/models/query_utils.py b/django/db/models/query_utils.py\nindex c957ffa564..ec296a85e5 100644\n--- a/django/db/models/query_utils.py\n+++ b/django/db/models/query_utils.py\n@@ -41,7 +41,11 @@ class Q(tree.Node):\n \n     def _combine(self, other, conn):\n         if not isinstance(other, Q):\n-            raise TypeError(other)\n+            # Allow combining with other conditional expressions (like Exists)\n+            if not getattr(other, 'conditional', False):\n+                raise TypeError(other)\n+            # Convert the conditional expression to a Q object\n+            other = Q(other)\n \n         # If the other Q() is empty, ignore it and just use `self`.\n         if not other:\n@@ -49,6 +53,12 @@ class Q(tree.Node):\n             return type(self)(*args, **kwargs)\n         # Or if this Q is empty, ignore it and just use `other`.\n         elif not self:\n+            # If other contains non-tuple children (like wrapped expressions),\n+            # we can't use deconstruct(), so just return other directly\n+            if (len(other.children) == 1 and \n+                not isinstance(other.children[0], Q) and \n+                not isinstance(other.children[0], tuple)):\n+                return other\n             _, args, kwargs = other.deconstruct()\n             return type(other)(*args, **kwargs)\n \ndiff --git a/tests/queries/test_q.py b/tests/queries/test_q.py\nindex 6dcf36ce02..372504fdc3 100644\n--- a/tests/queries/test_q.py\n+++ b/tests/queries/test_q.py\n@@ -1,6 +1,8 @@\n-from django.db.models import F, Q\n+from django.db.models import F, Q, Exists\n from django.test import SimpleTestCase\n \n+from .models import Author\n+\n \n class QTests(SimpleTestCase):\n     def test_combine_and_empty(self):\n@@ -111,3 +113,58 @@ class QTests(SimpleTestCase):\n         q = q1 & q2\n         path, args, kwargs = q.deconstruct()\n         self.assertEqual(Q(*args, **kwargs), q)\n+\n+    def test_combine_q_and_exists(self):\n+        \"\"\"Test that Q and Exists can be combined in both directions.\"\"\"\n+        queryset = Author.objects.all()\n+        exists = Exists(queryset)\n+        q_empty = Q()\n+        q_with_condition = Q(name='test')\n+        \n+        # Test Q() & Exists(...)\n+        result = q_empty & exists\n+        self.assertIsInstance(result, Q)\n+        self.assertEqual(len(result.children), 1)\n+        self.assertIn(exists, result.children)\n+        \n+        # Test Exists(...) & Q()\n+        result = exists & q_empty\n+        self.assertIsInstance(result, Q)\n+        self.assertEqual(len(result.children), 2)\n+        self.assertIn(exists, result.children)\n+        \n+        # Test Q() | Exists(...)\n+        result = q_empty | exists\n+        self.assertIsInstance(result, Q)\n+        self.assertEqual(len(result.children), 1)\n+        self.assertIn(exists, result.children)\n+        \n+        # Test Exists(...) | Q()\n+        result = exists | q_empty\n+        self.assertIsInstance(result, Q)\n+        self.assertEqual(len(result.children), 2)\n+        self.assertIn(exists, result.children)\n+        \n+        # Test Q(name='test') & Exists(...)\n+        result = q_with_condition & exists\n+        self.assertIsInstance(result, Q)\n+        self.assertEqual(len(result.children), 2)\n+        self.assertIn(exists, result.children)\n+        \n+        # Test Exists(...) & Q(name='test')\n+        result = exists & q_with_condition\n+        self.assertIsInstance(result, Q)\n+        self.assertEqual(len(result.children), 2)\n+        self.assertIn(exists, result.children)\n+        \n+        # Test Q(name='test') | Exists(...)\n+        result = q_with_condition | exists\n+        self.assertIsInstance(result, Q)\n+        self.assertEqual(len(result.children), 2)\n+        self.assertIn(exists, result.children)\n+        \n+        # Test Exists(...) | Q(name='test')\n+        result = exists | q_with_condition\n+        self.assertIsInstance(result, Q)\n+        self.assertEqual(len(result.children), 2)\n+        self.assertIn(exists, result.children)\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "sympy__sympy-13480", "model_patch": "diff --git a/sympy/functions/elementary/hyperbolic.py b/sympy/functions/elementary/hyperbolic.py\nindex 2a4555d919..5fbb73c786 100644\n--- a/sympy/functions/elementary/hyperbolic.py\n+++ b/sympy/functions/elementary/hyperbolic.py\n@@ -587,7 +587,7 @@ def eval(cls, arg):\n                 x, m = _peeloff_ipi(arg)\n                 if m:\n                     cothm = coth(m)\n-                    if cotm is S.ComplexInfinity:\n+                    if cothm is S.ComplexInfinity:\n                         return coth(x)\n                     else: # cothm == 0\n                         return tanh(x)\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "scikit-learn__scikit-learn-13496", "model_patch": "diff --git a/examples/ensemble/plot_isolation_forest.py b/examples/ensemble/plot_isolation_forest.py\nindex 1b79072df..ff700ebee 100644\n--- a/examples/ensemble/plot_isolation_forest.py\n+++ b/examples/ensemble/plot_isolation_forest.py\n@@ -21,6 +21,10 @@ Random partitioning produces noticeable shorter paths for anomalies.\n Hence, when a forest of random trees collectively produce shorter path lengths\n for particular samples, they are highly likely to be anomalies.\n \n+Note: IsolationForest supports incremental learning through the `warm_start`\n+parameter. When `warm_start=True`, you can add more trees to an existing\n+forest by increasing `n_estimators` and calling `fit()` again.\n+\n \"\"\"\n print(__doc__)\n \ndiff --git a/sklearn/ensemble/iforest.py b/sklearn/ensemble/iforest.py\nindex 8a1bd3625..f42c80532 100644\n--- a/sklearn/ensemble/iforest.py\n+++ b/sklearn/ensemble/iforest.py\n@@ -120,6 +120,11 @@ class IsolationForest(BaseBagging, OutlierMixin):\n     verbose : int, optional (default=0)\n         Controls the verbosity of the tree building process.\n \n+    warm_start : bool, optional (default=False)\n+        When set to ``True``, reuse the solution of the previous call to fit\n+        and add more estimators to the ensemble, otherwise, just fit a whole\n+        new forest. See :term:`the Glossary <warm_start>`.\n+\n \n     Attributes\n     ----------\n@@ -173,7 +178,8 @@ class IsolationForest(BaseBagging, OutlierMixin):\n                  n_jobs=None,\n                  behaviour='old',\n                  random_state=None,\n-                 verbose=0):\n+                 verbose=0,\n+                 warm_start=False):\n         super().__init__(\n             base_estimator=ExtraTreeRegressor(\n                 max_features=1,\n@@ -187,7 +193,8 @@ class IsolationForest(BaseBagging, OutlierMixin):\n             max_features=max_features,\n             n_jobs=n_jobs,\n             random_state=random_state,\n-            verbose=verbose)\n+            verbose=verbose,\n+            warm_start=warm_start)\n \n         self.behaviour = behaviour\n         self.contamination = contamination\ndiff --git a/sklearn/ensemble/tests/test_iforest.py b/sklearn/ensemble/tests/test_iforest.py\nindex 67ba2d7f9..93c02c8ee 100644\n--- a/sklearn/ensemble/tests/test_iforest.py\n+++ b/sklearn/ensemble/tests/test_iforest.py\n@@ -359,3 +359,94 @@ def test_iforest_chunks_works2(\n ):\n     test_iforest_works(contamination)\n     assert mocked_get_chunk.call_count == n_predict_calls\n+\n+\n+@pytest.mark.filterwarnings('ignore:default contamination')\n+@pytest.mark.filterwarnings('ignore:behaviour=\"old\"')\n+def test_iforest_warm_start():\n+    \"\"\"Test warm_start parameter in IsolationForest.\"\"\"\n+    # Test that warm_start parameter can be passed to constructor\n+    clf = IsolationForest(n_estimators=5, warm_start=True, random_state=42)\n+    assert clf.warm_start is True\n+    \n+    clf = IsolationForest(n_estimators=5, warm_start=False, random_state=42)\n+    assert clf.warm_start is False\n+    \n+    # Test default value\n+    clf = IsolationForest(n_estimators=5, random_state=42)\n+    assert clf.warm_start is False\n+\n+\n+@pytest.mark.filterwarnings('ignore:default contamination')\n+@pytest.mark.filterwarnings('ignore:behaviour=\"old\"')\n+def test_iforest_warm_start_functionality():\n+    \"\"\"Test that warm_start works correctly for incremental learning.\"\"\"\n+    X = iris.data\n+    \n+    # Test warm start behavior\n+    clf = IsolationForest(n_estimators=5, warm_start=True, random_state=42)\n+    clf.fit(X)\n+    \n+    # Check initial number of estimators\n+    assert len(clf.estimators_) == 5\n+    \n+    # Increase n_estimators and fit again\n+    clf.n_estimators = 10\n+    clf.fit(X)\n+    \n+    # Should have 10 estimators now (5 old + 5 new)\n+    assert len(clf.estimators_) == 10\n+    \n+    # Test that cold start retrains all estimators\n+    clf_cold = IsolationForest(n_estimators=5, warm_start=False, random_state=42)\n+    clf_cold.fit(X)\n+    assert len(clf_cold.estimators_) == 5\n+    \n+    clf_cold.n_estimators = 10\n+    clf_cold.fit(X)\n+    assert len(clf_cold.estimators_) == 10\n+\n+\n+@pytest.mark.filterwarnings('ignore:default contamination')\n+@pytest.mark.filterwarnings('ignore:behaviour=\"old\"')\n+def test_iforest_warm_start_predictions():\n+    \"\"\"Test that warm_start produces valid predictions.\"\"\"\n+    X = iris.data[:50]  # Use smaller dataset for faster testing\n+    X_test = iris.data[50:55]\n+    \n+    # Create model with warm start\n+    clf = IsolationForest(n_estimators=5, warm_start=True, random_state=42)\n+    clf.fit(X)\n+    \n+    # Get predictions after first fit\n+    pred1 = clf.predict(X_test)\n+    \n+    # Increase estimators and fit again\n+    clf.n_estimators = 10\n+    clf.fit(X)\n+    \n+    # Get predictions after warm start\n+    pred2 = clf.predict(X_test)\n+    \n+    # Both predictions should be valid (same length as test data)\n+    assert len(pred1) == len(X_test)\n+    assert len(pred2) == len(X_test)\n+    \n+    # Predictions should be in {-1, 1}\n+    assert_array_equal(np.unique(pred1), np.array([-1, 1]))\n+    assert_array_equal(np.unique(pred2), np.array([-1, 1]))\n+\n+\n+@pytest.mark.filterwarnings('ignore:default contamination')\n+@pytest.mark.filterwarnings('ignore:behaviour=\"old\"')\n+def test_iforest_warm_start_oob_error():\n+    \"\"\"Test that warm_start and oob_score are incompatible.\"\"\"\n+    # This should raise an error as warm_start and oob_score are incompatible\n+    # in BaseBagging\n+    with pytest.raises(ValueError, match=\"Out of bag estimate only available\"):\n+        clf = IsolationForest(warm_start=True, bootstrap=True)\n+        # Note: IsolationForest doesn't support oob_score, but this tests\n+        # the inherited behavior from BaseBagging\n+        clf._set_oob_score = lambda X, y: None  # Mock to avoid NotImplementedError\n+        clf.oob_score = True\n+        clf.fit(iris.data)\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "django__django-13590", "model_patch": "diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\nindex 4648daf395..a7961039ed 100644\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -1077,10 +1077,18 @@ class Query(BaseExpression):\n         elif isinstance(value, (list, tuple)):\n             # The items of the iterable may be expressions and therefore need\n             # to be resolved independently.\n-            return type(value)(\n+            resolved_values = tuple(\n                 self.resolve_lookup_value(sub_value, can_reuse, allow_joins)\n                 for sub_value in value\n             )\n+            \n+            # Check if this is a named tuple by looking for the _make method\n+            if hasattr(value, '_make'):\n+                # Use _make for named tuples as their constructors don't accept generators\n+                return type(value)._make(resolved_values)\n+            else:\n+                # Use regular constructor for lists/tuples\n+                return type(value)(resolved_values)\n         return value\n \n     def solve_lookup_type(self, lookup):\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "sympy__sympy-21847", "model_patch": "diff --git a/sympy/polys/monomials.py b/sympy/polys/monomials.py\nindex 0e84403307..43e7c4c757 100644\n--- a/sympy/polys/monomials.py\n+++ b/sympy/polys/monomials.py\n@@ -127,7 +127,8 @@ def itermonomials(variables, max_degrees, min_degrees=None):\n                 for variable in item:\n                     if variable != 1:\n                         powers[variable] += 1\n-                if max(powers.values()) >= min_degree:\n+                total_deg = sum(count for var, count in powers.items() if var != S.One)\n+                if min_degree <= total_deg <= max_degree:\n                     monomials_list_comm.append(Mul(*item))\n             yield from set(monomials_list_comm)\n         else:\n@@ -139,7 +140,8 @@ def itermonomials(variables, max_degrees, min_degrees=None):\n                 for variable in item:\n                     if variable != 1:\n                         powers[variable] += 1\n-                if max(powers.values()) >= min_degree:\n+                total_deg = sum(count for var, count in powers.items() if var != S.One)\n+                if min_degree <= total_deg <= max_degree:\n                     monomials_list_non_comm.append(Mul(*item))\n             yield from set(monomials_list_non_comm)\n     else:\ndiff --git a/sympy/polys/tests/test_monomials.py b/sympy/polys/tests/test_monomials.py\nindex 482cbee30d..0714ee768e 100644\n--- a/sympy/polys/tests/test_monomials.py\n+++ b/sympy/polys/tests/test_monomials.py\n@@ -162,6 +162,41 @@ def test_monomials():\n                     x*j**2, x*k**2, x*j*k, x**2*j**2*k**2, x*j*k**2, x**2, x**2*j*k**2\n             }\n \n+def test_itermonomials_min_degrees_total_degree():\n+    \"\"\"Test itermonomials with min_degrees in total degree mode.\n+    \n+    This test ensures that when min_degrees is specified in total degree mode,\n+    all monomials with total degree between min_degrees and max_degrees are\n+    generated, including mixed terms, not just pure powers.\n+    \n+    This addresses the bug where only monomials with max individual degree >= min_degree\n+    were generated instead of all monomials with total degree >= min_degree.\n+    \"\"\"\n+    # Test exact degree (min_degrees = max_degrees)\n+    assert set(itermonomials([x, y], 2, min_degrees=2)) == {x**2, x*y, y**2}\n+    assert set(itermonomials([x, y, z], 3, min_degrees=3)) == {\n+        x**3, y**3, z**3,  # pure powers\n+        x**2*y, x**2*z, y**2*x, y**2*z, z**2*x, z**2*y,  # mixed degree 3\n+        x*y*z  # all variables degree 1\n+    }\n+    \n+    # Test degree range\n+    assert set(itermonomials([x, y], 2, min_degrees=1)) == {x, y, x**2, x*y, y**2}\n+    assert set(itermonomials([x, y, z], 3, min_degrees=2)) == {\n+        x**2, y**2, z**2, x*y, x*z, y*z,  # degree 2\n+        x**3, y**3, z**3, x**2*y, x**2*z, y**2*x, y**2*z, z**2*x, z**2*y, x*y*z  # degree 3\n+    }\n+    \n+    # Test single variable\n+    assert set(itermonomials([x], 3, min_degrees=2)) == {x**2, x**3}\n+    \n+    # Test edge case with min_degrees = 0\n+    assert set(itermonomials([x, y], 1, min_degrees=0)) == {S.One, x, y}\n+    \n+    # Test non-commutative variables\n+    i, j = symbols('i j', commutative=False)\n+    assert set(itermonomials([i, j], 2, min_degrees=2)) == {i**2, i*j, j*i, j**2}\n+\n def test_monomial_count():\n     assert monomial_count(2, 2) == 6\n     assert monomial_count(2, 3) == 10\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "django__django-14915", "model_patch": "diff --git a/django/forms/models.py b/django/forms/models.py\nindex 5dcf923c12..4460380c99 100644\n--- a/django/forms/models.py\n+++ b/django/forms/models.py\n@@ -1171,6 +1171,12 @@ class ModelChoiceIteratorValue:\n             other = other.value\n         return self.value == other\n \n+    def __hash__(self):\n+        return hash(self.value)\n+\n+    def __hash__(self):\n+        return hash(self.value)\n+\n \n class ModelChoiceIterator:\n     def __init__(self, field):\ndiff --git a/tests/model_forms/test_modelchoicefield.py b/tests/model_forms/test_modelchoicefield.py\nindex 2a0c05d803..1fd003eced 100644\n--- a/tests/model_forms/test_modelchoicefield.py\n+++ b/tests/model_forms/test_modelchoicefield.py\n@@ -2,7 +2,7 @@ import datetime\n \n from django import forms\n from django.core.exceptions import ValidationError\n-from django.forms.models import ModelChoiceIterator\n+from django.forms.models import ModelChoiceIterator, ModelChoiceIteratorValue\n from django.forms.widgets import CheckboxSelectMultiple\n from django.template import Context, Template\n from django.test import TestCase\n@@ -373,3 +373,36 @@ class ModelChoiceFieldTests(TestCase):\n         )\n         with self.assertNumQueries(2):\n             template.render(Context({'form': CategoriesForm()}))\n+\n+    def test_modelchoiceiteratorvalue_hashable(self):\n+        \"\"\"\n+        Test that ModelChoiceIteratorValue is hashable and can be used as\n+        dictionary keys. Regression test for the issue where\n+        ModelChoiceIteratorValue was not hashable in Django 3.1+.\n+        \"\"\"\n+        # Test basic hashability\n+        value = ModelChoiceIteratorValue(self.c1.pk, self.c1)\n+        hash_value = hash(value)\n+        self.assertIsInstance(hash_value, int)\n+        \n+        # Test dictionary key usage\n+        d = {value: \"test_data\"}\n+        self.assertEqual(d[value], \"test_data\")\n+        \n+        # Test set membership\n+        s = {value}\n+        self.assertIn(value, s)\n+        \n+        # Test the specific scenario from the GitHub issue\n+        show_fields = {self.c1.pk: ['first_name', 'last_name'], self.c2.pk: ['name']}\n+        self.assertTrue(value in show_fields)\n+        self.assertEqual(show_fields[value], ['first_name', 'last_name'])\n+        \n+        # Test hash consistency with equality\n+        value2 = ModelChoiceIteratorValue(self.c1.pk, self.c1)\n+        self.assertEqual(value, value2)\n+        self.assertEqual(hash(value), hash(value2))\n+        \n+        # Test equality with raw values\n+        self.assertEqual(value, self.c1.pk)\n+        self.assertEqual(hash(value), hash(self.c1.pk))\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "scikit-learn__scikit-learn-14983", "model_patch": "diff --git a/sklearn/model_selection/_split.py b/sklearn/model_selection/_split.py\nindex c49a3ce6a..63ef0a301 100644\n--- a/sklearn/model_selection/_split.py\n+++ b/sklearn/model_selection/_split.py\n@@ -1163,6 +1163,29 @@ class _RepeatedSplits(metaclass=ABCMeta):\n                      **self.cvargs)\n         return cv.get_n_splits(X, y, groups) * self.n_repeats\n \n+    def __repr__(self):\n+        # Use the same approach as _build_repr but handle the special case\n+        # where n_splits is stored in cvargs instead of as a direct attribute\n+        class_name = self.__class__.__name__\n+        \n+        # Get the constructor signature to determine parameter order\n+        init_signature = signature(self.__class__.__init__)\n+        # Consider the constructor parameters excluding 'self', sorted alphabetically\n+        # to match the behavior of _build_repr\n+        args = sorted([p.name for p in init_signature.parameters.values()\n+                       if p.name != 'self' and p.kind != p.VAR_KEYWORD])\n+        \n+        params = dict()\n+        for key in args:\n+            if key == 'n_splits':\n+                # n_splits is stored in cvargs, not as a direct attribute\n+                params[key] = self.cvargs.get('n_splits', 5)\n+            else:\n+                # For other parameters, get them as direct attributes\n+                params[key] = getattr(self, key, None)\n+        \n+        return '%s(%s)' % (class_name, _pprint(params, offset=len(class_name)))\n+\n \n class RepeatedKFold(_RepeatedSplits):\n     \"\"\"Repeated K-Fold cross validator.\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "astropy__astropy-12907", "model_patch": "diff --git a/astropy/modeling/separable.py b/astropy/modeling/separable.py\nindex a308e27297..45bea36085 100644\n--- a/astropy/modeling/separable.py\n+++ b/astropy/modeling/separable.py\n@@ -242,7 +242,7 @@ def _cstack(left, right):\n         cright = _coord_matrix(right, 'right', noutp)\n     else:\n         cright = np.zeros((noutp, right.shape[1]))\n-        cright[-right.shape[0]:, -right.shape[1]:] = 1\n+        cright[-right.shape[0]:, -right.shape[1]:] = right\n \n     return np.hstack([cleft, cright])\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "sympy__sympy-23262", "model_patch": "diff --git a/sympy/utilities/lambdify.py b/sympy/utilities/lambdify.py\nindex da67263b19..fc4fb9572f 100644\n--- a/sympy/utilities/lambdify.py\n+++ b/sympy/utilities/lambdify.py\n@@ -961,7 +961,14 @@ def _recursive_to_string(doprint, arg):\n             left, right = \"()\"\n         else:\n             raise NotImplementedError(\"unhandled type: %s, %s\" % (type(arg), arg))\n-        return left +', '.join(_recursive_to_string(doprint, e) for e in arg) + right\n+        \n+        elements = ', '.join(_recursive_to_string(doprint, e) for e in arg)\n+        \n+        # Handle single-element tuples by adding trailing comma\n+        if isinstance(arg, tuple) and len(arg) == 1:\n+            elements += ','\n+            \n+        return left + elements + right\n     elif isinstance(arg, str):\n         return arg\n     else:\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "sympy__sympy-24066", "model_patch": "diff --git a/sympy/physics/units/unitsystem.py b/sympy/physics/units/unitsystem.py\nindex 3daf84c108..ce0609af12 100644\n--- a/sympy/physics/units/unitsystem.py\n+++ b/sympy/physics/units/unitsystem.py\n@@ -192,8 +192,37 @@ def _collect_factor_and_dimension(self, expr):\n         elif isinstance(expr, Function):\n             fds = [self._collect_factor_and_dimension(\n                 arg) for arg in expr.args]\n-            return (expr.func(*(f[0] for f in fds)),\n-                    *(d[1] for d in fds))\n+            \n+            # Check if all arguments are dimensionless\n+            all_dimensionless = all(\n+                self.get_dimension_system().is_dimensionless(d[1]) \n+                for d in fds\n+            )\n+            \n+            factor_part = expr.func(*(f[0] for f in fds))\n+            \n+            if all_dimensionless:\n+                # For transcendental functions, if all arguments are dimensionless,\n+                # the result should be dimensionless (Dimension(1))\n+                from sympy.functions.elementary.exponential import exp, log\n+                from sympy.functions.elementary.trigonometric import sin, cos, tan, cot, sec, csc\n+                from sympy.functions.elementary.trigonometric import asin, acos, atan, acot, asec, acsc\n+                from sympy.functions.elementary.hyperbolic import sinh, cosh, tanh, coth, sech, csch\n+                from sympy.functions.elementary.hyperbolic import asinh, acosh, atanh, acoth, asech, acsch\n+                \n+                transcendental_functions = (exp, log, sin, cos, tan, cot, sec, csc,\n+                                          asin, acos, atan, acot, asec, acsc,\n+                                          sinh, cosh, tanh, coth, sech, csch,\n+                                          asinh, acosh, atanh, acoth, asech, acsch)\n+                \n+                if isinstance(expr, transcendental_functions):\n+                    return factor_part, Dimension(1)\n+                else:\n+                    # For other functions (like sqrt, Abs), preserve original logic\n+                    return (factor_part, *(d[1] for d in fds))\n+            else:\n+                # For non-dimensionless arguments, use the original logic\n+                return (factor_part, *(d[1] for d in fds))\n         elif isinstance(expr, Dimension):\n             return S.One, expr\n         else:\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "matplotlib__matplotlib-24970", "model_patch": "diff --git a/lib/matplotlib/colors.py b/lib/matplotlib/colors.py\nindex 2d3072da04..57c3f81ddc 100644\n--- a/lib/matplotlib/colors.py\n+++ b/lib/matplotlib/colors.py\n@@ -727,6 +727,13 @@ class Colormap:\n                 xa = xa.astype(int)\n         # Set the over-range indices before the under-range;\n         # otherwise the under-range values get converted to over-range.\n+        # Convert small integer arrays to avoid NumPy 1.24+ deprecation warnings\n+        # when assigning out-of-bounds special indices to uint8/int8/uint16/int16 arrays\n+        if xa.dtype.kind in ('u', 'i') and xa.dtype.itemsize < 4:\n+            xa = xa.astype(np.int32, copy=False)\n+        elif xa.dtype == np.uint64:\n+            # Special case for uint64 to avoid casting issues\n+            xa = xa.astype(np.int64, copy=False)\n         xa[xa > self.N - 1] = self._i_over\n         xa[xa < 0] = self._i_under\n         xa[mask_bad] = self._i_bad\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "matplotlib__matplotlib-24149", "model_patch": "diff --git a/lib/matplotlib/cbook/__init__.py b/lib/matplotlib/cbook/__init__.py\nindex 34c6ddb861..5ff849bce5 100644\n--- a/lib/matplotlib/cbook/__init__.py\n+++ b/lib/matplotlib/cbook/__init__.py\n@@ -1746,7 +1746,12 @@ def _safe_first_finite(obj, *, skip_nonfinite=True):\n         raise RuntimeError(\"matplotlib does not \"\n                            \"support generators as input\")\n     else:\n-        return next(val for val in obj if safe_isfinite(val))\n+        try:\n+            return next(val for val in obj if safe_isfinite(val))\n+        except StopIteration:\n+            # If no finite values are found, return the first element regardless\n+            # This maintains backwards compatibility for cases with all non-finite data\n+            return next(iter(obj))\n \n \n def sanitize_sequence(data):\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "django__django-16139", "model_patch": "diff --git a/django/contrib/auth/forms.py b/django/contrib/auth/forms.py\nindex b3cfc6723c..28462a9bc6 100644\n--- a/django/contrib/auth/forms.py\n+++ b/django/contrib/auth/forms.py\n@@ -163,7 +163,10 @@ class UserChangeForm(forms.ModelForm):\n         super().__init__(*args, **kwargs)\n         password = self.fields.get(\"password\")\n         if password:\n-            password.help_text = password.help_text.format(\"../password/\")\n+            if self.instance and self.instance.pk:\n+                password.help_text = password.help_text.format(f\"../../{self.instance.pk}/password/\")\n+            else:\n+                password.help_text = password.help_text.format(\"../password/\")\n         user_permissions = self.fields.get(\"user_permissions\")\n         if user_permissions:\n             user_permissions.queryset = user_permissions.queryset.select_related(\ndiff --git a/tests/auth_tests/test_forms.py b/tests/auth_tests/test_forms.py\nindex 3bacd7a9fb..cc0a7003f9 100644\n--- a/tests/auth_tests/test_forms.py\n+++ b/tests/auth_tests/test_forms.py\n@@ -822,6 +822,48 @@ class UserChangeFormTest(TestDataMixin, TestCase):\n             if v.code == \"invalid\"\n         )\n         self.assertEqual(form[\"username\"].errors, [str(validator.message)])\n+    def test_password_link_with_instance_pk(self):\n+        \"\"\"Test that password link uses instance PK when available.\"\"\"\n+        user = User.objects.create_user(username=\"testuser\", email=\"test@example.com\")\n+        \n+        form = UserChangeForm(instance=user)\n+        password_field = form.fields.get('password')\n+        \n+        self.assertIsNotNone(password_field)\n+        help_text = password_field.help_text\n+        \n+        # Should contain the instance PK in the link\n+        expected_link = f\"../../{user.pk}/password/\"\n+        self.assertIn(expected_link, help_text)\n+        \n+        # Should NOT contain the old hardcoded link when instance has PK\n+        self.assertNotIn(\"../password/\", help_text)\n+    \n+    def test_password_link_without_instance(self):\n+        \"\"\"Test that password link falls back to relative path when no instance.\"\"\"\n+        form = UserChangeForm()\n+        password_field = form.fields.get('password')\n+        \n+        self.assertIsNotNone(password_field)\n+        help_text = password_field.help_text\n+        \n+        # Should contain the fallback relative link\n+        self.assertIn(\"../password/\", help_text)\n+    \n+    def test_password_link_with_unsaved_instance(self):\n+        \"\"\"Test that password link falls back when instance has no PK.\"\"\"\n+        user = User(username=\"testuser\", email=\"test@example.com\")\n+        # user.pk is None since it's not saved\n+        \n+        form = UserChangeForm(instance=user)\n+        password_field = form.fields.get('password')\n+        \n+        self.assertIsNotNone(password_field)\n+        help_text = password_field.help_text\n+        \n+        # Should contain the fallback relative link\n+        self.assertIn(\"../password/\", help_text)\n+\n \n     def test_bug_14242(self):\n         # A regression test, introduce by adding an optimization for the\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "pytest-dev__pytest-7490", "model_patch": "diff --git a/src/_pytest/skipping.py b/src/_pytest/skipping.py\nindex 335e10996..6535f00d5 100644\n--- a/src/_pytest/skipping.py\n+++ b/src/_pytest/skipping.py\n@@ -262,6 +262,15 @@ def pytest_runtest_makereport(item: Item, call: CallInfo[None]):\n     outcome = yield\n     rep = outcome.get_result()\n     xfailed = item._store.get(xfailed_key, None)\n+    # If no xfailed marker was found in store (i.e., not set during setup),\n+    # check if there are any dynamically added xfail markers.\n+    # We only do this during the \"call\" phase to avoid re-evaluating\n+    # static markers that may have failed during setup.\n+    if xfailed is None and not item.config.option.runxfail and call.when == \"call\":\n+        # Only evaluate if there are actually xfail markers to avoid\n+        # unnecessary evaluation and potential errors\n+        if any(item.iter_markers(name=\"xfail\")):\n+            xfailed = evaluate_xfail_marks(item)\n     # unittest special case, see setting of unexpectedsuccess_key\n     if unexpectedsuccess_key in item._store and rep.when == \"call\":\n         reason = item._store[unexpectedsuccess_key]\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "sympy__sympy-12419", "model_patch": "diff --git a/sympy/concrete/summations.py b/sympy/concrete/summations.py\nindex 372487664c..c981b2f665 100644\n--- a/sympy/concrete/summations.py\n+++ b/sympy/concrete/summations.py\n@@ -876,6 +876,23 @@ def eval_sum(f, limits):\n     if definite and (dif < 100):\n         return eval_sum_direct(f, (i, a, b))\n     if isinstance(f, Piecewise):\n+        # Handle special case: Sum(Piecewise((expr, condition), (0, True)), (var, start, end))\n+        # where condition is always true in the summation range\n+        if (len(f.args) == 2 and f.args[1].expr == 0 and f.args[1].cond == True):\n+            expr, cond = f.args[0]\n+            \n+            # Check if condition is of the form (start <= var <= end) and matches summation range\n+            from sympy import And, Le, Ge\n+            if isinstance(cond, And) and len(cond.args) == 2:\n+                # Check if condition matches the summation bounds\n+                cond_simplified = cond.subs(i, a)  # Check at lower bound\n+                cond_simplified2 = cond.subs(i, b)  # Check at upper bound\n+                \n+                # If condition is true at both bounds and involves the summation variable,\n+                # it's likely true throughout the range\n+                if cond_simplified == True and cond_simplified2 == True:\n+                    return eval_sum(expr, limits)\n+        \n         return None\n     # Try to do it symbolically. Even when the number of terms is known,\n     # this can save time when b-a is big.\ndiff --git a/sympy/matrices/expressions/matexpr.py b/sympy/matrices/expressions/matexpr.py\nindex b4d759836e..df7d6b0c83 100644\n--- a/sympy/matrices/expressions/matexpr.py\n+++ b/sympy/matrices/expressions/matexpr.py\n@@ -476,10 +476,16 @@ def conjugate(self):\n         return self\n \n     def _entry(self, i, j):\n-        if i == j:\n+        from sympy import Eq\n+        eq = Eq(i, j)\n+        if eq is S.true:\n             return S.One\n-        else:\n+        elif eq is S.false:\n             return S.Zero\n+        else:\n+            # For symbolic indices, return a KroneckerDelta\n+            from sympy.functions import KroneckerDelta\n+            return KroneckerDelta(i, j)\n \n     def _eval_determinant(self):\n         return S.One\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "astropy__astropy-14365", "model_patch": "diff --git a/astropy/io/ascii/qdp.py b/astropy/io/ascii/qdp.py\nindex 83a4f004aa..83ea51f66a 100644\n--- a/astropy/io/ascii/qdp.py\n+++ b/astropy/io/ascii/qdp.py\n@@ -34,6 +34,8 @@ def _line_type(line, delimiter=None):\n     --------\n     >>> _line_type(\"READ SERR 3\")\n     'command'\n+    >>> _line_type(\"read serr 3\")\n+    'command'\n     >>> _line_type(\" \\\\n    !some gibberish\")\n     'comment'\n     >>> _line_type(\"   \")\n@@ -68,7 +70,7 @@ def _line_type(line, delimiter=None):\n     _new_re = rf\"NO({sep}NO)+\"\n     _data_re = rf\"({_decimal_re}|NO|[-+]?nan)({sep}({_decimal_re}|NO|[-+]?nan))*)\"\n     _type_re = rf\"^\\s*((?P<command>{_command_re})|(?P<new>{_new_re})|(?P<data>{_data_re})?\\s*(\\!(?P<comment>.*))?\\s*$\"\n-    _line_type_re = re.compile(_type_re)\n+    _line_type_re = re.compile(_type_re, re.IGNORECASE)\n     line = line.strip()\n     if not line:\n         return \"comment\"\ndiff --git a/astropy/io/ascii/tests/test_qdp.py b/astropy/io/ascii/tests/test_qdp.py\nindex ef24e6f6a3..6462197fc8 100644\n--- a/astropy/io/ascii/tests/test_qdp.py\n+++ b/astropy/io/ascii/tests/test_qdp.py\n@@ -245,3 +245,43 @@ def test_get_lines_from_qdp(tmp_path):\n         assert file_output[i] == line\n         assert list_output[i] == line\n         assert text_output[i] == line\n+\n+\n+def test_case_insensitive_commands(tmp_path):\n+    \"\"\"Test that QDP commands are case-insensitive.\"\"\"\n+    \n+    # Test various case combinations for SERR and TERR commands\n+    test_cases = [\n+        (\"read serr 1 2\", \"lowercase serr\"),\n+        (\"READ SERR 1 2\", \"uppercase serr\"),\n+        (\"Read Serr 1 2\", \"title case serr\"),\n+        (\"rEaD sErR 1 2\", \"mixed case serr\"),\n+        (\"read terr 1\", \"lowercase terr\"),\n+        (\"READ TERR 1\", \"uppercase terr\"),\n+        (\"Read Terr 1\", \"title case terr\"),\n+        (\"rEaD tErR 1\", \"mixed case terr\"),\n+    ]\n+    \n+    for command, description in test_cases:\n+        # Create QDP content with the command\n+        qdp_content = f\"{command}\\n1 0.5 1 0.5\\n\"\n+        \n+        test_file = tmp_path / f\"test_{description.replace(' ', '_')}.qdp\"\n+        with open(test_file, \"w\") as f:\n+            f.write(qdp_content)\n+        \n+        # Should not raise an exception\n+        table = Table.read(test_file, format=\"ascii.qdp\", table_id=0)\n+        \n+        # Verify the table was read correctly\n+        assert len(table) == 1\n+        assert len(table.colnames) >= 2  # At least 2 columns (data + error columns)\n+        \n+        # For SERR commands, we expect error columns\n+        if \"serr\" in command.lower():\n+            assert any(\"_err\" in col for col in table.colnames)\n+        \n+        # For TERR commands, we expect positive and negative error columns  \n+        if \"terr\" in command.lower():\n+            assert any(\"_perr\" in col for col in table.colnames)\n+            assert any(\"_nerr\" in col for col in table.colnames)\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "django__django-15252", "model_patch": "diff --git a/django/db/migrations/recorder.py b/django/db/migrations/recorder.py\nindex 1a37c6b7d0..3c4c771cbf 100644\n--- a/django/db/migrations/recorder.py\n+++ b/django/db/migrations/recorder.py\n@@ -62,6 +62,10 @@ class MigrationRecorder:\n         # in the codebase.\n         if self.has_table():\n             return\n+        # Check if migrations are allowed on this database\n+        from django.db import router\n+        if not router.allow_migrate_model(self.connection.alias, self.Migration):\n+            return\n         # Make the table\n         try:\n             with self.connection.schema_editor() as editor:\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "sympy__sympy-20154", "model_patch": "diff --git a/sympy/utilities/iterables.py b/sympy/utilities/iterables.py\nindex dd36dea304..d21aaa5107 100644\n--- a/sympy/utilities/iterables.py\n+++ b/sympy/utilities/iterables.py\n@@ -1738,19 +1738,11 @@ def partitions(n, m=None, k=None, size=False):\n     {2: 1, 4: 1}\n     {3: 2}\n \n-    Note that the _same_ dictionary object is returned each time.\n-    This is for speed:  generating each partition goes quickly,\n-    taking constant time, independent of n.\n+    Each partition is returned as a separate dictionary object.\n \n-    >>> [p for p in partitions(6, k=2)]\n-    [{1: 6}, {1: 6}, {1: 6}, {1: 6}]\n-\n-    If you want to build a list of the returned dictionaries then\n-    make a copy of them:\n-\n-    >>> [p.copy() for p in partitions(6, k=2)]  # doctest: +SKIP\n+    >>> [p for p in partitions(6, k=2)]  # doctest: +SKIP\n     [{2: 3}, {1: 2, 2: 2}, {1: 4, 2: 1}, {1: 6}]\n-    >>> [(M, p.copy()) for M, p in partitions(6, k=2, size=True)]  # doctest: +SKIP\n+    >>> [(M, p) for M, p in partitions(6, k=2, size=True)]  # doctest: +SKIP\n     [(3, {2: 3}), (4, {1: 2, 2: 2}), (5, {1: 4, 2: 1}), (6, {1: 6})]\n \n     References\n@@ -1802,9 +1794,9 @@ def partitions(n, m=None, k=None, size=False):\n         keys.append(r)\n     room = m - q - bool(r)\n     if size:\n-        yield sum(ms.values()), ms\n+        yield sum(ms.values()), ms.copy()\n     else:\n-        yield ms\n+        yield ms.copy()\n \n     while keys != [1]:\n         # Reuse any 1's.\n@@ -1842,9 +1834,9 @@ def partitions(n, m=None, k=None, size=False):\n             break\n         room -= need\n         if size:\n-            yield sum(ms.values()), ms\n+            yield sum(ms.values()), ms.copy()\n         else:\n-            yield ms\n+            yield ms.copy()\n \n \n def ordered_partitions(n, m=None, sort=True):\ndiff --git a/sympy/utilities/tests/test_iterables.py b/sympy/utilities/tests/test_iterables.py\nindex f3ebd270dc..2873eee59a 100644\n--- a/sympy/utilities/tests/test_iterables.py\n+++ b/sympy/utilities/tests/test_iterables.py\n@@ -481,25 +481,36 @@ def test_partitions():\n         assert list(partitions(6, None, 2, size=i)) != ans[i]\n         assert list(partitions(6, 2, 0, size=i)) == ans[i]\n \n-    assert [p.copy() for p in partitions(6, k=2)] == [\n+    assert [p for p in partitions(6, k=2)] == [\n         {2: 3}, {1: 2, 2: 2}, {1: 4, 2: 1}, {1: 6}]\n \n-    assert [p.copy() for p in partitions(6, k=3)] == [\n+    assert [p for p in partitions(6, k=3)] == [\n         {3: 2}, {1: 1, 2: 1, 3: 1}, {1: 3, 3: 1}, {2: 3}, {1: 2, 2: 2},\n         {1: 4, 2: 1}, {1: 6}]\n \n-    assert [p.copy() for p in partitions(8, k=4, m=3)] == [\n+    assert [p for p in partitions(8, k=4, m=3)] == [\n         {4: 2}, {1: 1, 3: 1, 4: 1}, {2: 2, 4: 1}, {2: 1, 3: 2}] == [\n-        i.copy() for i in partitions(8, k=4, m=3) if all(k <= 4 for k in i)\n+        i for i in partitions(8, k=4, m=3) if all(k <= 4 for k in i)\n         and sum(i.values()) <=3]\n \n-    assert [p.copy() for p in partitions(S(3), m=2)] == [\n+    assert [p for p in partitions(S(3), m=2)] == [\n         {3: 1}, {1: 1, 2: 1}]\n \n-    assert [i.copy() for i in partitions(4, k=3)] == [\n+    assert [i for i in partitions(4, k=3)] == [\n         {1: 1, 3: 1}, {2: 2}, {1: 2, 2: 1}, {1: 4}] == [\n-        i.copy() for i in partitions(4) if all(k <= 3 for k in i)]\n-\n+        i for i in partitions(4) if all(k <= 3 for k in i)]\n+\n+    # Test that partitions returns independent dictionary objects\n+    result = list(partitions(4))\n+    # All objects should have different identities\n+    ids = [id(p) for p in result]\n+    assert len(set(ids)) == len(ids), \"partitions should return independent objects\"\n+    # Modifying one should not affect others\n+    if result:\n+        original_first = result[0].copy()\n+        result[0][999] = 123\n+        assert result[1] != result[0], \"partitions should be independent\"\n+        assert 999 not in result[1], \"modifying one partition should not affect others\"\n \n     # Consistency check on output of _partitions and RGS_unrank.\n     # This provides a sanity test on both routines.  Also verifies that\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "matplotlib__matplotlib-25311", "model_patch": "diff --git a/lib/matplotlib/offsetbox.py b/lib/matplotlib/offsetbox.py\nindex 1dee8a23d9..26cdc90917 100644\n--- a/lib/matplotlib/offsetbox.py\n+++ b/lib/matplotlib/offsetbox.py\n@@ -1516,6 +1516,7 @@ class DraggableBase:\n \n     def on_motion(self, evt):\n         if self._check_still_parented() and self.got_artist:\n+            self._ensure_canvas_connection()\n             dx = evt.x - self.mouse_x\n             dy = evt.y - self.mouse_y\n             self.update_offset(dx, dy)\n@@ -1529,6 +1530,7 @@ class DraggableBase:\n \n     def on_pick(self, evt):\n         if self._check_still_parented() and evt.artist == self.ref_artist:\n+            self._ensure_canvas_connection()\n             self.mouse_x = evt.mouseevent.x\n             self.mouse_y = evt.mouseevent.y\n             self.got_artist = True\n@@ -1546,9 +1548,11 @@ class DraggableBase:\n \n     def on_release(self, event):\n         if self._check_still_parented() and self.got_artist:\n+            self._ensure_canvas_connection()\n             self.finalize_offset()\n             self.got_artist = False\n-            self.canvas.mpl_disconnect(self._c1)\n+            if hasattr(self, '_c1'):\n+                self.canvas.mpl_disconnect(self._c1)\n \n             if self._use_blit:\n                 self.ref_artist.set_animated(False)\n@@ -1562,14 +1566,16 @@ class DraggableBase:\n \n     def disconnect(self):\n         \"\"\"Disconnect the callbacks.\"\"\"\n-        for cid in self.cids:\n-            self.canvas.mpl_disconnect(cid)\n-        try:\n-            c1 = self._c1\n-        except AttributeError:\n-            pass\n-        else:\n-            self.canvas.mpl_disconnect(c1)\n+        self._ensure_canvas_connection()\n+        if self.canvas is not None:\n+            for cid in self.cids:\n+                self.canvas.mpl_disconnect(cid)\n+            try:\n+                c1 = self._c1\n+            except AttributeError:\n+                pass\n+            else:\n+                self.canvas.mpl_disconnect(c1)\n \n     def save_offset(self):\n         pass\n@@ -1580,6 +1586,63 @@ class DraggableBase:\n     def finalize_offset(self):\n         pass\n \n+    def __getstate__(self):\n+        \"\"\"\n+        Return the state for pickling.\n+        \n+        We exclude the canvas reference since it may not be picklable\n+        (e.g., Qt canvases). The canvas will be restored from the \n+        ref_artist.figure.canvas when unpickling.\n+        \"\"\"\n+        state = self.__dict__.copy()\n+        # Remove the unpicklable canvas reference\n+        state.pop('canvas', None)\n+        # Also remove any active motion callback connection\n+        state.pop('_c1', None)\n+        # Reset dragging state\n+        state['got_artist'] = False\n+        return state\n+\n+    def __setstate__(self, state):\n+        \"\"\"\n+        Restore the state from pickling.\n+        \n+        Reconnect to the canvas and restore callbacks.\n+        \"\"\"\n+        self.__dict__.update(state)\n+        # Initialize with safe defaults\n+        self.canvas = None\n+        self._use_blit = False\n+        self.cids = []\n+        \n+        # We'll restore the canvas connection lazily when needed\n+        # This avoids issues with the figure not being fully restored yet\n+\n+    def _ensure_canvas_connection(self):\n+        \"\"\"\n+        Ensure that the canvas connection is established.\n+        \n+        This is called lazily to handle cases where the figure\n+        might not be fully restored during unpickling.\n+        \"\"\"\n+        if (self.canvas is None and \n+            hasattr(self, 'ref_artist') and \n+            self.ref_artist is not None and\n+            hasattr(self.ref_artist, 'figure') and\n+            self.ref_artist.figure is not None and\n+            hasattr(self.ref_artist.figure, 'canvas') and\n+            self.ref_artist.figure.canvas is not None):\n+            \n+            self.canvas = self.ref_artist.figure.canvas\n+            self._use_blit = getattr(self, '_use_blit', False) and self.canvas.supports_blit\n+            # Reconnect the callbacks\n+            self.cids = [\n+                self.canvas.callbacks._connect_picklable(\n+                    'pick_event', self.on_pick),\n+                self.canvas.callbacks._connect_picklable(\n+                    'button_release_event', self.on_release),\n+            ]\n+\n \n class DraggableOffsetBox(DraggableBase):\n     def __init__(self, ref_artist, offsetbox, use_blit=False):\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "matplotlib__matplotlib-25332", "model_patch": "diff --git a/lib/matplotlib/cbook.py b/lib/matplotlib/cbook.py\nindex c9699b2e21..8ff1ced160 100644\n--- a/lib/matplotlib/cbook.py\n+++ b/lib/matplotlib/cbook.py\n@@ -846,6 +846,81 @@ class Grouper:\n         siblings = self._mapping.get(weakref.ref(a), [weakref.ref(a)])\n         return [x() for x in siblings]\n \n+    def __getstate__(self):\n+        \"\"\"\n+        Convert weak references to strong references for pickling.\n+        \n+        This method is called during pickling to prepare the object state.\n+        Since weak references cannot be pickled, we convert them to strong\n+        references while preserving the grouping relationships.\n+        \"\"\"\n+        self.clean()  # Remove any dead weak references first\n+        \n+        # Convert the mapping from weak refs to strong refs\n+        strong_mapping = {}\n+        for weak_key, weak_list in self._mapping.items():\n+            strong_key = weak_key()\n+            if strong_key is not None:  # Only include live references\n+                strong_list = []\n+                for weak_ref in weak_list:\n+                    strong_obj = weak_ref()\n+                    if strong_obj is not None:\n+                        strong_list.append(strong_obj)\n+                if strong_list:  # Only include non-empty groups\n+                    strong_mapping[strong_key] = strong_list\n+        \n+        return {'strong_mapping': strong_mapping}\n+\n+    def __setstate__(self, state):\n+        \"\"\"\n+        Convert strong references back to weak references after unpickling.\n+        \n+        This method is called during unpickling to restore the object state.\n+        We rebuild the weak reference mapping from the strong references\n+        that were saved during pickling.\n+        \"\"\"\n+        strong_mapping = state['strong_mapping']\n+        self._mapping = {}\n+        \n+        # Rebuild the weak reference mapping\n+        for strong_key, strong_list in strong_mapping.items():\n+            weak_key = weakref.ref(strong_key)\n+            weak_list = [weakref.ref(obj) for obj in strong_list]\n+            self._mapping[weak_key] = weak_list\n+            \n+            # Ensure all objects in the same group point to the same list\n+            for weak_ref in weak_list:\n+                self._mapping[weak_ref] = weak_list\n+\n+    def __getstate__(self):\n+        \"\"\"Convert weak references to strong references for pickling.\"\"\"\n+        # Convert the _mapping from weak refs to strong refs\n+        strong_mapping = {}\n+        for weak_key, weak_value_list in self._mapping.items():\n+            strong_key = weak_key()  # Get the actual object\n+            if strong_key is not None:  # Only if the object still exists\n+                strong_value_list = []\n+                for weak_value in weak_value_list:\n+                    strong_value = weak_value()\n+                    if strong_value is not None:\n+                        strong_value_list.append(strong_value)\n+                if strong_value_list:  # Only if we have valid objects\n+                    strong_mapping[strong_key] = strong_value_list\n+        return {'_mapping': strong_mapping}\n+\n+    def __setstate__(self, state):\n+        \"\"\"Convert strong references back to weak references after unpickling.\"\"\"\n+        strong_mapping = state['_mapping']\n+        weak_mapping = {}\n+        for strong_key, strong_value_list in strong_mapping.items():\n+            weak_key = weakref.ref(strong_key)\n+            weak_value_list = [weakref.ref(obj) for obj in strong_value_list]\n+            weak_mapping[weak_key] = weak_value_list\n+            # Make sure all items in the list point to the same list object\n+            for weak_value in weak_value_list:\n+                weak_mapping[weak_value] = weak_value_list\n+        self._mapping = weak_mapping\n+\n \n class GrouperView:\n     \"\"\"Immutable view over a `.Grouper`.\"\"\"\ndiff --git a/lib/matplotlib/tests/test_figure.py b/lib/matplotlib/tests/test_figure.py\nindex 80d80f9691..109b860983 100644\n--- a/lib/matplotlib/tests/test_figure.py\n+++ b/lib/matplotlib/tests/test_figure.py\n@@ -83,6 +83,51 @@ def test_align_labels_stray_axes():\n     np.testing.assert_allclose(xn[:2], xn[2:])\n     np.testing.assert_allclose(yn[::2], yn[1::2])\n \n+\n+def test_pickle_figure_after_align_labels():\n+    \"\"\"\n+    Test that figures can be pickled after calling align_labels().\n+    \n+    This is a regression test for the issue where figures became\n+    unpicklable after calling align_labels() due to weak references\n+    in the Grouper objects.\n+    \"\"\"\n+    import pickle\n+    \n+    # Create figure with subplots as in the original bug report\n+    fig = plt.figure()\n+    ax1 = fig.add_subplot(211)\n+    ax2 = fig.add_subplot(212)\n+    \n+    time = [0, 1, 2, 3, 4]\n+    speed = [40000, 4300, 4500, 4700, 4800]\n+    acc = [10, 11, 12, 13, 14]\n+    \n+    ax1.plot(time, speed)\n+    ax1.set_ylabel('speed')\n+    ax2.plot(time, acc)\n+    ax2.set_ylabel('acc')\n+\n+    # This used to break pickling\n+    fig.align_labels()\n+    \n+    # Test that the figure can be pickled\n+    pickled_data = pickle.dumps(fig)\n+    \n+    # Test that it can be unpickled\n+    unpickled_fig = pickle.loads(pickled_data)\n+    \n+    # Verify the structure is preserved\n+    assert len(unpickled_fig.axes) == 2\n+    assert unpickled_fig.axes[0].get_ylabel() == 'speed'\n+    assert unpickled_fig.axes[1].get_ylabel() == 'acc'\n+    \n+    # Test that align_labels still works on unpickled figure\n+    unpickled_fig.align_labels()\n+    \n+    # Test that it can be pickled again\n+    pickle.dumps(unpickled_fig)\n+\n     fig, axs = plt.subplots(2, 2, constrained_layout=True)\n     for nn, ax in enumerate(axs.flat):\n         ax.set_xlabel('Boo')\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "django__django-14580", "model_patch": "diff --git a/django/db/migrations/serializer.py b/django/db/migrations/serializer.py\nindex e19c881cda..072a2efc14 100644\n--- a/django/db/migrations/serializer.py\n+++ b/django/db/migrations/serializer.py\n@@ -273,7 +273,7 @@ class TupleSerializer(BaseSequenceSerializer):\n class TypeSerializer(BaseSerializer):\n     def serialize(self):\n         special_cases = [\n-            (models.Model, \"models.Model\", []),\n+            (models.Model, \"models.Model\", [\"from django.db import models\"]),\n             (type(None), 'type(None)', []),\n         ]\n         for case, string, imports in special_cases:\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "django__django-12125", "model_patch": "diff --git a/django/db/migrations/serializer.py b/django/db/migrations/serializer.py\nindex 7d226955d5..00e7bea1b7 100644\n--- a/django/db/migrations/serializer.py\n+++ b/django/db/migrations/serializer.py\n@@ -267,9 +267,9 @@ class TypeSerializer(BaseSerializer):\n         if hasattr(self.value, \"__module__\"):\n             module = self.value.__module__\n             if module == builtins.__name__:\n-                return self.value.__name__, set()\n+                return self.value.__qualname__, set()\n             else:\n-                return \"%s.%s\" % (module, self.value.__name__), {\"import %s\" % module}\n+                return \"%s.%s\" % (module, self.value.__qualname__), {\"import %s\" % module}\n \n \n class UUIDSerializer(BaseSerializer):\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "django__django-13033", "model_patch": "diff --git a/django/db/models/sql/compiler.py b/django/db/models/sql/compiler.py\nindex abbb1e37cb..f59babce50 100644\n--- a/django/db/models/sql/compiler.py\n+++ b/django/db/models/sql/compiler.py\n@@ -727,7 +727,8 @@ class SQLCompiler:\n         # If we get to this point and the field is a relation to another model,\n         # append the default ordering for that model unless it is the pk\n         # shortcut or the attribute name of the field that is specified.\n-        if field.is_relation and opts.ordering and getattr(field, 'attname', None) != name and name != 'pk':\n+        # Also skip if the name ends with '_id' which indicates a direct foreign key field reference.\n+        if field.is_relation and opts.ordering and getattr(field, 'attname', None) != name and name != 'pk' and not name.endswith('_id'):\n             # Firstly, avoid infinite loops.\n             already_seen = already_seen or set()\n             join_tuple = tuple(getattr(self.query.alias_map[j], 'join_cols', None) for j in joins)\ndiff --git a/tests/ordering/models.py b/tests/ordering/models.py\nindex 2efb743e44..5608462ab7 100644\n--- a/tests/ordering/models.py\n+++ b/tests/ordering/models.py\n@@ -59,3 +59,18 @@ class Reference(models.Model):\n \n     class Meta:\n         ordering = ('article',)\n+\n+\n+class SelfRefModel(models.Model):\n+    \"\"\"Model with self-referencing foreign key and default ordering.\"\"\"\n+    parent = models.ForeignKey(\"self\", on_delete=models.CASCADE, null=True)\n+    value = models.IntegerField(null=True)\n+\n+    class Meta:\n+        ordering = (\"-id\",)\n+\n+\n+class RelatedToSelfRefModel(models.Model):\n+    \"\"\"Model that references SelfRefModel.\"\"\"\n+    ref = models.ForeignKey(SelfRefModel, on_delete=models.CASCADE)\n+    data = models.IntegerField(null=True)\ndiff --git a/tests/ordering/tests.py b/tests/ordering/tests.py\nindex a9cc729c45..dfd173db88 100644\n--- a/tests/ordering/tests.py\n+++ b/tests/ordering/tests.py\n@@ -8,7 +8,10 @@ from django.db.models import (\n from django.db.models.functions import Upper\n from django.test import TestCase\n \n-from .models import Article, Author, ChildArticle, OrderedByFArticle, Reference\n+from .models import (\n+    Article, Author, ChildArticle, OrderedByFArticle, Reference,\n+    RelatedToSelfRefModel, SelfRefModel,\n+)\n \n \n class OrderingTests(TestCase):\n@@ -480,3 +483,82 @@ class OrderingTests(TestCase):\n         ca4 = ChildArticle.objects.create(headline='h1', pub_date=datetime(2005, 7, 28))\n         articles = ChildArticle.objects.order_by('article_ptr')\n         self.assertSequenceEqual(articles, [ca4, ca2, ca1, ca3])\n+\n+    def test_self_referencing_fk_ordering_by_id_field(self):\n+        \"\"\"\n+        Regression test for issue where ordering by a self-referencing foreign key\n+        field with _id suffix creates unnecessary joins and applies wrong ordering.\n+        \"\"\"\n+        # Create test data\n+        root = SelfRefModel.objects.create(parent=None, value=1)\n+        child1 = SelfRefModel.objects.create(parent=root, value=2)\n+        child2 = SelfRefModel.objects.create(parent=root, value=3)\n+\n+        rel1 = RelatedToSelfRefModel.objects.create(ref=root, data=10)\n+        rel2 = RelatedToSelfRefModel.objects.create(ref=child1, data=20)\n+        rel3 = RelatedToSelfRefModel.objects.create(ref=child2, data=30)\n+\n+        # Test ordering by 'ref__parent_id' - should not create extra joins\n+        qs = RelatedToSelfRefModel.objects.filter(ref__value__in=[1, 2, 3]).order_by(\"ref__parent_id\")\n+        sql = str(qs.query)\n+        \n+        # Should not have LEFT OUTER JOIN or T3 table alias\n+        self.assertNotIn(\"LEFT OUTER JOIN\", sql)\n+        self.assertNotIn(\"T3\", sql)\n+        \n+        # Should have correct ASC ordering\n+        self.assertIn(\"ORDER BY\", sql)\n+        self.assertIn(\"ASC\", sql)\n+        self.assertNotIn(\"DESC\", sql)\n+        \n+        # Verify results are correctly ordered (None values first, then by parent_id)\n+        results = list(qs.values('id', 'ref__parent_id'))\n+        # rel1 has no parent (None), rel2 and rel3 have root as parent\n+        expected_parent_ids = [None, root.id, root.id]\n+        actual_parent_ids = [r['ref__parent_id'] for r in results]\n+        self.assertEqual(actual_parent_ids, expected_parent_ids)\n+\n+    def test_self_referencing_fk_ordering_by_id_field_desc(self):\n+        \"\"\"\n+        Test that ordering by '-ref__parent_id' works correctly.\n+        \"\"\"\n+        root = SelfRefModel.objects.create(parent=None, value=1)\n+        child1 = SelfRefModel.objects.create(parent=root, value=2)\n+        child2 = SelfRefModel.objects.create(parent=root, value=3)\n+\n+        rel1 = RelatedToSelfRefModel.objects.create(ref=root, data=10)\n+        rel2 = RelatedToSelfRefModel.objects.create(ref=child1, data=20)\n+        rel3 = RelatedToSelfRefModel.objects.create(ref=child2, data=30)\n+\n+        qs = RelatedToSelfRefModel.objects.filter(ref__value__in=[1, 2, 3]).order_by(\"-ref__parent_id\")\n+        sql = str(qs.query)\n+        \n+        # Should not have LEFT OUTER JOIN or T3 table alias\n+        self.assertNotIn(\"LEFT OUTER JOIN\", sql)\n+        self.assertNotIn(\"T3\", sql)\n+        \n+        # Should have correct DESC ordering\n+        self.assertIn(\"ORDER BY\", sql)\n+        self.assertIn(\"DESC\", sql)\n+\n+    def test_self_referencing_fk_ordering_by_relation_object(self):\n+        \"\"\"\n+        Test that ordering by 'ref__parent' (the relation object) still works\n+        and applies the default ordering from the related model.\n+        \"\"\"\n+        root = SelfRefModel.objects.create(parent=None, value=1)\n+        child1 = SelfRefModel.objects.create(parent=root, value=2)\n+        child2 = SelfRefModel.objects.create(parent=root, value=3)\n+\n+        rel1 = RelatedToSelfRefModel.objects.create(ref=root, data=10)\n+        rel2 = RelatedToSelfRefModel.objects.create(ref=child1, data=20)\n+        rel3 = RelatedToSelfRefModel.objects.create(ref=child2, data=30)\n+\n+        qs = RelatedToSelfRefModel.objects.filter(ref__value__in=[1, 2, 3]).order_by(\"ref__parent\")\n+        sql = str(qs.query)\n+        \n+        # This case should still create a join and apply default ordering\n+        # because we're ordering by the relation object, not the _id field\n+        self.assertIn(\"LEFT OUTER JOIN\", sql)\n+        self.assertIn(\"T3\", sql)\n+        self.assertIn(\"DESC\", sql)  # Default ordering from SelfRefModel\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "matplotlib__matplotlib-23314", "model_patch": "diff --git a/lib/mpl_toolkits/mplot3d/axes3d.py b/lib/mpl_toolkits/mplot3d/axes3d.py\nindex 9db44b7994..5479bc1af0 100644\n--- a/lib/mpl_toolkits/mplot3d/axes3d.py\n+++ b/lib/mpl_toolkits/mplot3d/axes3d.py\n@@ -387,6 +387,8 @@ class Axes3D(Axes):\n \n     @martist.allow_rasterization\n     def draw(self, renderer):\n+        if not self.get_visible():\n+            return\n         self._unstale_viewLim()\n \n         # draw the background patch\ndiff --git a/lib/mpl_toolkits/tests/test_mplot3d.py b/lib/mpl_toolkits/tests/test_mplot3d.py\nindex 966eb50b21..f2df90e5b6 100644\n--- a/lib/mpl_toolkits/tests/test_mplot3d.py\n+++ b/lib/mpl_toolkits/tests/test_mplot3d.py\n@@ -1,5 +1,6 @@\n import functools\n import itertools\n+from io import BytesIO\n \n import pytest\n \n@@ -1736,3 +1737,81 @@ def test_view_init_vertical_axis(\n         tickdir_expected = tickdirs_expected[i]\n         tickdir_actual = axis._get_tickdir()\n         np.testing.assert_array_equal(tickdir_expected, tickdir_actual)\n+\n+\n+def test_axes3d_set_visible():\n+    \"\"\"Test that Axes3D respects set_visible(False).\"\"\"\n+    fig = plt.figure()\n+    ax = fig.add_subplot(111, projection='3d')\n+    \n+    # Add some content to the axes\n+    ax.scatter([1], [1], [1], c='red', s=100)\n+    ax.set_xlabel('X')\n+    ax.set_ylabel('Y')\n+    ax.set_zlabel('Z')\n+    \n+    # Test that visibility flag is set correctly\n+    assert ax.get_visible() is True  # Default should be visible\n+    \n+    ax.set_visible(False)\n+    assert ax.get_visible() is False\n+    \n+    ax.set_visible(True)\n+    assert ax.get_visible() is True\n+\n+\n+def test_axes3d_draw_respects_visibility():\n+    \"\"\"Test that Axes3D.draw() respects the visibility flag.\"\"\"\n+    fig = plt.figure()\n+    ax = fig.add_subplot(111, projection='3d')\n+    \n+    # Add some content\n+    ax.scatter([1, 2, 3], [1, 2, 3], [1, 2, 3], c=['red', 'green', 'blue'])\n+    \n+    # Create a mock renderer to track draw calls\n+    from matplotlib.backends.backend_agg import RendererAgg\n+    renderer = RendererAgg(100, 100, 72)\n+    \n+    # When visible, draw should proceed normally\n+    ax.set_visible(True)\n+    try:\n+        ax.draw(renderer)\n+        # If we get here without exception, drawing worked\n+        draw_succeeded_when_visible = True\n+    except Exception:\n+        draw_succeeded_when_visible = False\n+    \n+    assert draw_succeeded_when_visible, \"Drawing should succeed when axes is visible\"\n+    \n+    # When invisible, draw should return early without doing work\n+    ax.set_visible(False)\n+    try:\n+        ax.draw(renderer)\n+        # Should return early, no exception expected\n+        draw_succeeded_when_invisible = True\n+    except Exception:\n+        draw_succeeded_when_invisible = False\n+    \n+    assert draw_succeeded_when_invisible, \"Drawing should return early when axes is invisible\"\n+\n+\n+def test_axes3d_visibility_with_subplots():\n+    \"\"\"Test visibility with multiple 3D subplots (reproduces original issue).\"\"\"\n+    fig, (ax1, ax2) = plt.subplots(1, 2, subplot_kw={'projection': '3d'})\n+    ax1.scatter(1, 1, 1)\n+    ax2.scatter(1, 1, 1, c='r')\n+    ax1.set_visible(False)\n+    \n+    # Test that visibility flags are set correctly\n+    assert ax1.get_visible() is False\n+    assert ax2.get_visible() is True\n+    \n+    # Save to buffer to ensure no exceptions during rendering\n+    buf = BytesIO()\n+    fig.savefig(buf, format='png')\n+    buf.seek(0)\n+    \n+    # Should produce a valid image with only ax2 visible\n+    assert len(buf.getvalue()) > 0, \"Should produce a valid image\"\n+    \n+    plt.close(fig)\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "astropy__astropy-14182", "model_patch": "diff --git a/astropy/io/ascii/rst.py b/astropy/io/ascii/rst.py\nindex abdeba8efb..43d9207259 100644\n--- a/astropy/io/ascii/rst.py\n+++ b/astropy/io/ascii/rst.py\n@@ -57,10 +57,27 @@ class RST(FixedWidth):\n     data_class = SimpleRSTData\n     header_class = SimpleRSTHeader\n \n-    def __init__(self):\n-        super().__init__(delimiter_pad=None, bookend=False)\n+    def __init__(self, header_rows=None):\n+        super().__init__(delimiter_pad=None, bookend=False, header_rows=header_rows)\n \n     def write(self, lines):\n         lines = super().write(lines)\n-        lines = [lines[1]] + lines + [lines[1]]\n-        return lines\n+        \n+        # Find the separator line (contains only = and spaces)\n+        separator_line = None\n+        separator_index = None\n+        for i, line in enumerate(lines):\n+            if line and set(line.strip()) <= {'=', ' '}:\n+                separator_line = line\n+                separator_index = i\n+                break\n+        \n+        if separator_line is None:\n+            # Fallback to old behavior if no separator found\n+            if len(lines) > 1:\n+                separator_line = lines[1]\n+            else:\n+                separator_line = \"\"\n+        \n+        # RST format: separator + header_rows + separator + data + separator\n+        return [separator_line] + lines + [separator_line]\ndiff --git a/astropy/io/ascii/tests/test_rst.py b/astropy/io/ascii/tests/test_rst.py\nindex 84d6fed401..57bc36e133 100644\n--- a/astropy/io/ascii/tests/test_rst.py\n+++ b/astropy/io/ascii/tests/test_rst.py\n@@ -185,3 +185,43 @@ Col1      Col2 Col3 Col4\n ==== ========= ==== ====\n \"\"\",\n     )\n+\n+\n+def test_write_header_rows():\n+    \"\"\"Test RST writer with header_rows parameter\"\"\"\n+    from astropy.table import QTable\n+    import astropy.units as u\n+    \n+    # Create a test table with units\n+    tbl = QTable({'wave': [350, 950]*u.nm, 'response': [0.7, 1.2]*u.count})\n+    \n+    # Test default behavior\n+    out = StringIO()\n+    ascii.write(tbl, out, format=\"rst\")\n+    assert_equal_splitlines(\n+        out.getvalue(),\n+        \"\"\"\\\n+===== ========\n+ wave response\n+===== ========\n+350.0      0.7\n+950.0      1.2\n+===== ========\n+\"\"\",\n+    )\n+    \n+    # Test with header_rows=[\"name\", \"unit\"]\n+    out = StringIO()\n+    ascii.write(tbl, out, format=\"rst\", header_rows=[\"name\", \"unit\"])\n+    assert_equal_splitlines(\n+        out.getvalue(),\n+        \"\"\"\\\n+===== ========\n+ wave response\n+   nm       ct\n+===== ========\n+350.0      0.7\n+950.0      1.2\n+===== ========\n+\"\"\",\n+    )\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "django__django-13933", "model_patch": "diff --git a/django/forms/models.py b/django/forms/models.py\nindex 422bc5d178..e03a3803cd 100644\n--- a/django/forms/models.py\n+++ b/django/forms/models.py\n@@ -1188,7 +1188,7 @@ class ModelChoiceField(ChoiceField):\n     # This class is a subclass of ChoiceField for purity, but it doesn't\n     # actually use any of ChoiceField's implementation.\n     default_error_messages = {\n-        'invalid_choice': _('Select a valid choice. That choice is not one of'\n+        'invalid_choice': _('Select a valid choice. %(value)s is not one of'\n                             ' the available choices.'),\n     }\n     iterator = ModelChoiceIterator\n@@ -1284,7 +1284,11 @@ class ModelChoiceField(ChoiceField):\n                 value = getattr(value, key)\n             value = self.queryset.get(**{key: value})\n         except (ValueError, TypeError, self.queryset.model.DoesNotExist):\n-            raise ValidationError(self.error_messages['invalid_choice'], code='invalid_choice')\n+            raise ValidationError(\n+                self.error_messages['invalid_choice'],\n+                code='invalid_choice',\n+                params={'value': value},\n+            )\n         return value\n \n     def validate(self, value):\ndiff --git a/tests/forms_tests/tests/test_error_messages.py b/tests/forms_tests/tests/test_error_messages.py\nindex 1a6d1386c3..4d95c5ad60 100644\n--- a/tests/forms_tests/tests/test_error_messages.py\n+++ b/tests/forms_tests/tests/test_error_messages.py\n@@ -292,11 +292,11 @@ class ModelChoiceFieldErrorMessagesTestCase(TestCase, AssertFormErrorsMixin):\n         # ModelChoiceField\n         e = {\n             'required': 'REQUIRED',\n-            'invalid_choice': 'INVALID CHOICE',\n+            'invalid_choice': '%(value)s IS INVALID CHOICE',\n         }\n         f = ModelChoiceField(queryset=ChoiceModel.objects.all(), error_messages=e)\n         self.assertFormErrors(['REQUIRED'], f.clean, '')\n-        self.assertFormErrors(['INVALID CHOICE'], f.clean, '4')\n+        self.assertFormErrors(['4 IS INVALID CHOICE'], f.clean, '4')\n \n         # ModelMultipleChoiceField\n         e = {\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "sphinx-doc__sphinx-8595", "model_patch": "diff --git a/sphinx/ext/autodoc/__init__.py b/sphinx/ext/autodoc/__init__.py\nindex d85d79617..c9f90acca 100644\n--- a/sphinx/ext/autodoc/__init__.py\n+++ b/sphinx/ext/autodoc/__init__.py\n@@ -1074,7 +1074,7 @@ class ModuleDocumenter(Documenter):\n     def get_object_members(self, want_all: bool) -> Tuple[bool, ObjectMembers]:\n         members = self.get_module_members()\n         if want_all:\n-            if not self.__all__:\n+            if self.__all__ is None:\n                 # for implicit module members, check __module__ to avoid\n                 # documenting imported objects\n                 return True, list(members.values())\ndiff --git a/tests/test_ext_autodoc.py b/tests/test_ext_autodoc.py\nindex 39897eb7d..c667d50ec 100644\n--- a/tests/test_ext_autodoc.py\n+++ b/tests/test_ext_autodoc.py\n@@ -738,6 +738,23 @@ def test_autodoc_ignore_module_all(app):\n     ]\n \n \n+@pytest.mark.sphinx('html', testroot='ext-autodoc')\n+def test_autodoc_empty_all(app):\n+    # Test that empty __all__ = [] results in no documented members\n+    options = {\"members\": None}\n+    actual = do_autodoc(app, 'module', 'target.empty_all', options)\n+    \n+    # Filter out the module directive and empty lines\n+    content_lines = [line for line in actual if line.strip() and not line.startswith('.. py:module::')]\n+    \n+    # Should only contain the module directive, no function/class directives\n+    function_lines = [line for line in content_lines if '.. py:function::' in line]\n+    class_lines = [line for line in content_lines if '.. py:class::' in line]\n+    \n+    assert function_lines == [], f\"Expected no functions, but found: {function_lines}\"\n+    assert class_lines == [], f\"Expected no classes, but found: {class_lines}\"\n+\n+\n @pytest.mark.sphinx('html', testroot='ext-autodoc')\n def test_autodoc_noindex(app):\n     options = {\"noindex\": True}\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "pylint-dev__pylint-7080", "model_patch": "diff --git a/Dockerfile b/Dockerfile\nindex 2667145da..3c398b2c7 100644\n--- a/Dockerfile\n+++ b/Dockerfile\n@@ -1,7 +1,30 @@\n-FROM python:3.10.0-alpine3.15\n \n-COPY ./ /tmp/build\n-WORKDIR /tmp/build\n-RUN python setup.py install && rm -rf /tmp/build\n+FROM swebench/sweb.eval.x86_64.pylint-dev_1776_pylint-7080:latest\n \n-ENTRYPOINT [\"pylint\"]\n+WORKDIR /install\n+# Install docker cli\n+# Add Docker's official GPG key:\n+RUN apt-get update\n+RUN apt-get install -y ca-certificates curl\n+RUN install -m 0755 -d /etc/apt/keyrings\n+RUN curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.asc\n+RUN chmod a+r /etc/apt/keyrings/docker.asc\n+\n+# Add the repository to Apt sources:\n+RUN echo   \"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu   $(. /etc/os-release && echo \"${UBUNTU_CODENAME:-$VERSION_CODENAME}\") stable\" |   tee /etc/apt/sources.list.d/docker.list > /dev/null\n+RUN apt-get update && apt-get install -y docker-ce-cli\n+\n+# Install required dependencies for SWE-bench (verification)\n+RUN apt-get install -y -V ca-certificates lsb-release wget\n+RUN wget https://apache.jfrog.io/artifactory/arrow/$(lsb_release --id --short | tr 'A-Z' 'a-z')/apache-arrow-apt-source-latest-$(lsb_release --codename --short).deb\n+RUN apt-get update\n+RUN apt-get install -y -V ./apache-arrow-apt-source-latest-$(lsb_release --codename --short).deb\n+\n+# Install SWE repo\n+RUN git clone https://github.com/princeton-nlp/SWE-bench.git /SWE-bench\n+WORKDIR /SWE-bench\n+RUN apt-get install -y python3-venv\n+RUN python3 -m venv .venv\n+RUN . .venv/bin/activate      &&     pip install --upgrade pip &&     pip install . \n+\n+WORKDIR /testbed\ndiff --git a/pylint/lint/pylinter.py b/pylint/lint/pylinter.py\nindex e2bbf061e..400935457 100644\n--- a/pylint/lint/pylinter.py\n+++ b/pylint/lint/pylinter.py\n@@ -610,11 +610,18 @@ class PyLinter(\n                         skip_subtrees.append(root)\n                         yield root\n                     else:\n-                        yield from (\n-                            os.path.join(root, file)\n-                            for file in files\n-                            if file.endswith(\".py\")\n-                        )\n+                        for file in files:\n+                            if file.endswith(\".py\"):\n+                                filepath = os.path.join(root, file)\n+                                # Make path relative to the starting directory for ignore pattern matching\n+                                relpath = os.path.relpath(filepath, something)\n+                                if not _is_ignored_file(\n+                                    relpath,\n+                                    self.config.ignore,\n+                                    self.config.ignore_patterns,\n+                                    self.config.ignore_paths,\n+                                ):\n+                                    yield filepath\n             else:\n                 yield something\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "django__django-11815", "model_patch": "diff --git a/django/db/migrations/serializer.py b/django/db/migrations/serializer.py\nindex 27b5cbd379..14032eb3e3 100644\n--- a/django/db/migrations/serializer.py\n+++ b/django/db/migrations/serializer.py\n@@ -120,9 +120,10 @@ class EnumSerializer(BaseSerializer):\n     def serialize(self):\n         enum_class = self.value.__class__\n         module = enum_class.__module__\n-        v_string, v_imports = serializer_factory(self.value.value).serialize()\n-        imports = {'import %s' % module, *v_imports}\n-        return \"%s.%s(%s)\" % (module, enum_class.__name__, v_string), imports\n+        # Use enum name instead of value for migration stability\n+        # This prevents migration failures when enum values change (e.g., translations)\n+        imports = {'import %s' % module}\n+        return \"%s.%s['%s']\" % (module, enum_class.__name__, self.value.name), imports\n \n \n class FloatSerializer(BaseSimpleSerializer):\ndiff --git a/tests/migrations/test_writer.py b/tests/migrations/test_writer.py\nindex f97d76e9ad..375fbf726a 100644\n--- a/tests/migrations/test_writer.py\n+++ b/tests/migrations/test_writer.py\n@@ -267,15 +267,15 @@ class WriterTests(SimpleTestCase):\n \n         self.assertSerializedResultEqual(\n             TextEnum.A,\n-            (\"migrations.test_writer.TextEnum('a-value')\", {'import migrations.test_writer'})\n+            (\"migrations.test_writer.TextEnum['A']\", {'import migrations.test_writer'})\n         )\n         self.assertSerializedResultEqual(\n             BinaryEnum.A,\n-            (\"migrations.test_writer.BinaryEnum(b'a-value')\", {'import migrations.test_writer'})\n+            (\"migrations.test_writer.BinaryEnum['A']\", {'import migrations.test_writer'})\n         )\n         self.assertSerializedResultEqual(\n             IntEnum.B,\n-            (\"migrations.test_writer.IntEnum(2)\", {'import migrations.test_writer'})\n+            (\"migrations.test_writer.IntEnum['B']\", {'import migrations.test_writer'})\n         )\n \n         field = models.CharField(default=TextEnum.B, choices=[(m.value, m) for m in TextEnum])\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "django__django-17087", "model_patch": "diff --git a/django/db/migrations/serializer.py b/django/db/migrations/serializer.py\nindex d88cda6e20..06657ebaab 100644\n--- a/django/db/migrations/serializer.py\n+++ b/django/db/migrations/serializer.py\n@@ -168,7 +168,7 @@ class FunctionTypeSerializer(BaseSerializer):\n         ):\n             klass = self.value.__self__\n             module = klass.__module__\n-            return \"%s.%s.%s\" % (module, klass.__name__, self.value.__name__), {\n+            return \"%s.%s.%s\" % (module, klass.__qualname__, self.value.__name__), {\n                 \"import %s\" % module\n             }\n         # Further error checking\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "django__django-15851", "model_patch": "diff --git a/django/db/backends/postgresql/client.py b/django/db/backends/postgresql/client.py\nindex 4c9bd63546..3b5ddafaca 100644\n--- a/django/db/backends/postgresql/client.py\n+++ b/django/db/backends/postgresql/client.py\n@@ -32,9 +32,9 @@ class DatabaseClient(BaseDatabaseClient):\n             args += [\"-h\", host]\n         if port:\n             args += [\"-p\", str(port)]\n+        args.extend(parameters)\n         if dbname:\n             args += [dbname]\n-        args.extend(parameters)\n \n         env = {}\n         if passwd:\ndiff --git a/tests/dbshell/test_postgresql.py b/tests/dbshell/test_postgresql.py\nindex 02924d0bcc..38bdbbaf15 100644\n--- a/tests/dbshell/test_postgresql.py\n+++ b/tests/dbshell/test_postgresql.py\n@@ -154,7 +154,54 @@ class PostgreSqlDbshellCommandTestCase(SimpleTestCase):\n     def test_parameters(self):\n         self.assertEqual(\n             self.settings_to_cmd_args_env({\"NAME\": \"dbname\"}, [\"--help\"]),\n-            ([\"psql\", \"dbname\", \"--help\"], None),\n+            ([\"psql\", \"--help\", \"dbname\"], None),\n+        )\n+\n+    def test_parameters_with_command(self):\n+        \"\"\"Test that -c parameters come before database name.\"\"\"\n+        self.assertEqual(\n+            self.settings_to_cmd_args_env(\n+                {\"NAME\": \"dbname\"}, [\"-c\", \"SELECT version();\"]\n+            ),\n+            ([\"psql\", \"-c\", \"SELECT version();\", \"dbname\"], None),\n+        )\n+\n+    def test_multiple_parameters(self):\n+        \"\"\"Test that multiple parameters come before database name.\"\"\"\n+        self.assertEqual(\n+            self.settings_to_cmd_args_env(\n+                {\"NAME\": \"dbname\"}, [\"-c\", \"SELECT 1;\", \"--quiet\"]\n+            ),\n+            ([\"psql\", \"-c\", \"SELECT 1;\", \"--quiet\", \"dbname\"], None),\n+        )\n+\n+    def test_parameters_with_full_connection(self):\n+        \"\"\"Test parameters with full connection details.\"\"\"\n+        self.assertEqual(\n+            self.settings_to_cmd_args_env(\n+                {\n+                    \"NAME\": \"dbname\",\n+                    \"USER\": \"someuser\",\n+                    \"HOST\": \"somehost\",\n+                    \"PORT\": \"444\",\n+                },\n+                [\"-c\", \"SELECT current_user;\"],\n+            ),\n+            (\n+                [\n+                    \"psql\",\n+                    \"-U\",\n+                    \"someuser\",\n+                    \"-h\",\n+                    \"somehost\",\n+                    \"-p\",\n+                    \"444\",\n+                    \"-c\",\n+                    \"SELECT current_user;\",\n+                    \"dbname\",\n+                ],\n+                None,\n+            ),\n         )\n \n     @skipUnless(connection.vendor == \"postgresql\", \"Requires a PostgreSQL connection\")\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "django__django-14672", "model_patch": "diff --git a/django/db/models/fields/reverse_related.py b/django/db/models/fields/reverse_related.py\nindex ccc2223a5f..65950590e2 100644\n--- a/django/db/models/fields/reverse_related.py\n+++ b/django/db/models/fields/reverse_related.py\n@@ -310,7 +310,7 @@ class ManyToManyRel(ForeignObjectRel):\n     def identity(self):\n         return super().identity + (\n             self.through,\n-            self.through_fields,\n+            make_hashable(self.through_fields),\n             self.db_constraint,\n         )\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "django__django-14752", "model_patch": "diff --git a/django/contrib/admin/views/autocomplete.py b/django/contrib/admin/views/autocomplete.py\nindex 3903e4c98c..c30181d726 100644\n--- a/django/contrib/admin/views/autocomplete.py\n+++ b/django/contrib/admin/views/autocomplete.py\n@@ -26,12 +26,19 @@ class AutocompleteJsonView(BaseListView):\n         context = self.get_context_data()\n         return JsonResponse({\n             'results': [\n-                {'id': str(getattr(obj, to_field_name)), 'text': str(obj)}\n+                self.serialize_result(obj, to_field_name)\n                 for obj in context['object_list']\n             ],\n             'pagination': {'more': context['page_obj'].has_next()},\n         })\n \n+    def serialize_result(self, obj, to_field_name):\n+        \"\"\"\n+        Convert the provided model object to a dictionary that is added to the\n+        autocomplete results.\n+        \"\"\"\n+        return {'id': str(getattr(obj, to_field_name)), 'text': str(obj)}\n+\n     def get_paginator(self, *args, **kwargs):\n         \"\"\"Use the ModelAdmin's paginator.\"\"\"\n         return self.model_admin.get_paginator(self.request, *args, **kwargs)\ndiff --git a/tests/admin_views/test_autocomplete_view.py b/tests/admin_views/test_autocomplete_view.py\nindex aa978f7a83..e064fdafd6 100644\n--- a/tests/admin_views/test_autocomplete_view.py\n+++ b/tests/admin_views/test_autocomplete_view.py\n@@ -293,6 +293,67 @@ class AutocompleteJsonViewTests(AdminViewBasicTestCase):\n             'pagination': {'more': False},\n         })\n \n+    def test_serialize_result_default(self):\n+        \"\"\"Test the default serialize_result method.\"\"\"\n+        q = Question.objects.create(question='Test serialize_result')\n+        view = AutocompleteJsonView()\n+        result = view.serialize_result(q, 'big_id')\n+        \n+        self.assertEqual(result, {\n+            'id': str(q.big_id),\n+            'text': str(q),\n+        })\n+\n+    def test_serialize_result_custom_override(self):\n+        \"\"\"Test custom override of serialize_result method.\"\"\"\n+        class CustomAutocompleteJsonView(AutocompleteJsonView):\n+            def serialize_result(self, obj, to_field_name):\n+                result = super().serialize_result(obj, to_field_name)\n+                result['extra_field'] = f\"Extra: {obj.question}\"\n+                return result\n+\n+        q = Question.objects.create(question='Custom test')\n+        request = self.factory.get(self.url, {'term': 'Custom', **self.opts})\n+        request.user = self.superuser\n+        response = CustomAutocompleteJsonView.as_view(**self.as_view_args)(request)\n+        self.assertEqual(response.status_code, 200)\n+        data = json.loads(response.content.decode('utf-8'))\n+        \n+        if data['results']:\n+            result = data['results'][0]\n+            self.assertIn('id', result)\n+            self.assertIn('text', result)\n+            self.assertIn('extra_field', result)\n+            self.assertEqual(result['extra_field'], f\"Extra: {q.question}\")\n+\n+    def test_serialize_result_complete_replacement(self):\n+        \"\"\"Test complete replacement of serialize_result method.\"\"\"\n+        class ReplacementAutocompleteJsonView(AutocompleteJsonView):\n+            def serialize_result(self, obj, to_field_name):\n+                return {\n+                    'value': str(getattr(obj, to_field_name)),\n+                    'label': str(obj),\n+                    'category': 'question'\n+                }\n+\n+        q = Question.objects.create(question='Replacement test')\n+        request = self.factory.get(self.url, {'term': 'Replacement', **self.opts})\n+        request.user = self.superuser\n+        response = ReplacementAutocompleteJsonView.as_view(**self.as_view_args)(request)\n+        self.assertEqual(response.status_code, 200)\n+        data = json.loads(response.content.decode('utf-8'))\n+        \n+        if data['results']:\n+            result = data['results'][0]\n+            self.assertIn('value', result)\n+            self.assertIn('label', result)\n+            self.assertIn('category', result)\n+            self.assertNotIn('id', result)  # Original keys should be gone\n+            self.assertNotIn('text', result)\n+            self.assertEqual(result['value'], str(q.big_id))\n+            self.assertEqual(result['label'], str(q))\n+            self.assertEqual(result['category'], 'question')\n+\n \n @override_settings(ROOT_URLCONF='admin_views.urls')\n class SeleniumTests(AdminSeleniumTestCase):\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "django__django-11099", "model_patch": "diff --git a/django/contrib/auth/validators.py b/django/contrib/auth/validators.py\nindex b4878cfd45..9345c5cb0b 100644\n--- a/django/contrib/auth/validators.py\n+++ b/django/contrib/auth/validators.py\n@@ -7,7 +7,7 @@ from django.utils.translation import gettext_lazy as _\n \n @deconstructible\n class ASCIIUsernameValidator(validators.RegexValidator):\n-    regex = r'^[\\w.@+-]+$'\n+    regex = r'^[\\w.@+-]+\\Z'\n     message = _(\n         'Enter a valid username. This value may contain only English letters, '\n         'numbers, and @/./+/-/_ characters.'\n@@ -17,7 +17,7 @@ class ASCIIUsernameValidator(validators.RegexValidator):\n \n @deconstructible\n class UnicodeUsernameValidator(validators.RegexValidator):\n-    regex = r'^[\\w.@+-]+$'\n+    regex = r'^[\\w.@+-]+\\Z'\n     message = _(\n         'Enter a valid username. This value may contain only letters, '\n         'numbers, and @/./+/-/_ characters.'\ndiff --git a/tests/auth_tests/test_validators.py b/tests/auth_tests/test_validators.py\nindex 1c2c6b4aff..ae06825223 100644\n--- a/tests/auth_tests/test_validators.py\n+++ b/tests/auth_tests/test_validators.py\n@@ -259,3 +259,73 @@ class UsernameValidatorsTests(SimpleTestCase):\n             with self.subTest(invalid=invalid):\n                 with self.assertRaises(ValidationError):\n                     v(invalid)\n+\n+    def test_unicode_validator_rejects_trailing_newlines(self):\n+        \"\"\"Test that UnicodeUsernameValidator rejects usernames with trailing newlines.\"\"\"\n+        invalid_usernames = [\n+            'validuser\\n',      # trailing newline\n+            'test@example\\n',   # with @ and trailing newline\n+            'user.name\\n',      # with . and trailing newline\n+            'user+name\\n',      # with + and trailing newline\n+            'user-name\\n',      # with - and trailing newline\n+            'user_name\\n',      # with _ and trailing newline\n+            'user\\r',           # trailing carriage return\n+            'user\\t',           # trailing tab\n+            'user\\r\\n',         # trailing CRLF\n+            'user\\n\\n',         # multiple trailing newlines\n+            'user ',            # trailing space\n+        ]\n+        v = validators.UnicodeUsernameValidator()\n+        for invalid in invalid_usernames:\n+            with self.subTest(invalid=repr(invalid)):\n+                with self.assertRaises(ValidationError):\n+                    v(invalid)\n+\n+    def test_ascii_validator_rejects_trailing_newlines(self):\n+        \"\"\"Test that ASCIIUsernameValidator rejects usernames with trailing newlines.\"\"\"\n+        invalid_usernames = [\n+            'validuser\\n',      # trailing newline\n+            'test@example\\n',   # with @ and trailing newline\n+            'user.name\\n',      # with . and trailing newline\n+            'user+name\\n',      # with + and trailing newline\n+            'user-name\\n',      # with - and trailing newline\n+            'user_name\\n',      # with _ and trailing newline\n+            'user\\r',           # trailing carriage return\n+            'user\\t',           # trailing tab\n+            'user\\r\\n',         # trailing CRLF\n+            'user\\n\\n',         # multiple trailing newlines\n+            'user ',            # trailing space\n+        ]\n+        v = validators.ASCIIUsernameValidator()\n+        for invalid in invalid_usernames:\n+            with self.subTest(invalid=repr(invalid)):\n+                with self.assertRaises(ValidationError):\n+                    v(invalid)\n+\n+    def test_unicode_validator_rejects_leading_newlines(self):\n+        \"\"\"Test that UnicodeUsernameValidator rejects usernames with leading newlines.\"\"\"\n+        invalid_usernames = [\n+            '\\nvaliduser',      # leading newline\n+            '\\ruser',           # leading carriage return\n+            '\\tuser',           # leading tab\n+            ' user',            # leading space\n+        ]\n+        v = validators.UnicodeUsernameValidator()\n+        for invalid in invalid_usernames:\n+            with self.subTest(invalid=repr(invalid)):\n+                with self.assertRaises(ValidationError):\n+                    v(invalid)\n+\n+    def test_ascii_validator_rejects_leading_newlines(self):\n+        \"\"\"Test that ASCIIUsernameValidator rejects usernames with leading newlines.\"\"\"\n+        invalid_usernames = [\n+            '\\nvaliduser',      # leading newline\n+            '\\ruser',           # leading carriage return\n+            '\\tuser',           # leading tab\n+            ' user',            # leading space\n+        ]\n+        v = validators.ASCIIUsernameValidator()\n+        for invalid in invalid_usernames:\n+            with self.subTest(invalid=repr(invalid)):\n+                with self.assertRaises(ValidationError):\n+                    v(invalid)\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "django__django-14534", "model_patch": "diff --git a/django/forms/boundfield.py b/django/forms/boundfield.py\nindex 2ff8b0ee26..7fb73cc47f 100644\n--- a/django/forms/boundfield.py\n+++ b/django/forms/boundfield.py\n@@ -277,7 +277,7 @@ class BoundWidget:\n \n     @property\n     def id_for_label(self):\n-        return 'id_%s_%s' % (self.data['name'], self.data['index'])\n+        return self.data['attrs'].get('id') or 'id_%s_%s' % (self.data['name'], self.data['index'])\n \n     @property\n     def choice_label(self):\ndiff --git a/tests/forms_tests/tests/test_forms.py b/tests/forms_tests/tests/test_forms.py\nindex f3ee64ceda..7d9eabb513 100644\n--- a/tests/forms_tests/tests/test_forms.py\n+++ b/tests/forms_tests/tests/test_forms.py\n@@ -3211,6 +3211,59 @@ Good luck picking a username that doesn&#x27;t already exist.</p>\n         self.assertEqual(f['first_name'].widget_type, 'text')\n         self.assertEqual(f['birthday'].widget_type, 'splithiddendatetime')\n \n+    def test_boundwidget_id_for_label_with_custom_auto_id(self):\n+        \"\"\"BoundWidget.id_for_label should use the id from data['attrs']['id'] when available.\"\"\"\n+        class TestForm(Form):\n+            choices = MultipleChoiceField(\n+                choices=[('option1', 'Option 1'), ('option2', 'Option 2')],\n+                widget=CheckboxSelectMultiple()\n+            )\n+        \n+        form = TestForm(auto_id='custom_id_%s')\n+        bound_field = form['choices']\n+        subwidgets = bound_field.subwidgets\n+        \n+        for i, subwidget in enumerate(subwidgets):\n+            expected_id = f'custom_id_choices_{i}'\n+            self.assertEqual(subwidget.data['attrs']['id'], expected_id)\n+            self.assertEqual(subwidget.id_for_label, expected_id)\n+\n+    def test_boundwidget_id_for_label_fallback_when_no_id(self):\n+        \"\"\"BoundWidget.id_for_label should fall back to hardcoded format when no id in attrs.\"\"\"\n+        class TestForm(Form):\n+            choices = MultipleChoiceField(\n+                choices=[('option1', 'Option 1'), ('option2', 'Option 2')],\n+                widget=CheckboxSelectMultiple()\n+            )\n+        \n+        form = TestForm(auto_id=False)\n+        bound_field = form['choices']\n+        subwidgets = bound_field.subwidgets\n+        \n+        for i, subwidget in enumerate(subwidgets):\n+            # When auto_id=False, no id should be set in attrs\n+            self.assertIsNone(subwidget.data['attrs'].get('id'))\n+            # Should fall back to hardcoded format\n+            expected_fallback = f'id_choices_{i}'\n+            self.assertEqual(subwidget.id_for_label, expected_fallback)\n+\n+    def test_boundwidget_id_for_label_with_widget_attrs_id(self):\n+        \"\"\"BoundWidget.id_for_label should work when widget has explicit id in attrs.\"\"\"\n+        class TestForm(Form):\n+            choices = MultipleChoiceField(\n+                choices=[('option1', 'Option 1'), ('option2', 'Option 2')],\n+                widget=CheckboxSelectMultiple(attrs={'id': 'explicit_id'})\n+            )\n+        \n+        form = TestForm()\n+        bound_field = form['choices']\n+        subwidgets = bound_field.subwidgets\n+        \n+        for i, subwidget in enumerate(subwidgets):\n+            expected_id = f'explicit_id_{i}'\n+            self.assertEqual(subwidget.data['attrs']['id'], expected_id)\n+            self.assertEqual(subwidget.id_for_label, expected_id)\n+\n     def test_boundfield_css_classes(self):\n         form = Person()\n         field = form['first_name']\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "sympy__sympy-12481", "model_patch": "diff --git a/sympy/combinatorics/permutations.py b/sympy/combinatorics/permutations.py\nindex 136ed5a478..4854a07853 100644\n--- a/sympy/combinatorics/permutations.py\n+++ b/sympy/combinatorics/permutations.py\n@@ -896,10 +896,7 @@ def __new__(cls, *args, **kwargs):\n \n         temp = flatten(args)\n         if has_dups(temp):\n-            if is_cycle:\n-                raise ValueError('there were repeated elements; to resolve '\n-                'cycles use Cycle%s.' % ''.join([str(tuple(c)) for c in args]))\n-            else:\n+            if not is_cycle:\n                 raise ValueError('there were repeated elements.')\n         temp = set(temp)\n \ndiff --git a/sympy/combinatorics/tests/test_permutations.py b/sympy/combinatorics/tests/test_permutations.py\nindex 7f8cd572e7..cb7ef829b1 100644\n--- a/sympy/combinatorics/tests/test_permutations.py\n+++ b/sympy/combinatorics/tests/test_permutations.py\n@@ -349,7 +349,7 @@ def test_args():\n     raises(ValueError, lambda: Permutation([[1, 2], 0]))\n            # enclosing brackets needed on 0\n     raises(ValueError, lambda: Permutation([1, 1, 0]))\n-    raises(ValueError, lambda: Permutation([[1], [1, 2]]))\n+    assert Permutation([[1], [1, 2]]) == Permutation([0, 2, 1])\n     raises(ValueError, lambda: Permutation([4, 5], size=10))  # where are 0-3?\n     # but this is ok because cycles imply that only those listed moved\n     assert Permutation(4, 5) == Permutation([0, 1, 2, 3, 5, 4])\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "pydata__xarray-4094", "model_patch": "diff --git a/xarray/core/dataarray.py b/xarray/core/dataarray.py\nindex b0df8749..d3ecd961 100644\n--- a/xarray/core/dataarray.py\n+++ b/xarray/core/dataarray.py\n@@ -1961,7 +1961,11 @@ class DataArray(AbstractArray, DataWithCoords):\n         # pull variables out of datarray\n         data_dict = {}\n         for k in variables:\n-            data_dict[k] = self.sel({variable_dim: k}).squeeze(drop=True)\n+            selected = self.sel({variable_dim: k}).squeeze(drop=True)\n+            # Drop the stacking dimension coordinate if it exists\n+            if dim in selected.coords:\n+                selected = selected.drop_vars(dim)\n+            data_dict[k] = selected\n \n         # unstacked dataset\n         return Dataset(data_dict)\ndiff --git a/xarray/tests/test_dataarray.py b/xarray/tests/test_dataarray.py\nindex d942667a..65343918 100644\n--- a/xarray/tests/test_dataarray.py\n+++ b/xarray/tests/test_dataarray.py\n@@ -2134,6 +2134,22 @@ class TestDataArray:\n         with pytest.raises(ValueError, match=\"'x' is not a stacked coordinate\"):\n             data.to_unstacked_dataset(\"x\", 0)\n \n+    def test_to_unstacked_dataset_single_dim_variables(self):\n+        # Test for issue where single-dimension variables caused MergeError\n+        # during unstacking due to conflicting scalar coordinates\n+        arr = DataArray(\n+            np.arange(3),\n+            coords=[(\"x\", [0, 1, 2])],\n+        )\n+        data = Dataset({\"a\": arr, \"b\": arr})\n+        \n+        # Stack and unstack should work without MergeError\n+        stacked = data.to_stacked_array('y', sample_dims=['x'])\n+        unstacked = stacked.to_unstacked_dataset('y')\n+        \n+        # Should be a perfect roundtrip\n+        assert_identical(data, unstacked)\n+\n     def test_transpose(self):\n         da = DataArray(\n             np.random.randn(3, 4, 5),\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "django__django-13925", "model_patch": "diff --git a/django/db/models/base.py b/django/db/models/base.py\nindex 4038859cfa..d0fa0d5ee4 100644\n--- a/django/db/models/base.py\n+++ b/django/db/models/base.py\n@@ -1302,6 +1302,25 @@ class Model(metaclass=ModelBase):\n             not settings.is_overridden('DEFAULT_AUTO_FIELD') and\n             not cls._meta.app_config._is_default_auto_field_overridden\n         ):\n+            # Don't warn for inherited primary keys from multi-table inheritance\n+            # If the primary key is a OneToOneField pointing to a parent model,\n+            # traverse the inheritance chain to find the ultimate base model\n+            # and check if it has an explicitly defined primary key\n+            if cls._meta.pk.one_to_one and cls._meta.pk.related_model in cls._meta.parents:\n+                # Traverse up the inheritance chain to find the root model\n+                current_model = cls._meta.pk.related_model\n+                while (\n+                    current_model._meta.pk.auto_created and\n+                    current_model._meta.pk.one_to_one and\n+                    current_model._meta.pk.related_model in current_model._meta.parents\n+                ):\n+                    current_model = current_model._meta.pk.related_model\n+                \n+                # If the root model has an explicitly defined primary key,\n+                # this is inheritance, not a truly auto-created primary key\n+                if not current_model._meta.pk.auto_created:\n+                    return []\n+            \n             return [\n                 checks.Warning(\n                     f\"Auto-created primary key used when not defining a \"\ndiff --git a/tests/check_framework/test_model_checks.py b/tests/check_framework/test_model_checks.py\nindex d4342ada07..f9da674788 100644\n--- a/tests/check_framework/test_model_checks.py\n+++ b/tests/check_framework/test_model_checks.py\n@@ -415,3 +415,43 @@ class ModelDefaultAutoFieldTests(SimpleTestCase):\n                 app_label = 'check_framework.apps.CheckPKConfig'\n \n         self.assertEqual(checks.run_checks(app_configs=apps.get_app_configs()), [])\n+\n+    def test_inherited_pk_from_explicit_pk(self):\n+        \"\"\"Models inheriting from a model with explicit PK should not trigger W042.\"\"\"\n+        class BaseModel(models.Model):\n+            id = models.BigAutoField(primary_key=True)\n+            name = models.CharField(max_length=100)\n+\n+        class ChildModel(BaseModel):\n+            email = models.EmailField()\n+\n+        self.assertEqual(checks.run_checks(app_configs=self.apps.get_app_configs()), [])\n+\n+    def test_inherited_pk_from_auto_pk(self):\n+        \"\"\"Models inheriting from a model with auto PK should still trigger W042.\"\"\"\n+        class BaseModelWithAutoPK(models.Model):\n+            name = models.CharField(max_length=100)\n+\n+        class ChildModelWithAutoPK(BaseModelWithAutoPK):\n+            email = models.EmailField()\n+\n+        errors = checks.run_checks(app_configs=self.apps.get_app_configs())\n+        # Both parent and child should have W042 warnings\n+        w042_errors = [e for e in errors if e.id == 'models.W042']\n+        self.assertEqual(len(w042_errors), 2)\n+        self.assertIn(BaseModelWithAutoPK, [e.obj for e in w042_errors])\n+        self.assertIn(ChildModelWithAutoPK, [e.obj for e in w042_errors])\n+\n+    def test_multi_level_inherited_pk_from_explicit_pk(self):\n+        \"\"\"Multi-level inheritance from explicit PK should not trigger W042.\"\"\"\n+        class BaseModel(models.Model):\n+            id = models.BigAutoField(primary_key=True)\n+            name = models.CharField(max_length=100)\n+\n+        class MiddleModel(BaseModel):\n+            email = models.EmailField()\n+\n+        class LeafModel(MiddleModel):\n+            phone = models.CharField(max_length=20)\n+\n+        self.assertEqual(checks.run_checks(app_configs=self.apps.get_app_configs()), [])\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "sympy__sympy-22714", "model_patch": "diff --git a/sympy/geometry/point.py b/sympy/geometry/point.py\nindex 73c20334d0..e8606524d2 100644\n--- a/sympy/geometry/point.py\n+++ b/sympy/geometry/point.py\n@@ -152,7 +152,7 @@ def __new__(cls, *args, **kwargs):\n                         'warn' or 'ignore'.'''))\n         if any(coords[dim:]):\n             raise ValueError('Nonzero coordinates cannot be removed.')\n-        if any(a.is_number and im(a) for a in coords):\n+        if any(a.is_number and not im(a).is_zero for a in coords):\n             raise ValueError('Imaginary coordinates are not permitted.')\n         if not all(isinstance(a, Expr) for a in coords):\n             raise TypeError('Coordinates must be valid SymPy expressions.')\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "django__django-14855", "model_patch": "diff --git a/django/contrib/admin/helpers.py b/django/contrib/admin/helpers.py\nindex dd154f72ee..45d6e8e29d 100644\n--- a/django/contrib/admin/helpers.py\n+++ b/django/contrib/admin/helpers.py\n@@ -204,7 +204,8 @@ class AdminReadonlyField:\n         return format_html('<label{}>{}{}</label>', flatatt(attrs), capfirst(label), self.form.label_suffix)\n \n     def get_admin_url(self, remote_field, remote_obj):\n-        url_name = 'admin:%s_%s_change' % (\n+        url_name = '%s:%s_%s_change' % (\n+            self.model_admin.admin_site.name,\n             remote_field.model._meta.app_label,\n             remote_field.model._meta.model_name,\n         )\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "django__django-16595", "model_patch": "diff --git a/django/db/migrations/operations/fields.py b/django/db/migrations/operations/fields.py\nindex cd3aab43ad..e2682aeac0 100644\n--- a/django/db/migrations/operations/fields.py\n+++ b/django/db/migrations/operations/fields.py\n@@ -264,6 +264,10 @@ class AlterField(FieldOperation):\n                     field=self.field,\n                 ),\n             ]\n+        elif isinstance(operation, AlterField) and self.is_same_field_operation(\n+            operation\n+        ):\n+            return [operation]\n         return super().reduce(operation, app_label)\n \n \ndiff --git a/tests/migrations/test_optimizer.py b/tests/migrations/test_optimizer.py\nindex 6485009eb4..b6398777a6 100644\n--- a/tests/migrations/test_optimizer.py\n+++ b/tests/migrations/test_optimizer.py\n@@ -822,6 +822,21 @@ class OptimizerTests(SimpleTestCase):\n             ],\n         )\n \n+    def test_multiple_alter_field(self):\n+        \"\"\"\n+        Multiple AlterField operations on the same field should be reduced to a single AlterField.\n+        \"\"\"\n+        self.assertOptimizesTo(\n+            [\n+                migrations.AlterField(\"Foo\", \"age\", models.IntegerField()),\n+                migrations.AlterField(\"Foo\", \"age\", models.FloatField()),\n+                migrations.AlterField(\"Foo\", \"age\", models.CharField(max_length=100)),\n+            ],\n+            [\n+                migrations.AlterField(\"Foo\", \"age\", models.CharField(max_length=100)),\n+            ],\n+        )\n+\n     def _test_create_alter_foo_field(self, alter):\n         \"\"\"\n         CreateModel, AlterFooTogether/AlterOrderWithRespectTo followed by an\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "scikit-learn__scikit-learn-10297", "model_patch": "diff --git a/sklearn/linear_model/ridge.py b/sklearn/linear_model/ridge.py\nindex 911c74ae3..6469cdbcf 100644\n--- a/sklearn/linear_model/ridge.py\n+++ b/sklearn/linear_model/ridge.py\n@@ -1301,6 +1301,12 @@ class RidgeClassifierCV(LinearClassifierMixin, _BaseRidgeCV):\n         weights inversely proportional to class frequencies in the input data\n         as ``n_samples / (n_classes * np.bincount(y))``\n \n+    store_cv_values : boolean, default=False\n+        Flag indicating if the cross-validation values corresponding to\n+        each alpha should be stored in the `cv_values_` attribute (see\n+        below). This flag is only compatible with `cv=None` (i.e. using\n+        Generalized Cross-Validation).\n+\n     Attributes\n     ----------\n     cv_values_ : array, shape = [n_samples, n_alphas] or \\\n@@ -1333,10 +1339,11 @@ class RidgeClassifierCV(LinearClassifierMixin, _BaseRidgeCV):\n     advantage of the multi-variate response support in Ridge.\n     \"\"\"\n     def __init__(self, alphas=(0.1, 1.0, 10.0), fit_intercept=True,\n-                 normalize=False, scoring=None, cv=None, class_weight=None):\n+                 normalize=False, scoring=None, cv=None, class_weight=None,\n+                 store_cv_values=False):\n         super(RidgeClassifierCV, self).__init__(\n             alphas=alphas, fit_intercept=fit_intercept, normalize=normalize,\n-            scoring=scoring, cv=cv)\n+            scoring=scoring, cv=cv, store_cv_values=store_cv_values)\n         self.class_weight = class_weight\n \n     def fit(self, X, y, sample_weight=None):\ndiff --git a/sklearn/linear_model/tests/test_ridge.py b/sklearn/linear_model/tests/test_ridge.py\nindex ee44da5d5..e6d48860e 100644\n--- a/sklearn/linear_model/tests/test_ridge.py\n+++ b/sklearn/linear_model/tests/test_ridge.py\n@@ -35,6 +35,7 @@ from sklearn.model_selection import KFold\n \n from sklearn.utils import check_random_state\n from sklearn.datasets import make_multilabel_classification\n+from sklearn.datasets import make_classification\n \n diabetes = datasets.load_diabetes()\n X_diabetes, y_diabetes = diabetes.data, diabetes.target\n@@ -860,3 +861,49 @@ def test_dtype_match_cholesky():\n     assert ridge_32.predict(X_32).dtype == X_32.dtype\n     assert ridge_64.predict(X_64).dtype == X_64.dtype\n     assert_almost_equal(ridge_32.coef_, ridge_64.coef_, decimal=5)\n+\n+\n+def test_ridgeclassifiercv_store_cv_values():\n+    \"\"\"Test that RidgeClassifierCV supports store_cv_values parameter.\"\"\"\n+    X, y = make_classification(n_samples=50, n_features=10, n_classes=2, \n+                              random_state=42)\n+    \n+    # Test with store_cv_values=True\n+    clf = RidgeClassifierCV(alphas=[0.1, 1.0, 10.0], store_cv_values=True)\n+    clf.fit(X, y)\n+    \n+    # Should have cv_values_ attribute\n+    assert_true(hasattr(clf, 'cv_values_'))\n+    assert_true(clf.cv_values_ is not None)\n+    assert_equal(clf.cv_values_.shape, (X.shape[0], 1, len(clf.alphas)))\n+    \n+    # Test with store_cv_values=False (default)\n+    clf_default = RidgeClassifierCV(alphas=[0.1, 1.0, 10.0])\n+    clf_default.fit(X, y)\n+    \n+    # Should not have cv_values_ attribute\n+    assert_true(not hasattr(clf_default, 'cv_values_'))\n+\n+\n+def test_ridgeclassifiercv_store_cv_values_multiclass():\n+    \"\"\"Test store_cv_values with multiclass classification.\"\"\"\n+    X, y = make_classification(n_samples=50, n_features=10, n_classes=3, \n+                              n_informative=8, random_state=42)\n+    \n+    clf = RidgeClassifierCV(alphas=[0.1, 1.0, 10.0], store_cv_values=True)\n+    clf.fit(X, y)\n+    \n+    # Should have cv_values_ attribute with correct shape for multiclass\n+    assert_true(hasattr(clf, 'cv_values_'))\n+    assert_equal(clf.cv_values_.shape, (X.shape[0], 3, len(clf.alphas)))\n+\n+\n+def test_ridgeclassifiercv_store_cv_values_incompatible_with_cv():\n+    \"\"\"Test that store_cv_values=True with cv!=None raises ValueError.\"\"\"\n+    X, y = make_classification(n_samples=50, n_features=10, n_classes=2, \n+                              random_state=42)\n+    \n+    clf = RidgeClassifierCV(alphas=[0.1, 1.0, 10.0], cv=5, store_cv_values=True)\n+    \n+    assert_raise_message(ValueError, \"cv!=None and store_cv_values=True\",\n+                        clf.fit, X, y)\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "django__django-14238", "model_patch": "diff --git a/django/db/models/fields/__init__.py b/django/db/models/fields/__init__.py\nindex 0f53d9c30b..f2a6a277ff 100644\n--- a/django/db/models/fields/__init__.py\n+++ b/django/db/models/fields/__init__.py\n@@ -2524,7 +2524,9 @@ class AutoFieldMeta(type):\n         return isinstance(instance, self._subclasses) or super().__instancecheck__(instance)\n \n     def __subclasscheck__(self, subclass):\n-        return subclass in self._subclasses or super().__subclasscheck__(subclass)\n+        return (subclass in self._subclasses or \n+                any(issubclass(subclass, subcls) for subcls in self._subclasses) or\n+                super().__subclasscheck__(subclass))\n \n \n class AutoField(AutoFieldMixin, IntegerField, metaclass=AutoFieldMeta):\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "psf__requests-2317", "model_patch": "diff --git a/requests/models.py b/requests/models.py\nindex 3f6a4f92..6ff429e9 100644\n--- a/requests/models.py\n+++ b/requests/models.py\n@@ -329,6 +329,10 @@ class PreparedRequest(RequestEncodingMixin, RequestHooksMixin):\n         \"\"\"Prepares the given HTTP method.\"\"\"\n         self.method = method\n         if self.method is not None:\n+            # Handle bytes method names properly by decoding them\n+            # instead of using str() which gives the repr() of bytes\n+            if isinstance(self.method, bytes):\n+                self.method = self.method.decode('utf-8')\n             self.method = self.method.upper()\n \n     def prepare_url(self, url, params):\ndiff --git a/requests/sessions.py b/requests/sessions.py\nindex d701ff2e..61160268 100644\n--- a/requests/sessions.py\n+++ b/requests/sessions.py\n@@ -425,7 +425,12 @@ class Session(SessionRedirectMixin):\n             If Tuple, ('cert', 'key') pair.\n         \"\"\"\n \n-        method = builtin_str(method)\n+        # Handle bytes method names properly by decoding them\n+        # instead of using str() which gives the repr() of bytes\n+        if isinstance(method, bytes):\n+            method = method.decode('utf-8')\n+        else:\n+            method = builtin_str(method)\n \n         # Create the Request.\n         req = Request(\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "django__django-16527", "model_patch": "diff --git a/django/contrib/admin/templatetags/admin_modify.py b/django/contrib/admin/templatetags/admin_modify.py\nindex 9df4b7aadb..5b742af46a 100644\n--- a/django/contrib/admin/templatetags/admin_modify.py\n+++ b/django/contrib/admin/templatetags/admin_modify.py\n@@ -100,6 +100,7 @@ def submit_row(context):\n                 and context.get(\"show_delete\", True)\n             ),\n             \"show_save_as_new\": not is_popup\n+            and has_add_permission\n             and has_change_permission\n             and change\n             and save_as,\ndiff --git a/tests/admin_views/tests.py b/tests/admin_views/tests.py\nindex 03ab9a9454..7a2471d169 100644\n--- a/tests/admin_views/tests.py\n+++ b/tests/admin_views/tests.py\n@@ -2647,6 +2647,56 @@ class AdminViewPermissionsTest(TestCase):\n             post, reverse(\"admin:admin_views_article_change\", args=(new_article.pk,))\n         )\n \n+    def test_save_as_new_button_visibility(self):\n+        \"\"\"\n+        The 'Save as new' button should only be visible to users with both\n+        'change' and 'add' permissions.\n+        \"\"\"\n+        # Create a Person object to test with (PersonAdmin has save_as=True)\n+        person = Person.objects.create(name=\"Test Person\", gender=1, alive=True)\n+        person_change_url = reverse(\n+            \"admin:admin_views_person_change\", args=(person.pk,)\n+        )\n+\n+        # Set up permissions for Person model\n+        person_opts = Person._meta\n+        person_add_perm = get_perm(Person, get_permission_codename(\"add\", person_opts))\n+        person_change_perm = get_perm(Person, get_permission_codename(\"change\", person_opts))\n+\n+        # Create users with specific permissions\n+        user_with_both = User.objects.create_user(\n+            username=\"both_perms\", password=\"secret\", is_staff=True\n+        )\n+        user_with_both.user_permissions.add(person_add_perm, person_change_perm)\n+\n+        user_with_change_only = User.objects.create_user(\n+            username=\"change_only\", password=\"secret\", is_staff=True\n+        )\n+        user_with_change_only.user_permissions.add(person_change_perm)\n+\n+        user_with_add_only = User.objects.create_user(\n+            username=\"add_only\", password=\"secret\", is_staff=True\n+        )\n+        user_with_add_only.user_permissions.add(person_add_perm)\n+\n+        # User with both add and change permissions should see the button\n+        self.client.force_login(user_with_both)\n+        response = self.client.get(person_change_url)\n+        self.assertTrue(response.context[\"show_save_as_new\"])\n+        self.assertContains(response, 'value=\"Save as new\"')\n+\n+        # User with only change permission should NOT see the button\n+        self.client.force_login(user_with_change_only)\n+        response = self.client.get(person_change_url)\n+        self.assertFalse(response.context[\"show_save_as_new\"])\n+        self.assertNotContains(response, 'value=\"Save as new\"')\n+\n+        # User with only add permission should NOT see the button\n+        # (because they can't access the change form)\n+        self.client.force_login(user_with_add_only)\n+        response = self.client.get(person_change_url)\n+        self.assertEqual(response.status_code, 403)\n+\n     def test_change_view_with_view_only_inlines(self):\n         \"\"\"\n         User with change permission to a section but view-only for inlines.\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "sphinx-doc__sphinx-8721", "model_patch": "diff --git a/sphinx/ext/viewcode.py b/sphinx/ext/viewcode.py\nindex a7d52a91c..060604e25 100644\n--- a/sphinx/ext/viewcode.py\n+++ b/sphinx/ext/viewcode.py\n@@ -182,6 +182,8 @@ def collect_pages(app: Sphinx) -> Generator[Tuple[str, Dict[str, Any], str], Non\n     env = app.builder.env\n     if not hasattr(env, '_viewcode_modules'):\n         return\n+    if app.builder.name.startswith(\"epub\") and not env.config.viewcode_enable_epub:\n+        return\n     highlighter = app.builder.highlighter  # type: ignore\n     urito = app.builder.get_relative_uri\n \ndiff --git a/tests/test_ext_viewcode.py b/tests/test_ext_viewcode.py\nindex 79864095b..0fda34567 100644\n--- a/tests/test_ext_viewcode.py\n+++ b/tests/test_ext_viewcode.py\n@@ -102,3 +102,17 @@ def test_local_source_files(app, status, warning):\n \n     assert result.count('href=\"_modules/not_a_package/submodule.html#not_a_package.submodule.Class3.class_attr\"') == 1\n     assert result.count('This is the class attribute class_attr') == 1\n+\n+\n+@pytest.mark.sphinx('epub', testroot='ext-viewcode', \n+                   confoverrides={'viewcode_enable_epub': False})\n+def test_viewcode_epub_disabled(app, status, warning):\n+    \"\"\"Test that viewcode does not create pages for epub when disabled.\"\"\"\n+    app.builder.build_all()\n+    \n+    # Check that no _modules directory was created\n+    modules_dir = app.outdir / \"_modules\"\n+    assert not modules_dir.exists(), f\"_modules directory should not exist when viewcode_enable_epub=False, but found: {modules_dir}\"\n+\n+\n+\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "sympy__sympy-17655", "model_patch": "diff --git a/sympy/core/numbers.py b/sympy/core/numbers.py\nindex c82993e2b0..4331b4cb21 100644\n--- a/sympy/core/numbers.py\n+++ b/sympy/core/numbers.py\n@@ -1310,6 +1310,9 @@ def __mul__(self, other):\n         if isinstance(other, Number) and global_evaluate[0]:\n             rhs, prec = other._as_mpf_op(self._prec)\n             return Float._new(mlib.mpf_mul(self._mpf_, rhs, prec, rnd), prec)\n+        # Return NotImplemented for Point objects to allow Point.__rmul__ to handle it\n+        if hasattr(other, 'is_Point') and other.is_Point:\n+            return NotImplemented\n         return Number.__mul__(self, other)\n \n     @_sympifyit('other', NotImplemented)\n@@ -1744,6 +1747,9 @@ def __mul__(self, other):\n                 return Rational(self.p*other.p, self.q*other.q, igcd(self.p, other.q)*igcd(self.q, other.p))\n             elif isinstance(other, Float):\n                 return other*self\n+            # Return NotImplemented for Point objects to allow Point.__rmul__ to handle it\n+            elif hasattr(other, 'is_Point') and other.is_Point:\n+                return NotImplemented\n             else:\n                 return Number.__mul__(self, other)\n         return Number.__mul__(self, other)\n@@ -2210,6 +2216,9 @@ def __mul__(self, other):\n                 return Integer(self.p*other.p)\n             elif isinstance(other, Rational):\n                 return Rational(self.p*other.p, other.q, igcd(self.p, other.q))\n+            # Return NotImplemented for Point objects to allow Point.__rmul__ to handle it\n+            elif hasattr(other, 'is_Point') and other.is_Point:\n+                return NotImplemented\n             return Rational.__mul__(self, other)\n         return Rational.__mul__(self, other)\n \n@@ -2219,6 +2228,9 @@ def __rmul__(self, other):\n                 return Integer(other*self.p)\n             elif isinstance(other, Rational):\n                 return Rational(other.p*self.p, other.q, igcd(self.p, other.q))\n+            # Return NotImplemented for Point objects to allow Point.__rmul__ to handle it\n+            elif hasattr(other, 'is_Point') and other.is_Point:\n+                return NotImplemented\n             return Rational.__rmul__(self, other)\n         return Rational.__rmul__(self, other)\n \ndiff --git a/sympy/geometry/point.py b/sympy/geometry/point.py\nindex 7c978c47be..43fcb776ba 100644\n--- a/sympy/geometry/point.py\n+++ b/sympy/geometry/point.py\n@@ -278,6 +278,13 @@ def __mul__(self, factor):\n         coords = [simplify(x*factor) for x in self.args]\n         return Point(coords, evaluate=False)\n \n+    def __rmul__(self, factor):\n+        \"\"\"Multiply point's coordinates by a factor (reverse multiplication).\n+        \n+        This method handles cases like `2 * point` by delegating to `__mul__`.\n+        \"\"\"\n+        return self.__mul__(factor)\n+\n     def __neg__(self):\n         \"\"\"Negate the point.\"\"\"\n         coords = [-x for x in self.args]\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "django__django-11964", "model_patch": "diff --git a/django/db/models/enums.py b/django/db/models/enums.py\nindex bbe362a6ab..05897976f0 100644\n--- a/django/db/models/enums.py\n+++ b/django/db/models/enums.py\n@@ -65,11 +65,16 @@ class Choices(enum.Enum, metaclass=ChoicesMeta):\n \n class IntegerChoices(int, Choices):\n     \"\"\"Class for creating enumerated integer choices.\"\"\"\n-    pass\n+    \n+    def __str__(self):\n+        return str(self.value)\n \n \n class TextChoices(str, Choices):\n     \"\"\"Class for creating enumerated string choices.\"\"\"\n \n+    def __str__(self):\n+        return str(self.value)\n+\n     def _generate_next_value_(name, start, count, last_values):\n         return name\ndiff --git a/tests/model_enums/tests.py b/tests/model_enums/tests.py\nindex 6b4bd6e7fd..0d9b5a384f 100644\n--- a/tests/model_enums/tests.py\n+++ b/tests/model_enums/tests.py\n@@ -80,6 +80,21 @@ class ChoicesTests(SimpleTestCase):\n         self.assertIn(1, Suit)\n         self.assertNotIn(0, Suit)\n \n+    def test_integerchoices_str_returns_value(self):\n+        \"\"\"Test that str() of IntegerChoices returns the string representation of the enum value.\"\"\"\n+        self.assertEqual(str(Suit.DIAMOND), '1')\n+        self.assertEqual(str(Suit.SPADE), '2')\n+        self.assertEqual(str(Vehicle.CAR), '1')\n+        self.assertEqual(str(Vehicle.TRUCK), '2')\n+        \n+        # Test with zero value\n+        class ZeroChoice(models.IntegerChoices):\n+            ZERO = 0, 'Zero'\n+            ONE = 1, 'One'\n+        \n+        self.assertEqual(str(ZeroChoice.ZERO), '0')\n+        self.assertEqual(str(ZeroChoice.ONE), '1')\n+\n     def test_textchoices(self):\n         self.assertEqual(YearInSchool.choices, [\n             ('FR', 'Freshman'), ('SO', 'Sophomore'), ('JR', 'Junior'), ('SR', 'Senior'), ('GR', 'Graduate'),\n@@ -121,6 +136,21 @@ class ChoicesTests(SimpleTestCase):\n         self.assertIn('FR', YearInSchool)\n         self.assertNotIn('XX', YearInSchool)\n \n+    def test_textchoices_str_returns_value(self):\n+        \"\"\"Test that str() of TextChoices returns the enum value, not the enum name.\"\"\"\n+        self.assertEqual(str(YearInSchool.FRESHMAN), 'FR')\n+        self.assertEqual(str(YearInSchool.SOPHOMORE), 'SO')\n+        self.assertEqual(str(Gender.MALE), 'M')\n+        self.assertEqual(str(Gender.FEMALE), 'F')\n+        \n+        # Test with empty string value\n+        class BlankStr(models.TextChoices):\n+            EMPTY = '', '(Empty)'\n+            ONE = 'ONE', 'One'\n+        \n+        self.assertEqual(str(BlankStr.EMPTY), '')\n+        self.assertEqual(str(BlankStr.ONE), 'ONE')\n+\n     def test_textchoices_blank_value(self):\n         class BlankStr(models.TextChoices):\n             EMPTY = '', '(Empty)'\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "pytest-dev__pytest-7432", "model_patch": "diff --git a/src/_pytest/skipping.py b/src/_pytest/skipping.py\nindex 7bd975e5a..85778415b 100644\n--- a/src/_pytest/skipping.py\n+++ b/src/_pytest/skipping.py\n@@ -291,7 +291,9 @@ def pytest_runtest_makereport(item: Item, call: CallInfo[None]):\n             else:\n                 rep.outcome = \"passed\"\n                 rep.wasxfail = xfailed.reason\n-    elif (\n+    \n+    # Fix skip location reporting regardless of runxfail option\n+    if (\n         item._store.get(skipped_by_mark_key, True)\n         and rep.skipped\n         and type(rep.longrepr) is tuple\ndiff --git a/testing/test_skipping.py b/testing/test_skipping.py\nindex 0b1c0b49b..e29002550 100644\n--- a/testing/test_skipping.py\n+++ b/testing/test_skipping.py\n@@ -648,6 +648,37 @@ class TestSkip:\n         result = testdir.runpytest(\"-rs\")\n         result.stdout.fnmatch_lines([\"*unconditional skip*\", \"*1 skipped*\"])\n \n+    def test_skip_location_with_runxfail(self, testdir):\n+        \"\"\"Test that skip location reporting works correctly with --runxfail.\"\"\"\n+        p = testdir.makepyfile(\n+            \"\"\"\n+            import pytest\n+            @pytest.mark.skip\n+            def test_skip_location():\n+                assert 0\n+            \n+            @pytest.mark.skipif(True, reason=\"skipif test\")\n+            def test_skipif_location():\n+                assert 0\n+        \"\"\"\n+        )\n+        \n+        # Test without --runxfail (should work correctly)\n+        result = testdir.runpytest(p, \"-rs\")\n+        result.stdout.fnmatch_lines([\n+            \"*test_skip_location_with_runxfail.py:2: unconditional skip*\",\n+            \"*test_skip_location_with_runxfail.py:6: skipif test*\"\n+        ])\n+        \n+        # Test with --runxfail (this was broken before the fix)\n+        result = testdir.runpytest(p, \"-rs\", \"--runxfail\")\n+        result.stdout.fnmatch_lines([\n+            \"*test_skip_location_with_runxfail.py:2: unconditional skip*\",\n+            \"*test_skip_location_with_runxfail.py:6: skipif test*\"\n+        ])\n+        # Ensure it doesn't show the internal pytest location\n+        assert \"src/_pytest/skipping.py\" not in result.stdout.str()\n+\n \n class TestSkipif:\n     def test_skipif_conditional(self, testdir):\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "django__django-13551", "model_patch": "diff --git a/django/contrib/auth/tokens.py b/django/contrib/auth/tokens.py\nindex 93e2d71af2..bdabb1ea2e 100644\n--- a/django/contrib/auth/tokens.py\n+++ b/django/contrib/auth/tokens.py\n@@ -78,13 +78,14 @@ class PasswordResetTokenGenerator:\n \n     def _make_hash_value(self, user, timestamp):\n         \"\"\"\n-        Hash the user's primary key and some user state that's sure to change\n+        Hash the user's primary key, email, and some user state that's sure to change\n         after a password reset to produce a token that invalidated when it's\n         used:\n         1. The password field will change upon a password reset (even if the\n            same password is chosen, due to password salting).\n         2. The last_login field will usually be updated very shortly after\n            a password reset.\n+        3. The email field will change upon an email change.\n         Failing those things, settings.PASSWORD_RESET_TIMEOUT eventually\n         invalidates the token.\n \n@@ -94,7 +95,8 @@ class PasswordResetTokenGenerator:\n         # Truncate microseconds so that tokens are consistent even if the\n         # database doesn't support microseconds.\n         login_timestamp = '' if user.last_login is None else user.last_login.replace(microsecond=0, tzinfo=None)\n-        return str(user.pk) + user.password + str(login_timestamp) + str(timestamp)\n+        email = getattr(user, user.get_email_field_name(), '') or ''\n+        return str(user.pk) + user.password + str(login_timestamp) + str(timestamp) + email\n \n     def _num_seconds(self, dt):\n         return int((dt - datetime(2001, 1, 1)).total_seconds())\ndiff --git a/tests/auth_tests/test_tokens.py b/tests/auth_tests/test_tokens.py\nindex bba435be84..680e67f497 100644\n--- a/tests/auth_tests/test_tokens.py\n+++ b/tests/auth_tests/test_tokens.py\n@@ -110,3 +110,40 @@ class TokenGeneratorTest(TestCase):\n         legacy_token = p_old_generator.make_token(user)\n         self.assertIs(p_old_generator.check_token(user, legacy_token), True)\n         self.assertIs(p_new_generator.check_token(user, legacy_token), True)\n+\n+    def test_token_invalidated_by_email_change(self):\n+        \"\"\"\n+        Password reset tokens should be invalidated when the user's email\n+        address changes.\n+        \"\"\"\n+        user = User.objects.create_user('tokentestuser', 'test@example.com', 'testpw')\n+        p0 = PasswordResetTokenGenerator()\n+        tk1 = p0.make_token(user)\n+        \n+        # Token should be valid before email change\n+        self.assertIs(p0.check_token(user, tk1), True)\n+        \n+        # Change email address\n+        user.email = 'changed@example.com'\n+        user.save()\n+        \n+        # Token should be invalid after email change\n+        self.assertIs(p0.check_token(user, tk1), False)\n+\n+    def test_token_with_no_email(self):\n+        \"\"\"\n+        Password reset tokens should work for users without email addresses.\n+        \"\"\"\n+        user = User.objects.create_user('tokentestuser', '', 'testpw')\n+        p0 = PasswordResetTokenGenerator()\n+        tk1 = p0.make_token(user)\n+        \n+        # Token should be valid\n+        self.assertIs(p0.check_token(user, tk1), True)\n+        \n+        # Setting email should invalidate token\n+        user.email = 'new@example.com'\n+        user.save()\n+        \n+        # Token should be invalid after setting email\n+        self.assertIs(p0.check_token(user, tk1), False)\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "django__django-13158", "model_patch": "diff --git a/django/db/models/sql/compiler.py b/django/db/models/sql/compiler.py\nindex 686e75c979..0c5e4ac584 100644\n--- a/django/db/models/sql/compiler.py\n+++ b/django/db/models/sql/compiler.py\n@@ -432,6 +432,10 @@ class SQLCompiler:\n \n     def get_combinator_sql(self, combinator, all):\n         features = self.connection.features\n+        # If this query was set to empty (e.g., by calling none()), then\n+        # we should return an empty result regardless of the combined queries.\n+        if self.query.is_empty():\n+            raise EmptyResultSet\n         compilers = [\n             query.get_compiler(self.using, self.connection)\n             for query in self.query.combined_queries if not query.is_empty()\ndiff --git a/tests/queries/test_qs_combinators.py b/tests/queries/test_qs_combinators.py\nindex 9c6fd474ca..e73a704def 100644\n--- a/tests/queries/test_qs_combinators.py\n+++ b/tests/queries/test_qs_combinators.py\n@@ -2,6 +2,7 @@ import operator\n \n from django.db import DatabaseError, NotSupportedError, connection\n from django.db.models import Exists, F, IntegerField, OuterRef, Value\n+from django.db.models.query import EmptyQuerySet\n from django.test import TestCase, skipIfDBFeature, skipUnlessDBFeature\n \n from .models import Number, ReservedName\n@@ -314,3 +315,50 @@ class QuerySetSetOperationTests(TestCase):\n                         msg % (operation, combinator),\n                     ):\n                         getattr(getattr(qs, combinator)(qs), operation)()\n+\n+    def test_none_on_union(self):\n+        \"\"\"Test that calling none() on a union queryset returns an empty result.\"\"\"\n+        qs1 = Number.objects.filter(num__lte=1)\n+        qs2 = Number.objects.filter(num__gte=8)\n+        union_qs = qs1.union(qs2)\n+        \n+        # Verify union has results\n+        self.assertEqual(union_qs.count(), 4)  # 0, 1, 8, 9\n+        \n+        # Verify none() returns empty queryset\n+        none_qs = union_qs.none()\n+        self.assertEqual(list(none_qs), [])\n+        self.assertEqual(none_qs.count(), 0)\n+        self.assertTrue(isinstance(none_qs, EmptyQuerySet))\n+\n+    @skipUnlessDBFeature('supports_select_intersection')\n+    def test_none_on_intersection(self):\n+        \"\"\"Test that calling none() on an intersection queryset returns an empty result.\"\"\"\n+        qs1 = Number.objects.filter(num__lte=5)\n+        qs2 = Number.objects.filter(num__gte=3)\n+        intersection_qs = qs1.intersection(qs2)\n+        \n+        # Verify intersection has results\n+        self.assertEqual(intersection_qs.count(), 3)  # 3, 4, 5\n+        \n+        # Verify none() returns empty queryset\n+        none_qs = intersection_qs.none()\n+        self.assertEqual(list(none_qs), [])\n+        self.assertEqual(none_qs.count(), 0)\n+        self.assertTrue(isinstance(none_qs, EmptyQuerySet))\n+\n+    @skipUnlessDBFeature('supports_select_difference')\n+    def test_none_on_difference(self):\n+        \"\"\"Test that calling none() on a difference queryset returns an empty result.\"\"\"\n+        qs1 = Number.objects.filter(num__lte=5)\n+        qs2 = Number.objects.filter(num__gte=3)\n+        difference_qs = qs1.difference(qs2)\n+        \n+        # Verify difference has results\n+        self.assertEqual(difference_qs.count(), 3)  # 0, 1, 2\n+        \n+        # Verify none() returns empty queryset\n+        none_qs = difference_qs.none()\n+        self.assertEqual(list(none_qs), [])\n+        self.assertEqual(none_qs.count(), 0)\n+        self.assertTrue(isinstance(none_qs, EmptyQuerySet))\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "sympy__sympy-24213", "model_patch": "diff --git a/sympy/physics/units/tests/test_quantities.py b/sympy/physics/units/tests/test_quantities.py\nindex c1830ba5f7..d7323be236 100644\n--- a/sympy/physics/units/tests/test_quantities.py\n+++ b/sympy/physics/units/tests/test_quantities.py\n@@ -377,6 +377,66 @@ def test_factor_and_dimension():\n         assert (3000, Dimension(1)) == Quantity._collect_factor_and_dimension(3000)\n \n \n+def test_collect_factor_and_dimension_equivalent_dims():\n+    \"\"\"Test that _collect_factor_and_dimension handles equivalent dimensions correctly.\"\"\"\n+    from sympy.physics.units import velocity, acceleration, time, force, mass\n+    \n+    # Test the original issue: acceleration*time + velocity should work\n+    v_equiv = Quantity('v_equiv')\n+    SI.set_quantity_dimension(v_equiv, velocity)\n+    SI.set_quantity_scale_factor(v_equiv, 2 * meter / second)\n+    \n+    a_equiv = Quantity('a_equiv')\n+    SI.set_quantity_dimension(a_equiv, acceleration)\n+    SI.set_quantity_scale_factor(a_equiv, -9.8 * meter / second**2)\n+    \n+    t_equiv = Quantity('t_equiv')\n+    SI.set_quantity_dimension(t_equiv, time)\n+    SI.set_quantity_scale_factor(t_equiv, 5 * second)\n+    \n+    # This should work: acceleration*time + velocity are equivalent dimensions\n+    expr1 = a_equiv*t_equiv + v_equiv\n+    factor, dimension = SI._collect_factor_and_dimension(expr1)\n+    \n+    # Check that we get the expected result\n+    # Factor should be: a_equiv_factor * t_equiv_factor + v_equiv_factor = -9.8 * 5 + 2 = -47\n+    assert abs(float(factor) - (-47.0)) < 1e-10\n+    \n+    # The dimension should be equivalent to velocity\n+    assert SI.get_dimension_system().equivalent_dims(dimension, velocity)\n+    \n+    # Test force + mass*acceleration (should work)\n+    f_equiv = Quantity('f_equiv')\n+    SI.set_quantity_dimension(f_equiv, force)\n+    SI.set_quantity_scale_factor(f_equiv, 10 * kilogram * meter / second**2)\n+    \n+    m_equiv = Quantity('m_equiv')\n+    SI.set_quantity_dimension(m_equiv, mass)\n+    SI.set_quantity_scale_factor(m_equiv, 2 * kilogram)\n+    \n+    a2_equiv = Quantity('a2_equiv')\n+    SI.set_quantity_dimension(a2_equiv, acceleration)\n+    SI.set_quantity_scale_factor(a2_equiv, 5 * meter / second**2)\n+    \n+    # This should work: force and mass*acceleration are equivalent\n+    expr2 = f_equiv + m_equiv*a2_equiv\n+    factor2, dimension2 = SI._collect_factor_and_dimension(expr2)\n+    \n+    # Factor should be: 10*1000 + 2*1000*5 = 10000 + 10000 = 20000 (in base SI units)\n+    assert abs(float(factor2) - 20000.0) < 1e-10\n+    \n+    # The dimension should be equivalent to force\n+    assert SI.get_dimension_system().equivalent_dims(dimension2, force)\n+    \n+    # Test that non-equivalent dimensions still raise errors\n+    mass_equiv = Quantity('mass_equiv')\n+    SI.set_quantity_dimension(mass_equiv, mass)\n+    SI.set_quantity_scale_factor(mass_equiv, 3 * kilogram)\n+    \n+    # This should still raise an error: velocity + mass are not equivalent\n+    raises(ValueError, lambda: SI._collect_factor_and_dimension(v_equiv + mass_equiv))\n+\n+\n @XFAIL\n def test_factor_and_dimension_with_Abs():\n     with warns_deprecated_sympy():\ndiff --git a/sympy/physics/units/unitsystem.py b/sympy/physics/units/unitsystem.py\nindex a436880c4b..5705c821c2 100644\n--- a/sympy/physics/units/unitsystem.py\n+++ b/sympy/physics/units/unitsystem.py\n@@ -175,7 +175,7 @@ def _collect_factor_and_dimension(self, expr):\n             for addend in expr.args[1:]:\n                 addend_factor, addend_dim = \\\n                     self._collect_factor_and_dimension(addend)\n-                if dim != addend_dim:\n+                if not self.get_dimension_system().equivalent_dims(dim, addend_dim):\n                     raise ValueError(\n                         'Dimension of \"{}\" is {}, '\n                         'but it should be {}'.format(\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "django__django-13315", "model_patch": "diff --git a/django/forms/models.py b/django/forms/models.py\nindex 5d115458a1..f993bb9c98 100644\n--- a/django/forms/models.py\n+++ b/django/forms/models.py\n@@ -100,7 +100,7 @@ def apply_limit_choices_to_to_formfield(formfield):\n     if hasattr(formfield, 'queryset') and hasattr(formfield, 'get_limit_choices_to'):\n         limit_choices_to = formfield.get_limit_choices_to()\n         if limit_choices_to is not None:\n-            formfield.queryset = formfield.queryset.complex_filter(limit_choices_to)\n+            formfield.queryset = formfield.queryset.complex_filter(limit_choices_to).distinct()\n \n \n def fields_for_model(model, fields=None, exclude=None, widgets=None,\ndiff --git a/tests/model_forms/models.py b/tests/model_forms/models.py\nindex 1a2102f898..1fbbd691d1 100644\n--- a/tests/model_forms/models.py\n+++ b/tests/model_forms/models.py\n@@ -422,11 +422,61 @@ class Student(models.Model):\n     study = models.CharField(max_length=30)\n \n \n+\n+\n+\n # Model for #639\n class Photo(models.Model):\n     title = models.CharField(max_length=30)\n     image = models.FileField(storage=temp_storage, upload_to='tests')\n \n+\n+# Models for testing duplicate choices issue with limit_choices_to and Q objects\n+class TestWriter(models.Model):\n+    name = models.CharField(max_length=100)\n+    is_active = models.BooleanField(default=True)\n+\n+    def __str__(self):\n+        return self.name\n+\n+\n+class TestNovel(models.Model):\n+    title = models.CharField(max_length=200)\n+    writer = models.ForeignKey(TestWriter, models.CASCADE)\n+    is_available = models.BooleanField(default=True)\n+\n+    def __str__(self):\n+        return self.title\n+\n+\n+class TestLabel(models.Model):\n+    name = models.CharField(max_length=50)\n+    is_active = models.BooleanField(default=True)\n+\n+    def __str__(self):\n+        return self.name\n+\n+\n+class TestNovelLabel(models.Model):\n+    \"\"\"Many-to-many through model to create more complex joins\"\"\"\n+    novel = models.ForeignKey(TestNovel, models.CASCADE)\n+    label = models.ForeignKey(TestLabel, models.CASCADE)\n+\n+\n+class TestBookReview(models.Model):\n+    novel = models.ForeignKey(\n+        TestNovel, \n+        models.CASCADE,\n+        # This Q object involves joins that may cause duplicate options\n+        # Using OR condition which might cause the same book to appear multiple times\n+        limit_choices_to=models.Q(writer__is_active=True) | models.Q(testnovellabel__label__is_active=True)\n+    )\n+    rating = models.IntegerField()\n+    comment = models.TextField()\n+\n+    def __str__(self):\n+        return f\"Review for {self.novel.title}\"\n+\n     # Support code for the tests; this keeps track of how many times save()\n     # gets called on each instance.\n     def __init__(self, *args, **kwargs):\ndiff --git a/tests/model_forms/tests.py b/tests/model_forms/tests.py\nindex 9e900e35f4..5fbd60cd29 100644\n--- a/tests/model_forms/tests.py\n+++ b/tests/model_forms/tests.py\n@@ -2829,6 +2829,80 @@ class LimitChoicesToTests(TestCase):\n             StumpJokeForm()\n             self.assertEqual(today_callable_dict.call_count, 3)\n \n+    def test_limit_choices_to_q_object_with_joins_no_duplicates(self):\n+        \"\"\"\n+        Test that limit_choices_to with Q objects involving joins doesn't \n+        produce duplicate options in form fields.\n+        \"\"\"\n+        from .models import TestWriter, TestNovel, TestLabel, TestNovelLabel, TestBookReview\n+        from django import forms\n+        \n+        # Create test data\n+        writer1 = TestWriter.objects.create(name=\"Active Writer\", is_active=True)\n+        writer2 = TestWriter.objects.create(name=\"Inactive Writer\", is_active=False)\n+        \n+        label1 = TestLabel.objects.create(name=\"Active Label 1\", is_active=True)\n+        label2 = TestLabel.objects.create(name=\"Active Label 2\", is_active=True)\n+        label3 = TestLabel.objects.create(name=\"Inactive Label\", is_active=False)\n+        \n+        # Create novels\n+        novel1 = TestNovel.objects.create(title=\"Novel 1\", writer=writer1)  # Should match both conditions\n+        novel2 = TestNovel.objects.create(title=\"Novel 2\", writer=writer2)  # Should match only label condition\n+        novel3 = TestNovel.objects.create(title=\"Novel 3\", writer=writer1)  # Should match both conditions\n+        novel4 = TestNovel.objects.create(title=\"Novel 4\", writer=writer2)  # Should not match any condition\n+        \n+        # Create novel-label relationships\n+        # Novel 1 has multiple active labels - this would cause duplicates without distinct()\n+        TestNovelLabel.objects.create(novel=novel1, label=label1)\n+        TestNovelLabel.objects.create(novel=novel1, label=label2)\n+        \n+        # Novel 2 has one active label\n+        TestNovelLabel.objects.create(novel=novel2, label=label1)\n+        \n+        # Novel 3 has one inactive label but active writer\n+        TestNovelLabel.objects.create(novel=novel3, label=label3)\n+        \n+        # Novel 4 has no labels\n+        \n+        # Create form and test choices\n+        class ReviewForm(forms.ModelForm):\n+            class Meta:\n+                model = TestBookReview\n+                fields = ['novel', 'rating', 'comment']\n+        \n+        form = ReviewForm()\n+        novel_field = form.fields['novel']\n+        \n+        # Get the choices and check for duplicates\n+        choices = list(novel_field.choices)\n+        choice_values = []\n+        for choice in choices:\n+            if choice[0] != '':  # Skip empty choice\n+                # Extract the actual value from ModelChoiceIteratorValue\n+                if hasattr(choice[0], 'value'):\n+                    choice_values.append(choice[0].value)\n+                else:\n+                    choice_values.append(choice[0])\n+        \n+        # Check that there are no duplicates\n+        unique_values = set(choice_values)\n+        self.assertEqual(\n+            len(choice_values), \n+            len(unique_values),\n+            f\"Duplicate choices found: {choice_values}. Expected unique values: {list(unique_values)}\"\n+        )\n+        \n+        # Verify that the expected novels are included\n+        expected_novels = {novel1.pk, novel2.pk, novel3.pk}  # novel4 should be excluded\n+        actual_novels = set(choice_values)\n+        self.assertEqual(actual_novels, expected_novels)\n+        \n+        # Verify that the queryset uses DISTINCT\n+        queryset_sql = str(novel_field.queryset.query)\n+        self.assertIn('DISTINCT', queryset_sql.upper())\n+\n+\n+\n \n class FormFieldCallbackTests(SimpleTestCase):\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "scikit-learn__scikit-learn-13142", "model_patch": "diff --git a/sklearn/mixture/base.py b/sklearn/mixture/base.py\nindex bd34333c0..8920bef18 100644\n--- a/sklearn/mixture/base.py\n+++ b/sklearn/mixture/base.py\n@@ -257,11 +257,6 @@ class BaseMixture(DensityMixin, BaseEstimator, metaclass=ABCMeta):\n                 best_params = self._get_parameters()\n                 best_n_iter = n_iter\n \n-        # Always do a final e-step to guarantee that the labels returned by\n-        # fit_predict(X) are always consistent with fit(X).predict(X)\n-        # for any value of max_iter and tol (and any random_state).\n-        _, log_resp = self._e_step(X)\n-\n         if not self.converged_:\n             warnings.warn('Initialization %d did not converge. '\n                           'Try different init parameters, '\n@@ -273,6 +268,11 @@ class BaseMixture(DensityMixin, BaseEstimator, metaclass=ABCMeta):\n         self.n_iter_ = best_n_iter\n         self.lower_bound_ = max_lower_bound\n \n+        # Always do a final e-step to guarantee that the labels returned by\n+        # fit_predict(X) are always consistent with fit(X).predict(X)\n+        # for any value of max_iter and tol (and any random_state).\n+        _, log_resp = self._e_step(X)\n+\n         return log_resp.argmax(axis=1)\n \n     def _e_step(self, X):\ndiff --git a/sklearn/mixture/tests/test_bayesian_mixture.py b/sklearn/mixture/tests/test_bayesian_mixture.py\nindex c3503a632..eb2d18d54 100644\n--- a/sklearn/mixture/tests/test_bayesian_mixture.py\n+++ b/sklearn/mixture/tests/test_bayesian_mixture.py\n@@ -451,6 +451,17 @@ def test_bayesian_mixture_fit_predict(seed, max_iter, tol):\n         assert_array_equal(Y_pred1, Y_pred2)\n \n \n+def test_bayesian_mixture_fit_predict_n_init():\n+    # Check that fit_predict is equivalent to fit.predict when n_init > 1\n+    # This is a regression test for issue where fit_predict and predict\n+    # disagreed when n_init > 1 due to final e-step using wrong parameters\n+    X = np.random.RandomState(0).randn(1000, 5)\n+    bgmm = BayesianGaussianMixture(n_components=5, n_init=5, random_state=0)\n+    y_pred1 = bgmm.fit_predict(X)\n+    y_pred2 = bgmm.predict(X)\n+    assert_array_equal(y_pred1, y_pred2)\n+\n+\n def test_bayesian_mixture_predict_predict_proba():\n     # this is the same test as test_gaussian_mixture_predict_predict_proba()\n     rng = np.random.RandomState(0)\ndiff --git a/sklearn/mixture/tests/test_gaussian_mixture.py b/sklearn/mixture/tests/test_gaussian_mixture.py\nindex 4d549ccd7..faf2bbcfe 100644\n--- a/sklearn/mixture/tests/test_gaussian_mixture.py\n+++ b/sklearn/mixture/tests/test_gaussian_mixture.py\n@@ -598,6 +598,17 @@ def test_gaussian_mixture_fit_predict(seed, max_iter, tol):\n         assert_greater(adjusted_rand_score(Y, Y_pred2), .95)\n \n \n+def test_gaussian_mixture_fit_predict_n_init():\n+    # Check that fit_predict is equivalent to fit.predict when n_init > 1\n+    # This is a regression test for issue where fit_predict and predict\n+    # disagreed when n_init > 1 due to final e-step using wrong parameters\n+    X = np.random.RandomState(0).randn(1000, 5)\n+    gm = GaussianMixture(n_components=5, n_init=5, random_state=0)\n+    y_pred1 = gm.fit_predict(X)\n+    y_pred2 = gm.predict(X)\n+    assert_array_equal(y_pred1, y_pred2)\n+\n+\n def test_gaussian_mixture_fit():\n     # recover the ground truth\n     rng = np.random.RandomState(0)\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "sympy__sympy-20590", "model_patch": "diff --git a/sympy/core/_print_helpers.py b/sympy/core/_print_helpers.py\nindex 96d7e72676..e4f1c3352a 100644\n--- a/sympy/core/_print_helpers.py\n+++ b/sympy/core/_print_helpers.py\n@@ -17,6 +17,9 @@ class Printable:\n     This also adds support for LaTeX printing in jupyter notebooks.\n     \"\"\"\n \n+    __slots__ = ()\n+    __slots__ = ()\n+\n     # Note, we always use the default ordering (lex) in __str__ and __repr__,\n     # regardless of the global setting. See issue 5487.\n     def __str__(self):\ndiff --git a/sympy/core/tests/test_symbol.py b/sympy/core/tests/test_symbol.py\nindex a07a1d2f36..fbcf2361eb 100644\n--- a/sympy/core/tests/test_symbol.py\n+++ b/sympy/core/tests/test_symbol.py\n@@ -387,3 +387,17 @@ def test_disambiguate():\n     assert disambiguate(*t7) == (y*y_1, y_1)\n     assert disambiguate(Dummy('x_1'), Dummy('x_1')\n         ) == (x_1, Symbol('x_1_1'))\n+\n+\n+def test_symbol_no_dict():\n+    \"\"\"Test that Symbol instances do not have __dict__ when using __slots__.\"\"\"\n+    # This is a regression test for issue where Symbol instances\n+    # incorrectly had __dict__ due to missing __slots__ in parent classes\n+    s = Symbol('s')\n+    \n+    # Symbol should not have __dict__ when using __slots__\n+    raises(AttributeError, lambda: s.__dict__)\n+    \n+    # Verify that Symbol still has __slots__\n+    assert hasattr(s, '__slots__')\n+    assert s.__slots__ == ('name',)\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "matplotlib__matplotlib-23299", "model_patch": "diff --git a/lib/matplotlib/pyplot.py b/lib/matplotlib/pyplot.py\nindex e3c66ea67c..82551cd461 100644\n--- a/lib/matplotlib/pyplot.py\n+++ b/lib/matplotlib/pyplot.py\n@@ -206,7 +206,7 @@ def _get_backend_mod():\n     return _backend_mod\n \n \n-def switch_backend(newbackend):\n+def switch_backend(newbackend, *, _close_figures=True):\n     \"\"\"\n     Close all open figures and set the Matplotlib backend.\n \n@@ -222,7 +222,11 @@ def switch_backend(newbackend):\n     global _backend_mod\n     # make sure the init is pulled up so we can assign to it later\n     import matplotlib.backends\n-    close(\"all\")\n+    \n+    # Only close figures if explicitly requested (default behavior)\n+    # or if we're not resolving the auto backend sentinel\n+    if _close_figures and newbackend is not rcsetup._auto_backend_sentinel:\n+        close(\"all\")\n \n     if newbackend is rcsetup._auto_backend_sentinel:\n         current_framework = cbook._get_running_interactive_framework()\n@@ -247,7 +251,7 @@ def switch_backend(newbackend):\n         # are of worse quality.\n         for candidate in candidates:\n             try:\n-                switch_backend(candidate)\n+                switch_backend(candidate, _close_figures=False)\n             except ImportError:\n                 continue\n             else:\n@@ -256,7 +260,7 @@ def switch_backend(newbackend):\n         else:\n             # Switching to Agg should always succeed; if it doesn't, let the\n             # exception propagate out.\n-            switch_backend(\"agg\")\n+            switch_backend(\"agg\", _close_figures=False)\n             rcParamsOrig[\"backend\"] = \"agg\"\n             return\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "sphinx-doc__sphinx-11445", "model_patch": "diff --git a/sphinx/util/rst.py b/sphinx/util/rst.py\nindex 7a1538325..621d94553 100644\n--- a/sphinx/util/rst.py\n+++ b/sphinx/util/rst.py\n@@ -25,7 +25,7 @@ except ImportError:\n \n logger = logging.getLogger(__name__)\n \n-docinfo_re = re.compile(':\\\\w+:.*?')\n+docinfo_re = re.compile(r':\\w+:\\s+.*')\n symbols_re = re.compile(r'([!-\\-/:-@\\[-`{-~])')  # symbols without dot(0x2e)\n SECTIONING_CHARS = ['=', '-', '~']\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "django__django-15814", "model_patch": "diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\nindex 33cc636b22..5036335bec 100644\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -748,7 +748,7 @@ class Query(BaseExpression):\n                     cur_model = source.related_model\n                 else:\n                     cur_model = source.remote_field.model\n-                opts = cur_model._meta\n+                opts = cur_model._meta.concrete_model._meta\n                 # Even if we're \"just passing through\" this model, we must add\n                 # both the current model's pk and the related reference field\n                 # (if it's not a reverse relation) to the things we select.\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "django__django-11999", "model_patch": "diff --git a/django/db/models/fields/__init__.py b/django/db/models/fields/__init__.py\nindex ee45bb941e..be243a5e5d 100644\n--- a/django/db/models/fields/__init__.py\n+++ b/django/db/models/fields/__init__.py\n@@ -763,8 +763,13 @@ class Field(RegisterLookupMixin):\n             if not getattr(cls, self.attname, None):\n                 setattr(cls, self.attname, self.descriptor_class(self))\n         if self.choices is not None:\n-            setattr(cls, 'get_%s_display' % self.name,\n-                    partialmethod(cls._get_FIELD_display, field=self))\n+            display_method_name = 'get_%s_display' % self.name\n+            # Check if the method already exists and is not a partialmethod\n+            existing_method = getattr(cls, display_method_name, None)\n+            if existing_method is None or isinstance(existing_method, partialmethod):\n+                # Only set if no custom method exists\n+                setattr(cls, display_method_name,\n+                        partialmethod(cls._get_FIELD_display, field=self))\n \n     def get_filter_kwargs_for_object(self, obj):\n         \"\"\"\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "django__django-13028", "model_patch": "diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\nindex ce18098fd2..697f22b3f0 100644\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -1124,7 +1124,8 @@ class Query(BaseExpression):\n \n     def check_filterable(self, expression):\n         \"\"\"Raise an error if expression cannot be used in a WHERE clause.\"\"\"\n-        if not getattr(expression, 'filterable', True):\n+        from django.db.models.expressions import BaseExpression\n+        if isinstance(expression, BaseExpression) and not expression.filterable:\n             raise NotSupportedError(\n                 expression.__class__.__name__ + ' is disallowed in the filter '\n                 'clause.'\ndiff --git a/tests/queries/models.py b/tests/queries/models.py\nindex 247d4b7671..ba22e0eeb1 100644\n--- a/tests/queries/models.py\n+++ b/tests/queries/models.py\n@@ -745,3 +745,16 @@ class JSONFieldNullable(models.Model):\n \n     class Meta:\n         required_db_features = {'supports_json_field'}\n+\n+\n+# Models for testing the filterable field regression\n+class FilterableFieldModel(models.Model):\n+    \"\"\"Model with a field named 'filterable' to test the regression.\"\"\"\n+    name = models.CharField(max_length=100)\n+    filterable = models.BooleanField(default=False)\n+\n+\n+class ReferencingFilterableModel(models.Model):\n+    \"\"\"Model that references FilterableFieldModel.\"\"\"\n+    name = models.CharField(max_length=100)\n+    ref = models.ForeignKey(FilterableFieldModel, models.CASCADE)\ndiff --git a/tests/queries/tests.py b/tests/queries/tests.py\nindex cd31453d08..871846b319 100644\n--- a/tests/queries/tests.py\n+++ b/tests/queries/tests.py\n@@ -20,13 +20,13 @@ from .models import (\n     CategoryRelationship, Celebrity, Channel, Chapter, Child, ChildObjectA,\n     Classroom, CommonMixedCaseForeignKeys, Company, Cover, CustomPk,\n     CustomPkTag, DateTimePK, Detail, DumbCategory, Eaten, Employment,\n-    ExtraInfo, Fan, Food, Identifier, Individual, Item, Job,\n+    ExtraInfo, Fan, FilterableFieldModel, Food, Identifier, Individual, Item, Job,\n     JobResponsibilities, Join, LeafA, LeafB, LoopX, LoopZ, ManagedModel,\n     Member, MixedCaseDbColumnCategoryItem, MixedCaseFieldCategoryItem, ModelA,\n     ModelB, ModelC, ModelD, MyObject, NamedCategory, Node, Note, NullableName,\n     Number, ObjectA, ObjectB, ObjectC, OneToOneCategory, Order, OrderItem,\n     Page, Paragraph, Person, Plaything, PointerA, Program, ProxyCategory,\n-    ProxyObjectA, ProxyObjectB, Ranking, Related, RelatedIndividual,\n+    ProxyObjectA, ProxyObjectB, Ranking, ReferencingFilterableModel, Related, RelatedIndividual,\n     RelatedObject, Report, ReportComment, ReservedName, Responsibility, School,\n     SharedConnection, SimpleCategory, SingleObject, SpecialCategory, Staff,\n     StaffUser, Student, Tag, Task, Teacher, Ticket21203Child,\n@@ -3973,4 +3973,60 @@ class Ticket23622Tests(TestCase):\n             set(Ticket23605A.objects.filter(qx).values_list('pk', flat=True)),\n             set(Ticket23605A.objects.filter(qy).values_list('pk', flat=True))\n         )\n-        self.assertSequenceEqual(Ticket23605A.objects.filter(qx), [a2])\n+\n+\n+class FilterableRegressionTests(TestCase):\n+    \"\"\"\n+    Test that model instances with 'filterable' fields can be used in queries.\n+    \n+    Regression test for issue where QuerySet raises NotSupportedError when RHS \n+    has filterable=False attribute.\n+    \"\"\"\n+    \n+    @classmethod\n+    def setUpTestData(cls):\n+        cls.filterable_false = FilterableFieldModel.objects.create(\n+            name=\"test_false\", filterable=False\n+        )\n+        cls.filterable_true = FilterableFieldModel.objects.create(\n+            name=\"test_true\", filterable=True\n+        )\n+        cls.ref1 = ReferencingFilterableModel.objects.create(\n+            name=\"ref1\", ref=cls.filterable_false\n+        )\n+        cls.ref2 = ReferencingFilterableModel.objects.create(\n+            name=\"ref2\", ref=cls.filterable_true\n+        )\n+    \n+    def test_filter_with_filterable_false_model(self):\n+        \"\"\"Model instances with filterable=False should work in filters.\"\"\"\n+        result = ReferencingFilterableModel.objects.filter(ref=self.filterable_false)\n+        self.assertEqual(result.count(), 1)\n+        self.assertEqual(result.first().name, \"ref1\")\n+    \n+    def test_filter_with_filterable_true_model(self):\n+        \"\"\"Model instances with filterable=True should work in filters.\"\"\"\n+        result = ReferencingFilterableModel.objects.filter(ref=self.filterable_true)\n+        self.assertEqual(result.count(), 1)\n+        self.assertEqual(result.first().name, \"ref2\")\n+    \n+    def test_filter_by_filterable_field_itself(self):\n+        \"\"\"Filtering by the 'filterable' field itself should work.\"\"\"\n+        result = FilterableFieldModel.objects.filter(filterable=False)\n+        self.assertEqual(result.count(), 1)\n+        self.assertEqual(result.first().name, \"test_false\")\n+        \n+        result = FilterableFieldModel.objects.filter(filterable=True)\n+        self.assertEqual(result.count(), 1)\n+        self.assertEqual(result.first().name, \"test_true\")\n+    \n+    def test_window_expressions_still_fail_in_where(self):\n+        \"\"\"Window expressions should still be rejected in WHERE clauses.\"\"\"\n+        from django.db.models import Window, F\n+        from django.db.models.functions import RowNumber\n+        from django.db.utils import NotSupportedError\n+        \n+        window_expr = Window(expression=RowNumber(), order_by=[F('name')])\n+        with self.assertRaises(NotSupportedError) as cm:\n+            list(FilterableFieldModel.objects.filter(id=window_expr))\n+        self.assertIn(\"disallowed in the filter clause\", str(cm.exception))\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "django__django-11848", "model_patch": "diff --git a/django/utils/http.py b/django/utils/http.py\nindex 572cfb4347..6be2ebcd89 100644\n--- a/django/utils/http.py\n+++ b/django/utils/http.py\n@@ -176,10 +176,24 @@ def parse_http_date(date):\n     try:\n         year = int(m.group('year'))\n         if year < 100:\n-            if year < 70:\n-                year += 2000\n+            # RFC 7231: two-digit year should be interpreted as the most recent\n+            # year in the past that had the same last two digits, if the\n+            # century-adjusted year would be more than 50 years in the future.\n+            current_year = datetime.datetime.utcnow().year\n+            current_century = (current_year // 100) * 100\n+            \n+            # Try current century first\n+            candidate_year = current_century + year\n+            \n+            # If the candidate is in the past, try next century\n+            if candidate_year < current_year:\n+                candidate_year += 100\n+            \n+            # If more than 50 years in the future, use previous century\n+            if candidate_year > current_year + 50:\n+                year = candidate_year - 100\n             else:\n-                year += 1900\n+                year = candidate_year\n         month = MONTHS.index(m.group('mon').lower()) + 1\n         day = int(m.group('day'))\n         hour = int(m.group('hour'))\ndiff --git a/tests/utils_tests/test_http.py b/tests/utils_tests/test_http.py\nindex bc8bcfe977..24bad15707 100644\n--- a/tests/utils_tests/test_http.py\n+++ b/tests/utils_tests/test_http.py\n@@ -328,6 +328,85 @@ class HttpDateProcessingTests(unittest.TestCase):\n         parsed = parse_http_date('Sun Nov  6 08:49:37 0037')\n         self.assertEqual(datetime.utcfromtimestamp(parsed), datetime(2037, 11, 6, 8, 49, 37))\n \n+    def test_rfc7231_two_digit_year_compliance(self):\n+        \"\"\"\n+        Test RFC 7231 compliance for two-digit years in RFC850 format.\n+        Two-digit years should be interpreted as the most recent year in the past\n+        that had the same last two digits, if the century-adjusted year would be\n+        more than 50 years in the future.\n+        \"\"\"\n+        # Mock the current year to make tests deterministic\n+        import unittest.mock\n+        \n+        # Test with current year 2025\n+        with unittest.mock.patch('django.utils.http.datetime') as mock_datetime:\n+            mock_datetime.datetime.utcnow.return_value.year = 2025\n+            mock_datetime.datetime.side_effect = lambda *args, **kw: datetime(*args, **kw)\n+            \n+            # Years that should be in 2000s (within 50 years of 2025)\n+            test_cases_2000s = [\n+                ('Sunday, 06-Nov-25 08:49:37 GMT', 2025),  # Current year\n+                ('Sunday, 06-Nov-26 08:49:37 GMT', 2026),  # 1 year future\n+                ('Sunday, 06-Nov-69 08:49:37 GMT', 2069),  # 44 years future\n+                ('Sunday, 06-Nov-75 08:49:37 GMT', 2075),  # 50 years future (boundary)\n+            ]\n+            \n+            for date_str, expected_year in test_cases_2000s:\n+                with self.subTest(date=date_str, expected_year=expected_year):\n+                    parsed = parse_http_date(date_str)\n+                    result_date = datetime.utcfromtimestamp(parsed)\n+                    self.assertEqual(result_date.year, expected_year)\n+            \n+            # Years that should be in 1900s (more than 50 years in future)\n+            test_cases_1900s = [\n+                ('Sunday, 06-Nov-76 08:49:37 GMT', 1976),  # 51 years future -> past\n+                ('Sunday, 06-Nov-94 08:49:37 GMT', 1994),  # 69 years future -> past\n+                ('Sunday, 06-Nov-99 08:49:37 GMT', 1999),  # 74 years future -> past\n+                ('Sunday, 06-Nov-00 08:49:37 GMT', 2000),  # 75 years future -> past\n+                ('Sunday, 06-Nov-24 08:49:37 GMT', 2024),  # 99 years future -> past\n+            ]\n+            \n+            for date_str, expected_year in test_cases_1900s:\n+                with self.subTest(date=date_str, expected_year=expected_year):\n+                    parsed = parse_http_date(date_str)\n+                    result_date = datetime.utcfromtimestamp(parsed)\n+                    self.assertEqual(result_date.year, expected_year)\n+\n+    def test_rfc7231_different_current_years(self):\n+        \"\"\"\n+        Test RFC 7231 compliance with different current years to ensure\n+        the sliding window works correctly.\n+        \"\"\"\n+        import unittest.mock\n+        \n+        # Test with current year 2070\n+        with unittest.mock.patch('django.utils.http.datetime') as mock_datetime:\n+            mock_datetime.datetime.utcnow.return_value.year = 2070\n+            mock_datetime.datetime.side_effect = lambda *args, **kw: datetime(*args, **kw)\n+            \n+            # In 2070, year \"25\" should be 2125 (55 years future) -> 2025 (past)\n+            parsed = parse_http_date('Sunday, 06-Nov-25 08:49:37 GMT')\n+            result_date = datetime.utcfromtimestamp(parsed)\n+            self.assertEqual(result_date.year, 2025)\n+            \n+            # In 2070, year \"70\" should be 2070 (current year)\n+            parsed = parse_http_date('Sunday, 06-Nov-70 08:49:37 GMT')\n+            result_date = datetime.utcfromtimestamp(parsed)\n+            self.assertEqual(result_date.year, 2070)\n+\n+    def test_four_digit_years_unchanged(self):\n+        \"\"\"\n+        Ensure that four-digit years in RFC1123 and ASCTIME formats\n+        are not affected by the two-digit year logic.\n+        \"\"\"\n+        # RFC1123 format with four-digit year\n+        parsed = parse_http_date('Sun, 06 Nov 1994 08:49:37 GMT')\n+        self.assertEqual(datetime.utcfromtimestamp(parsed), datetime(1994, 11, 6, 8, 49, 37))\n+        \n+        # ASCTIME format with four-digit year\n+        parsed = parse_http_date('Sun Nov  6 08:49:37 1994')\n+        self.assertEqual(datetime.utcfromtimestamp(parsed), datetime(1994, 11, 6, 8, 49, 37))\n+\n \n class EscapeLeadingSlashesTests(unittest.TestCase):\n     def test(self):\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "django__django-14999", "model_patch": "diff --git a/django/db/migrations/operations/models.py b/django/db/migrations/operations/models.py\nindex 982816be3a..5f6c62f50d 100644\n--- a/django/db/migrations/operations/models.py\n+++ b/django/db/migrations/operations/models.py\n@@ -320,6 +320,9 @@ class RenameModel(ModelOperation):\n         new_model = to_state.apps.get_model(app_label, self.new_name)\n         if self.allow_migrate_model(schema_editor.connection.alias, new_model):\n             old_model = from_state.apps.get_model(app_label, self.old_name)\n+            # If the db_table is the same, this is a no-op at the database level\n+            if old_model._meta.db_table == new_model._meta.db_table:\n+                return\n             # Move the main table\n             schema_editor.alter_db_table(\n                 new_model,\ndiff --git a/tests/migrations/test_operations.py b/tests/migrations/test_operations.py\nindex 11961a1f40..f33d08f5b8 100644\n--- a/tests/migrations/test_operations.py\n+++ b/tests/migrations/test_operations.py\n@@ -3821,3 +3821,86 @@ class FieldOperationTests(SimpleTestCase):\n         self.assertIs(operation.references_field('Through', 'whatever', 'migrations'), False)\n         self.assertIs(operation.references_field('Through', 'first', 'migrations'), True)\n         self.assertIs(operation.references_field('Through', 'second', 'migrations'), True)\n+\n+    def test_rename_model_with_same_db_table_is_noop(self):\n+        \"\"\"\n+        RenameModel with the same db_table in old and new models should be a no-op\n+        at the database level.\n+        \"\"\"\n+        # Mock schema editor to track operations\n+        class MockSchemaEditor:\n+            def __init__(self):\n+                self.operations_called = []\n+                self.connection = connection\n+            \n+            def alter_db_table(self, model, old_table, new_table):\n+                self.operations_called.append(('alter_db_table', old_table, new_table))\n+            \n+            def alter_field(self, model, old_field, new_field):\n+                self.operations_called.append(('alter_field', model._meta.label, old_field.name))\n+\n+        # Create initial state with a model that has db_table defined\n+        from_state = ProjectState()\n+        from_state.add_model(ModelState(\n+            app_label='testapp',\n+            name='Author',\n+            fields=[\n+                ('id', models.AutoField(primary_key=True)),\n+                ('name', models.CharField(max_length=100)),\n+            ],\n+            options={'db_table': 'custom_author_table'}\n+        ))\n+        \n+        # Add a related model to test foreign key handling\n+        from_state.add_model(ModelState(\n+            app_label='testapp',\n+            name='Book',\n+            fields=[\n+                ('id', models.AutoField(primary_key=True)),\n+                ('title', models.CharField(max_length=100)),\n+                ('author', models.ForeignKey('testapp.Author', models.CASCADE)),\n+            ],\n+            options={}\n+        ))\n+        \n+        # Create target state with renamed model but same db_table\n+        to_state = ProjectState()\n+        to_state.add_model(ModelState(\n+            app_label='testapp',\n+            name='Writer',  # Renamed from Author to Writer\n+            fields=[\n+                ('id', models.AutoField(primary_key=True)),\n+                ('name', models.CharField(max_length=100)),\n+            ],\n+            options={'db_table': 'custom_author_table'}  # Same db_table!\n+        ))\n+        \n+        # Add the related model with updated foreign key\n+        to_state.add_model(ModelState(\n+            app_label='testapp',\n+            name='Book',\n+            fields=[\n+                ('id', models.AutoField(primary_key=True)),\n+                ('title', models.CharField(max_length=100)),\n+                ('author', models.ForeignKey('testapp.Writer', models.CASCADE)),\n+            ],\n+            options={}\n+        ))\n+        \n+        # Create the RenameModel operation\n+        operation = migrations.RenameModel(old_name='Author', new_name='Writer')\n+        \n+        # Get the models from both states\n+        old_model = from_state.apps.get_model('testapp', 'Author')\n+        new_model = to_state.apps.get_model('testapp', 'Writer')\n+        \n+        # Verify both models have the same db_table\n+        self.assertEqual(old_model._meta.db_table, new_model._meta.db_table)\n+        \n+        # Test the database operation with mock schema editor\n+        mock_editor = MockSchemaEditor()\n+        operation.database_forwards('testapp', mock_editor, from_state, to_state)\n+        \n+        # Verify no operations were called (should be no-op)\n+        self.assertEqual(len(mock_editor.operations_called), 0,\n+                        \"RenameModel with same db_table should not perform any database operations\")\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "django__django-12308", "model_patch": "diff --git a/django/contrib/admin/utils.py b/django/contrib/admin/utils.py\nindex e4ddc8f017..c696eb7e9e 100644\n--- a/django/contrib/admin/utils.py\n+++ b/django/contrib/admin/utils.py\n@@ -398,6 +398,10 @@ def display_for_field(value, field, empty_value_display):\n         return formats.number_format(value)\n     elif isinstance(field, models.FileField) and value:\n         return format_html('<a href=\"{}\">{}</a>', value.url, value)\n+    elif isinstance(field, models.JSONField):\n+        # Use the field's formfield to properly handle InvalidJSONInput\n+        form_field = field.formfield()\n+        return form_field.prepare_value(value)\n     else:\n         return display_for_value(value, empty_value_display)\n \ndiff --git a/tests/admin_utils/tests.py b/tests/admin_utils/tests.py\nindex 463ba9556d..3934ec6331 100644\n--- a/tests/admin_utils/tests.py\n+++ b/tests/admin_utils/tests.py\n@@ -9,6 +9,7 @@ from django.contrib.admin.utils import (\n     flatten_fieldsets, label_for_field, lookup_field, quote,\n )\n from django.db import DEFAULT_DB_ALIAS, models\n+from django.forms.fields import InvalidJSONInput\n from django.test import SimpleTestCase, TestCase, override_settings\n from django.utils.formats import localize\n from django.utils.safestring import mark_safe\n@@ -217,6 +218,43 @@ class UtilsTests(SimpleTestCase):\n         self.assertEqual(display_for_value(True, ''), 'True')\n         self.assertEqual(display_for_value(False, ''), 'False')\n \n+    def test_json_display_for_field(self):\n+        \"\"\"\n+        JSONField values are displayed as JSON, not Python dict representation.\n+        \"\"\"\n+        tests = [\n+            ({'foo': 'bar'}, '{\"foo\": \"bar\"}'),\n+            ({'nested': {'key': 'value'}}, '{\"nested\": {\"key\": \"value\"}}'),\n+            ([1, 2, 3], '[1, 2, 3]'),\n+            ('simple string', '\"simple string\"'),\n+            (42, '42'),\n+            (True, 'true'),\n+            (False, 'false'),\n+        ]\n+        \n+        field = models.JSONField()\n+        for value, expected in tests:\n+            with self.subTest(value=value):\n+                result = display_for_field(value, field, self.empty_value)\n+                self.assertEqual(result, expected)\n+\n+    def test_json_display_for_field_invalid_input(self):\n+        \"\"\"\n+        InvalidJSONInput should be displayed as-is without JSON encoding.\n+        \"\"\"\n+        field = models.JSONField()\n+        invalid_input = InvalidJSONInput('{\"invalid\": json}')\n+        result = display_for_field(invalid_input, field, self.empty_value)\n+        self.assertEqual(result, '{\"invalid\": json}')\n+\n+    def test_json_display_for_field_none_value(self):\n+        \"\"\"\n+        None values in JSONField should display the empty_value_display.\n+        \"\"\"\n+        field = models.JSONField()\n+        result = display_for_field(None, field, self.empty_value)\n+        self.assertEqual(result, self.empty_value)\n+\n     def test_label_for_field(self):\n         \"\"\"\n         Tests for label_for_field\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "scikit-learn__scikit-learn-13439", "model_patch": "diff --git a/sklearn/pipeline.py b/sklearn/pipeline.py\nindex 7eaf9a46f..d1d03656d 100644\n--- a/sklearn/pipeline.py\n+++ b/sklearn/pipeline.py\n@@ -199,6 +199,12 @@ class Pipeline(_BaseComposition):\n             if trans is not None and trans != 'passthrough':\n                 yield idx, name, trans\n \n+    def __len__(self):\n+        \"\"\"\n+        Returns the length of the Pipeline\n+        \"\"\"\n+        return len(self.steps)\n+\n     def __getitem__(self, ind):\n         \"\"\"Returns a sub-pipeline or a single esimtator in the pipeline\n \ndiff --git a/sklearn/tests/test_pipeline.py b/sklearn/tests/test_pipeline.py\nindex 8d6fe8f70..c2386511f 100644\n--- a/sklearn/tests/test_pipeline.py\n+++ b/sklearn/tests/test_pipeline.py\n@@ -552,6 +552,43 @@ def test_pipeline_index():\n     assert_raises(KeyError, lambda: pipe['foobar'])\n \n \n+def test_pipeline_len():\n+    # Test that Pipeline implements __len__\n+    transf = Transf()\n+    clf = FitParamT()\n+    \n+    # Test 1-step pipeline\n+    pipe1 = Pipeline([('clf', clf)])\n+    assert_equal(len(pipe1), 1)\n+    \n+    # Test 2-step pipeline\n+    pipe2 = Pipeline([('transf', transf), ('clf', clf)])\n+    assert_equal(len(pipe2), 2)\n+    \n+    # Test 3-step pipeline\n+    pipe3 = Pipeline([('transf1', transf), ('transf2', Transf()), ('clf', clf)])\n+    assert_equal(len(pipe3), 3)\n+    \n+    # Test that len() is consistent with steps attribute\n+    assert_equal(len(pipe2), len(pipe2.steps))\n+    \n+    # Test that len() works with slicing using len()\n+    full_pipe = pipe3[:len(pipe3)]\n+    assert_equal(len(full_pipe), len(pipe3))\n+    assert_equal(len(full_pipe), 3)\n+    \n+    # Test partial slicing with len()\n+    partial_pipe = pipe3[:len(pipe3)-1]\n+    assert_equal(len(partial_pipe), 2)\n+    \n+    # Test with passthrough and None steps\n+    pipe_with_passthrough = Pipeline([('transf', transf), ('passthrough', 'passthrough'), ('clf', clf)])\n+    assert_equal(len(pipe_with_passthrough), 3)\n+    \n+    pipe_with_none = Pipeline([('transf', transf), ('none', None), ('clf', clf)])\n+    assert_equal(len(pipe_with_none), 3)\n+\n+\n def test_set_pipeline_steps():\n     transf1 = Transf()\n     transf2 = Transf()\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "scikit-learn__scikit-learn-14894", "model_patch": "diff --git a/sklearn/svm/base.py b/sklearn/svm/base.py\nindex 64cebe837..ac261c26e 100644\n--- a/sklearn/svm/base.py\n+++ b/sklearn/svm/base.py\n@@ -287,8 +287,14 @@ class BaseLibSVM(BaseEstimator, metaclass=ABCMeta):\n         n_SV = self.support_vectors_.shape[0]\n \n         dual_coef_indices = np.tile(np.arange(n_SV), n_class)\n-        dual_coef_indptr = np.arange(0, dual_coef_indices.size + 1,\n-                                     dual_coef_indices.size / n_class)\n+        # Handle the edge case when there are no support vectors\n+        if dual_coef_indices.size == 0:\n+            # For empty sparse matrix, indptr should be zeros with n_class+1 elements\n+            dual_coef_indptr = np.zeros(n_class + 1, dtype=int)\n+        else:\n+            # Original logic for non-empty case\n+            dual_coef_indptr = np.arange(0, dual_coef_indices.size + 1,\n+                                         dual_coef_indices.size / n_class)\n         self.dual_coef_ = sp.csr_matrix(\n             (dual_coef_data, dual_coef_indices, dual_coef_indptr),\n             (n_class, n_SV))\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "scikit-learn__scikit-learn-25747", "model_patch": "diff --git a/sklearn/utils/_set_output.py b/sklearn/utils/_set_output.py\nindex 335773c6a..10a9b535f 100644\n--- a/sklearn/utils/_set_output.py\n+++ b/sklearn/utils/_set_output.py\n@@ -56,7 +56,9 @@ def _wrap_in_pandas_container(\n         if columns is not None:\n             data_to_wrap.columns = columns\n         if index is not None:\n-            data_to_wrap.index = index\n+            # Only set the index if it has the same length as the data\n+            if len(index) == len(data_to_wrap):\n+                data_to_wrap.index = index\n         return data_to_wrap\n \n     return pd.DataFrame(data_to_wrap, index=index, columns=columns)\n", "model_name_or_path": "Refact.ai_Agent"}
{"instance_id": "django__django-11133", "model_patch": "diff --git a/django/http/response.py b/django/http/response.py\nindex 6a84e193ba..5cc277d100 100644\n--- a/django/http/response.py\n+++ b/django/http/response.py\n@@ -220,6 +220,14 @@ class HttpResponseBase:\n \n     # Common methods used by subclasses\n \n+    def _supports_buffer_protocol(self, value):\n+        \"\"\"Check if an object supports the buffer protocol.\"\"\"\n+        try:\n+            memoryview(value)\n+            return True\n+        except TypeError:\n+            return False\n+\n     def make_bytes(self, value):\n         \"\"\"Turn a value into a bytestring encoded in the output charset.\"\"\"\n         # Per PEP 3333, this response body must be bytes. To avoid returning\n@@ -233,7 +241,16 @@ class HttpResponseBase:\n             return bytes(value)\n         if isinstance(value, str):\n             return bytes(value.encode(self.charset))\n-        # Handle non-string types.\n+        \n+        # Handle objects that support the buffer protocol (memoryview, bytearray, etc.)\n+        # but exclude integers which also work with bytes() but create zero-filled arrays\n+        if not isinstance(value, int):\n+            try:\n+                return bytes(value)\n+            except TypeError:\n+                pass\n+        \n+        # Handle non-string types that don't support buffer protocol\n         return str(value).encode(self.charset)\n \n     # These methods partially implement the file-like object interface.\n@@ -309,7 +326,10 @@ class HttpResponse(HttpResponseBase):\n     @content.setter\n     def content(self, value):\n         # Consume iterators upon assignment to allow repeated iteration.\n-        if hasattr(value, '__iter__') and not isinstance(value, (bytes, str)):\n+        # Prioritize buffer protocol objects (memoryview, bytearray) over iteration\n+        # since they should be converted as single units, not iterated over.\n+        if (hasattr(value, '__iter__') and not isinstance(value, (bytes, str)) and \n+            not self._supports_buffer_protocol(value)):\n             content = b''.join(self.make_bytes(chunk) for chunk in value)\n             if hasattr(value, 'close'):\n                 try:\n", "model_name_or_path": "Refact.ai_Agent"}
