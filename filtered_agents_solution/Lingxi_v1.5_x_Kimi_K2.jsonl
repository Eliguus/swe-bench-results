{"instance_id": "django__django-14608", "model_patch": "diff --git a/django/forms/formsets.py b/django/forms/formsets.py\nindex a89c35599f..1b0d4554e0 100644\n--- a/django/forms/formsets.py\n+++ b/django/forms/formsets.py\n@@ -333,7 +333,7 @@ class BaseFormSet:\n         self._non_form_errors.\n         \"\"\"\n         self._errors = []\n-        self._non_form_errors = self.error_class()\n+        self._non_form_errors = self.error_class(error_class='nonform')\n         empty_forms_count = 0\n \n         if not self.is_bound:  # Stop further processing.\n@@ -380,7 +380,7 @@ class BaseFormSet:\n             # Give self.clean() a chance to do cross-form validation.\n             self.clean()\n         except ValidationError as e:\n-            self._non_form_errors = self.error_class(e.error_list)\n+            self._non_form_errors = self.error_class(e.error_list, error_class='nonform')\n \n     def clean(self):\n         \"\"\"\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "scikit-learn__scikit-learn-13779", "model_patch": "diff --git a/sklearn/ensemble/voting.py b/sklearn/ensemble/voting.py\nindex 7afa7180c..13accdcec 100644\n--- a/sklearn/ensemble/voting.py\n+++ b/sklearn/ensemble/voting.py\n@@ -78,7 +78,7 @@ class _BaseVoting(_BaseComposition, TransformerMixin):\n \n         if sample_weight is not None:\n             for name, step in self.estimators:\n-                if not has_fit_parameter(step, 'sample_weight'):\n+                if step is not None and not has_fit_parameter(step, 'sample_weight'):\n                     raise ValueError('Underlying estimator \\'%s\\' does not'\n                                      ' support sample weights.' % name)\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "sympy__sympy-13031", "model_patch": "diff --git a/sympy/matrices/sparse.py b/sympy/matrices/sparse.py\nindex e6f36cdf35..6cd2550cab 100644\n--- a/sympy/matrices/sparse.py\n+++ b/sympy/matrices/sparse.py\n@@ -986,7 +986,7 @@ def col_join(self, other):\n         True\n         \"\"\"\n         if not self:\n-            return type(self)(other)\n+            return type(self)(self.rows + other.rows, other.cols, {})\n         A, B = self, other\n         if not A.cols == B.cols:\n             raise ShapeError()\n@@ -1192,7 +1192,7 @@ def row_join(self, other):\n         True\n         \"\"\"\n         if not self:\n-            return type(self)(other)\n+            return type(self)(other.rows, self.cols + other.cols, {})\n         A, B = self, other\n         if not A.rows == B.rows:\n             raise ShapeError()\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "scikit-learn__scikit-learn-14087", "model_patch": "diff --git a/sklearn/linear_model/logistic.py b/sklearn/linear_model/logistic.py\nindex 1999f1dae..1a83f159a 100644\n--- a/sklearn/linear_model/logistic.py\n+++ b/sklearn/linear_model/logistic.py\n@@ -2170,7 +2170,7 @@ class LogisticRegressionCV(LogisticRegression, BaseEstimator,\n                 # Take the best scores across every fold and the average of\n                 # all coefficients corresponding to the best scores.\n                 best_indices = np.argmax(scores, axis=1)\n-                if self.multi_class == 'ovr':\n+                if multi_class == 'ovr':\n                     w = np.mean([coefs_paths[i, best_indices[i], :]\n                                  for i in range(len(folds))], axis=0)\n                 else:\n@@ -2181,7 +2181,10 @@ class LogisticRegressionCV(LogisticRegression, BaseEstimator,\n                 self.C_.append(np.mean(self.Cs_[best_indices_C]))\n \n                 best_indices_l1 = best_indices // len(self.Cs_)\n-                self.l1_ratio_.append(np.mean(l1_ratios_[best_indices_l1]))\n+                if l1_ratios_[0] is not None:\n+                    self.l1_ratio_.append(np.mean([l1_ratios_[i] for i in best_indices_l1]))\n+                else:\n+                    self.l1_ratio_.append(None)\n \n             if multi_class == 'multinomial':\n                 self.C_ = np.tile(self.C_, n_classes)\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "django__django-12708", "model_patch": "diff --git a/django/db/backends/base/schema.py b/django/db/backends/base/schema.py\nindex 61f88401ab..1f521cfc5c 100644\n--- a/django/db/backends/base/schema.py\n+++ b/django/db/backends/base/schema.py\n@@ -393,7 +393,7 @@ class BaseDatabaseSchemaEditor:\n         news = {tuple(fields) for fields in new_index_together}\n         # Deleted indexes\n         for fields in olds.difference(news):\n-            self._delete_composed_index(model, fields, {'index': True}, self.sql_delete_index)\n+            self._delete_composed_index(model, fields, {'index': True, 'unique': False}, self.sql_delete_index)\n         # Created indexes\n         for field_names in news.difference(olds):\n             fields = [model._meta.get_field(field) for field in field_names]\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "astropy__astropy-14995", "model_patch": "diff --git a/astropy/nddata/mixins/ndarithmetic.py b/astropy/nddata/mixins/ndarithmetic.py\nindex 4153dfccb2..c69a8bf921 100644\n--- a/astropy/nddata/mixins/ndarithmetic.py\n+++ b/astropy/nddata/mixins/ndarithmetic.py\n@@ -522,6 +522,9 @@ class NDArithmeticMixin:\n             return deepcopy(operand.mask)\n         elif operand is None:\n             return deepcopy(self.mask)\n+        elif operand.mask is None:\n+            # If operand has no mask but self has a mask, return self.mask\n+            return deepcopy(self.mask)\n         else:\n             # Now lets calculate the resulting mask (operation enforces copy)\n             return handle_mask(self.mask, operand.mask, **kwds)\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "django__django-13964", "model_patch": "diff --git a/django/db/models/base.py b/django/db/models/base.py\nindex 2428218696..6c923da7c5 100644\n--- a/django/db/models/base.py\n+++ b/django/db/models/base.py\n@@ -933,7 +933,10 @@ class Model(metaclass=ModelBase):\n                         \"%s() prohibited to prevent data loss due to unsaved \"\n                         \"related object '%s'.\" % (operation_name, field.name)\n                     )\n-                elif getattr(self, field.attname) is None:\n+                elif getattr(self, field.attname) is None or (\n+                    getattr(self, field.attname) in field.target_field.empty_values and\n+                    obj.pk not in field.target_field.empty_values\n+                ):\n                     # Use pk from related object if it has been saved after\n                     # an assignment.\n                     setattr(self, field.attname, obj.pk)\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "sympy__sympy-18698", "model_patch": "diff --git a/sympy/polys/polytools.py b/sympy/polys/polytools.py\nindex c9e77a901f..ea3f7f7747 100644\n--- a/sympy/polys/polytools.py\n+++ b/sympy/polys/polytools.py\n@@ -5950,6 +5950,39 @@ def _symbolic_factor_list(expr, opt, method):\n \n                 factors.append((_factors_product(other), exp))\n \n+    # Combine factors with the same multiplicity for consistency\n+    if method == 'sqf' and len(factors) > 1:\n+        from collections import defaultdict\n+        \n+        # Group factors by multiplicity\n+        multiplicity_groups = defaultdict(list)\n+        for factor, mult in factors:\n+            multiplicity_groups[mult].append(factor)\n+        \n+        # Combine factors with same multiplicity\n+        combined_factors = []\n+        for mult, factor_list in multiplicity_groups.items():\n+            if len(factor_list) == 1:\n+                combined_factors.append((factor_list[0], mult))\n+            else:\n+                # Multiply all factors together\n+                if all(hasattr(f, 'as_expr') for f in factor_list):\n+                    # For Poly objects, multiply as expressions then convert back\n+                    combined_expr = Mul(*[f.as_expr() for f in factor_list])\n+                    try:\n+                        combined_factor, _ = _poly_from_expr(combined_expr, opt)\n+                        combined_factors.append((combined_factor, mult))\n+                    except:\n+                        # If conversion fails, keep factors separate\n+                        for f in factor_list:\n+                            combined_factors.append((f, mult))\n+                else:\n+                    # For regular expressions, multiply directly\n+                    combined_factor = Mul(*factor_list)\n+                    combined_factors.append((combined_factor, mult))\n+        \n+        factors = combined_factors\n+    \n     return coeff, factors\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "django__django-15695", "model_patch": "diff --git a/django/db/migrations/operations/models.py b/django/db/migrations/operations/models.py\nindex d17232e4ec..1d9ab2afda 100644\n--- a/django/db/migrations/operations/models.py\n+++ b/django/db/migrations/operations/models.py\n@@ -967,7 +967,31 @@ class RenameIndex(IndexOperation):\n \n     def database_backwards(self, app_label, schema_editor, from_state, to_state):\n         if self.old_fields:\n-            # Backward operation with unnamed index is a no-op.\n+            # For unnamed indexes, we need to restore the original auto-generated name\n+            to_model = to_state.apps.get_model(app_label, self.model_name)\n+            if not self.allow_migrate_model(schema_editor.connection.alias, to_model):\n+                return\n+            \n+            # Calculate what the original auto-generated name should be\n+            columns = [\n+                to_model._meta.get_field(field).column for field in self.old_fields\n+            ]\n+            original_name = schema_editor._create_index_name(\n+                to_model._meta.db_table, columns\n+            )\n+            \n+            # Create an index with the new name (current state)\n+            from_model_state = from_state.models[app_label, self.model_name_lower]\n+            old_index = from_model_state.get_index_by_name(self.new_name)\n+            \n+            # Create an index with the original auto-generated name\n+            new_index = models.Index(\n+                fields=self.old_fields,\n+                name=original_name,\n+            )\n+            \n+            # Rename from the new name back to the original auto-generated name\n+            schema_editor.rename_index(to_model, old_index, new_index)\n             return\n \n         self.new_name_lower, self.old_name_lower = (\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "sympy__sympy-16792", "model_patch": "diff --git a/sympy/utilities/codegen.py b/sympy/utilities/codegen.py\nindex f0befb2bd7..5e2efc8888 100644\n--- a/sympy/utilities/codegen.py\n+++ b/sympy/utilities/codegen.py\n@@ -739,7 +739,14 @@ def routine(self, name, expr, argument_sequence=None, global_vars=None):\n                 try:\n                     new_args.append(name_arg_dict[symbol])\n                 except KeyError:\n-                    new_args.append(InputArgument(symbol))\n+                    # If symbol is a MatrixSymbol, preserve its dimensions\n+                    if isinstance(symbol, MatrixSymbol):\n+                        dims = []\n+                        for dim in symbol.shape:\n+                            dims.append((S.Zero, dim - 1))\n+                        new_args.append(InputArgument(symbol, dimensions=dims))\n+                    else:\n+                        new_args.append(InputArgument(symbol))\n             arg_list = new_args\n \n         return Routine(name, arg_list, return_val, local_vars, global_vars)\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "django__django-14787", "model_patch": "diff --git a/django/utils/decorators.py b/django/utils/decorators.py\nindex 5c9a5d01c7..45d384ebe2 100644\n--- a/django/utils/decorators.py\n+++ b/django/utils/decorators.py\n@@ -38,6 +38,9 @@ def _multi_decorate(decorators, method):\n         # 'func'. Also, wrap method.__get__() in a function because new\n         # attributes can't be set on bound method objects, only on functions.\n         bound_method = partial(method.__get__(self, type(self)))\n+        # Copy function attributes from the original method to the partial object\n+        # so that decorators can access attributes like __name__, __module__, etc.\n+        update_wrapper(bound_method, method)\n         for dec in decorators:\n             bound_method = dec(bound_method)\n         return bound_method(*args, **kwargs)\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "sympy__sympy-18199", "model_patch": "diff --git a/sympy/ntheory/residue_ntheory.py b/sympy/ntheory/residue_ntheory.py\nindex 9a3052d4c3..50543d16c2 100644\n--- a/sympy/ntheory/residue_ntheory.py\n+++ b/sympy/ntheory/residue_ntheory.py\n@@ -707,6 +707,11 @@ def _nthroot_mod1(s, q, p, all_roots):\n     .. [1] A. M. Johnston \"A Generalized qth Root Algorithm\"\n \n     \"\"\"\n+    # Handle the case where s â‰¡ 0 (mod p)\n+    if s % p == 0:\n+        # x^q = 0 mod p has only one solution: x = 0 mod p\n+        return [0] if all_roots else 0\n+    \n     g = primitive_root(p)\n     if not isprime(q):\n         r = _nthroot_mod2(s, q, p)\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "sympy__sympy-21379", "model_patch": "diff --git a/sympy/polys/polyutils.py b/sympy/polys/polyutils.py\nindex f51f80098d..64d5968f76 100644\n--- a/sympy/polys/polyutils.py\n+++ b/sympy/polys/polyutils.py\n@@ -266,8 +266,10 @@ def _is_coeff(factor):\n                     else:\n                         base, exp = decompose_power_rat(factor)\n \n-                    elements[base] = elements.setdefault(base, 0) + exp\n-                    gens.add(base)\n+                    # Skip Piecewise expressions as they don't make sense as generators\n+                    if base.__class__.__name__ != 'Piecewise':\n+                        elements[base] = elements.setdefault(base, 0) + exp\n+                        gens.add(base)\n \n             terms.append((coeff, elements))\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "django__django-13658", "model_patch": "diff --git a/django/core/management/__init__.py b/django/core/management/__init__.py\nindex 1ba093e51f..095ad0ccf0 100644\n--- a/django/core/management/__init__.py\n+++ b/django/core/management/__init__.py\n@@ -344,7 +344,12 @@ class ManagementUtility:\n         # Preprocess options to extract --settings and --pythonpath.\n         # These options could affect the commands that are available, so they\n         # must be processed early.\n-        parser = CommandParser(usage='%(prog)s subcommand [options] [args]', add_help=False, allow_abbrev=False)\n+        parser = CommandParser(\n+            prog=self.prog_name,\n+            usage='%(prog)s subcommand [options] [args]',\n+            add_help=False,\n+            allow_abbrev=False\n+        )\n         parser.add_argument('--settings')\n         parser.add_argument('--pythonpath')\n         parser.add_argument('args', nargs='*')  # catch-all\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "django__django-16255", "model_patch": "diff --git a/django/contrib/sitemaps/__init__.py b/django/contrib/sitemaps/__init__.py\nindex 27756d9d96..b40ad806ed 100644\n--- a/django/contrib/sitemaps/__init__.py\n+++ b/django/contrib/sitemaps/__init__.py\n@@ -168,7 +168,7 @@ class Sitemap:\n         if callable(self.lastmod):\n             try:\n                 return max([self.lastmod(item) for item in self.items()])\n-            except TypeError:\n+            except (TypeError, ValueError):\n                 return None\n         else:\n             return self.lastmod\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "matplotlib__matplotlib-23476", "model_patch": "diff --git a/lib/matplotlib/figure.py b/lib/matplotlib/figure.py\nindex c55864243a..8161166821 100644\n--- a/lib/matplotlib/figure.py\n+++ b/lib/matplotlib/figure.py\n@@ -3023,6 +3023,10 @@ class Figure(FigureBase):\n         # Set cached renderer to None -- it can't be pickled.\n         state[\"_cachedRenderer\"] = None\n \n+        # Preserve the original DPI to prevent device pixel ratio scaling issues\n+        if hasattr(self, \"_original_dpi\"):\n+            state[\"_original_dpi\"] = self._original_dpi\n+\n         # add version information to the state\n         state['__mpl_version__'] = mpl.__version__\n \n@@ -3036,6 +3040,9 @@ class Figure(FigureBase):\n         version = state.pop('__mpl_version__')\n         restore_to_pylab = state.pop('_restore_to_pylab', False)\n \n+        # Restore the original DPI before setting up the new canvas\n+        original_dpi = state.pop(\"_original_dpi\", None)\n+\n         if version != mpl.__version__:\n             _api.warn_external(\n                 f\"This figure was saved with matplotlib version {version} and \"\n@@ -3043,6 +3050,10 @@ class Figure(FigureBase):\n \n         self.__dict__ = state\n \n+        # Restore the original DPI if it was preserved\n+        if original_dpi is not None:\n+            self._original_dpi = original_dpi\n+\n         # re-initialise some of the unstored state information\n         FigureCanvasBase(self)  # Set self.canvas.\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "sympy__sympy-18189", "model_patch": "diff --git a/sympy/solvers/diophantine.py b/sympy/solvers/diophantine.py\nindex 6092e35dab..b43f5c1dcf 100644\n--- a/sympy/solvers/diophantine.py\n+++ b/sympy/solvers/diophantine.py\n@@ -182,7 +182,7 @@ def diophantine(eq, param=symbols(\"t\", integer=True), syms=None,\n             if syms != var:\n                 dict_sym_index = dict(zip(syms, range(len(syms))))\n                 return {tuple([t[dict_sym_index[i]] for i in var])\n-                            for t in diophantine(eq, param)}\n+                            for t in diophantine(eq, param, permute=permute)}\n         n, d = eq.as_numer_denom()\n         if n.is_number:\n             return set()\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "sympy__sympy-17139", "model_patch": "diff --git a/sympy/simplify/fu.py b/sympy/simplify/fu.py\nindex ad1130ef96..ef1362bd3d 100644\n--- a/sympy/simplify/fu.py\n+++ b/sympy/simplify/fu.py\n@@ -500,6 +500,8 @@ def _f(rv):\n         # change is not going to allow a simplification as far as I can tell.\n         if not (rv.is_Pow and rv.base.func == f):\n             return rv\n+        if not rv.exp.is_extended_real:\n+            return rv\n \n         if (rv.exp < 0) == True:\n             return rv\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "django__django-14155", "model_patch": "diff --git a/django/urls/resolvers.py b/django/urls/resolvers.py\nindex 9b00e24509..3974cd0a8a 100644\n--- a/django/urls/resolvers.py\n+++ b/django/urls/resolvers.py\n@@ -45,6 +45,15 @@ class ResolverMatch:\n         self.namespaces = [x for x in namespaces if x] if namespaces else []\n         self.namespace = ':'.join(self.namespaces)\n \n+        # Handle functools.partial objects by unwrapping them\n+        if isinstance(func, functools.partial):\n+            self._partial_args = func.args\n+            self._partial_kwargs = func.keywords\n+            func = func.func\n+        else:\n+            self._partial_args = ()\n+            self._partial_kwargs = {}\n+\n         if not hasattr(func, '__name__'):\n             # A class-based view\n             self._func_path = func.__class__.__module__ + '.' + func.__class__.__name__\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "django__django-10914", "model_patch": "diff --git a/django/conf/global_settings.py b/django/conf/global_settings.py\nindex acee9887d2..bdeec80610 100644\n--- a/django/conf/global_settings.py\n+++ b/django/conf/global_settings.py\n@@ -304,7 +304,7 @@ FILE_UPLOAD_TEMP_DIR = None\n \n # The numeric mode to set newly-uploaded files to. The value should be a mode\n # you'd pass directly to os.chmod; see https://docs.python.org/library/os.html#files-and-directories.\n-FILE_UPLOAD_PERMISSIONS = None\n+FILE_UPLOAD_PERMISSIONS = 0o644\n \n # The numeric mode to assign to newly-created directories, when uploading files.\n # The value should be a mode as you'd pass to os.chmod;\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "sympy__sympy-17630", "model_patch": "diff --git a/sympy/matrices/expressions/blockmatrix.py b/sympy/matrices/expressions/blockmatrix.py\nindex 95302a05ca..4ea456ac21 100644\n--- a/sympy/matrices/expressions/blockmatrix.py\n+++ b/sympy/matrices/expressions/blockmatrix.py\n@@ -164,7 +164,30 @@ def structurally_equal(self, other):\n     def _blockmul(self, other):\n         if (isinstance(other, BlockMatrix) and\n                 self.colblocksizes == other.rowblocksizes):\n-            return BlockMatrix(self.blocks*other.blocks)\n+            # Perform matrix multiplication on the blocks\n+            product_blocks = self.blocks * other.blocks\n+            \n+            # Fix any ZeroMatrix objects that were converted to scalar Zero objects\n+            # during matrix multiplication (this happens in dense.py Add(*vec) call)\n+            from sympy.core.numbers import Zero\n+            fixed_blocks = []\n+            for i in range(product_blocks.shape[0]):\n+                row = []\n+                for j in range(product_blocks.shape[1]):\n+                    element = product_blocks[i, j]\n+                    # If element is a scalar Zero, convert it to ZeroMatrix\n+                    if isinstance(element, Zero):\n+                        # Determine the appropriate dimensions for the ZeroMatrix\n+                        # The element at position (i,j) should have dimensions:\n+                        # rows = self.rowblocksizes[i], cols = other.colblocksizes[j]\n+                        zero_rows = self.rowblocksizes[i]\n+                        zero_cols = other.colblocksizes[j]\n+                        row.append(ZeroMatrix(zero_rows, zero_cols))\n+                    else:\n+                        row.append(element)\n+                fixed_blocks.append(row)\n+            \n+            return BlockMatrix(fixed_blocks)\n \n         return self * other\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "django__django-11179", "model_patch": "diff --git a/django/db/models/deletion.py b/django/db/models/deletion.py\nindex 92fe4affb9..3a462f1c4c 100644\n--- a/django/db/models/deletion.py\n+++ b/django/db/models/deletion.py\n@@ -277,6 +277,7 @@ class Collector:\n             if self.can_fast_delete(instance):\n                 with transaction.mark_for_rollback_on_error():\n                     count = sql.DeleteQuery(model).delete_batch([instance.pk], self.using)\n+                setattr(instance, model._meta.pk.attname, None)\n                 return count, {model._meta.label: count}\n \n         with transaction.atomic(using=self.using, savepoint=False):\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "sympy__sympy-15345", "model_patch": "diff --git a/sympy/printing/mathematica.py b/sympy/printing/mathematica.py\nindex ea7e3a2d94..ebee216a87 100644\n--- a/sympy/printing/mathematica.py\n+++ b/sympy/printing/mathematica.py\n@@ -31,6 +31,8 @@\n     \"asech\": [(lambda x: True, \"ArcSech\")],\n     \"acsch\": [(lambda x: True, \"ArcCsch\")],\n     \"conjugate\": [(lambda x: True, \"Conjugate\")],\n+    \"Max\": [(lambda *x: True, \"Max\")],\n+    \"Min\": [(lambda *x: True, \"Min\")],\n \n }\n \n@@ -101,6 +103,8 @@ def _print_Function(self, expr):\n                     return \"%s[%s]\" % (mfunc, self.stringify(expr.args, \", \"))\n         return expr.func.__name__ + \"[%s]\" % self.stringify(expr.args, \", \")\n \n+    _print_Expr = _print_Function\n+\n     def _print_Integral(self, expr):\n         if len(expr.variables) == 1 and not expr.limits[0][1:]:\n             args = [expr.args[0], expr.variables[0]]\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "sympy__sympy-21612", "model_patch": "diff --git a/sympy/parsing/latex/_antlr/latexlexer.py b/sympy/parsing/latex/_antlr/latexlexer.py\nindex 29eb4b462a..f15740e7f6 100644\n--- a/sympy/parsing/latex/_antlr/latexlexer.py\n+++ b/sympy/parsing/latex/_antlr/latexlexer.py\n@@ -1,6 +1,16 @@\n \n # encoding: utf-8\n \n+# *** GENERATED BY `setup.py antlr`, DO NOT EDIT BY HAND ***\n+#\n+# Generated from ../LaTeX.g4, derived from latex2sympy\n+#     latex2sympy is licensed under the MIT license\n+#     https://github.com/augustt198/latex2sympy/blob/master/LICENSE.txt\n+#\n+# Generated with antlr4\n+#    antlr4 is licensed under the BSD-3-Clause License\n+#    https://github.com/antlr/antlr4/blob/master/LICENSE.txt\n+\n # *** GENERATED BY `setup.py antlr`, DO NOT EDIT BY HAND ***\n #\n # Generated from ../LaTeX.g4, derived from latex2sympy\n@@ -16,7 +26,6 @@\n import sys\n \n \n-\n def serializedATN():\n     with StringIO() as buf:\n         buf.write(u\"\\3\\u608b\\ua72a\\u8133\\ub9ed\\u417c\\u3be7\\u7786\\u5964\\2\")\ndiff --git a/sympy/parsing/latex/_antlr/latexparser.py b/sympy/parsing/latex/_antlr/latexparser.py\nindex 0fc7e5a7a6..f6be7423ee 100644\n--- a/sympy/parsing/latex/_antlr/latexparser.py\n+++ b/sympy/parsing/latex/_antlr/latexparser.py\n@@ -1,6 +1,16 @@\n \n # encoding: utf-8\n \n+# *** GENERATED BY `setup.py antlr`, DO NOT EDIT BY HAND ***\n+#\n+# Generated from ../LaTeX.g4, derived from latex2sympy\n+#     latex2sympy is licensed under the MIT license\n+#     https://github.com/augustt198/latex2sympy/blob/master/LICENSE.txt\n+#\n+# Generated with antlr4\n+#    antlr4 is licensed under the BSD-3-Clause License\n+#    https://github.com/antlr/antlr4/blob/master/LICENSE.txt\n+\n # *** GENERATED BY `setup.py antlr`, DO NOT EDIT BY HAND ***\n #\n # Generated from ../LaTeX.g4, derived from latex2sympy\n@@ -15,7 +25,6 @@\n from io import StringIO\n import sys\n \n-\n def serializedATN():\n     with StringIO() as buf:\n         buf.write(u\"\\3\\u608b\\ua72a\\u8133\\ub9ed\\u417c\\u3be7\\u7786\\u5964\\3\")\n@@ -444,7 +453,6 @@ def __init__(self, input, output=sys.stdout):\n \n \n \n-\n     class MathContext(ParserRuleContext):\n \n         def __init__(self, parser, parent=None, invokingState=-1):\n@@ -477,7 +485,6 @@ def math(self):\n             self.exitRule()\n         return localctx\n \n-\n     class RelationContext(ParserRuleContext):\n \n         def __init__(self, parser, parent=None, invokingState=-1):\n@@ -566,7 +573,6 @@ def relation(self, _p=0):\n             self.unrollRecursionContexts(_parentctx)\n         return localctx\n \n-\n     class EqualityContext(ParserRuleContext):\n \n         def __init__(self, parser, parent=None, invokingState=-1):\n@@ -609,7 +615,6 @@ def equality(self):\n             self.exitRule()\n         return localctx\n \n-\n     class ExprContext(ParserRuleContext):\n \n         def __init__(self, parser, parent=None, invokingState=-1):\n@@ -642,7 +647,6 @@ def expr(self):\n             self.exitRule()\n         return localctx\n \n-\n     class AdditiveContext(ParserRuleContext):\n \n         def __init__(self, parser, parent=None, invokingState=-1):\n@@ -719,7 +723,6 @@ def additive(self, _p=0):\n             self.unrollRecursionContexts(_parentctx)\n         return localctx\n \n-\n     class MpContext(ParserRuleContext):\n \n         def __init__(self, parser, parent=None, invokingState=-1):\n@@ -808,7 +811,6 @@ def mp(self, _p=0):\n             self.unrollRecursionContexts(_parentctx)\n         return localctx\n \n-\n     class Mp_nofuncContext(ParserRuleContext):\n \n         def __init__(self, parser, parent=None, invokingState=-1):\n@@ -897,7 +899,6 @@ def mp_nofunc(self, _p=0):\n             self.unrollRecursionContexts(_parentctx)\n         return localctx\n \n-\n     class UnaryContext(ParserRuleContext):\n \n         def __init__(self, parser, parent=None, invokingState=-1):\n@@ -976,7 +977,6 @@ def unary(self):\n             self.exitRule()\n         return localctx\n \n-\n     class Unary_nofuncContext(ParserRuleContext):\n \n         def __init__(self, parser, parent=None, invokingState=-1):\n@@ -1058,7 +1058,6 @@ def unary_nofunc(self):\n             self.exitRule()\n         return localctx\n \n-\n     class PostfixContext(ParserRuleContext):\n \n         def __init__(self, parser, parent=None, invokingState=-1):\n@@ -1109,7 +1108,6 @@ def postfix(self):\n             self.exitRule()\n         return localctx\n \n-\n     class Postfix_nofuncContext(ParserRuleContext):\n \n         def __init__(self, parser, parent=None, invokingState=-1):\n@@ -1160,7 +1158,6 @@ def postfix_nofunc(self):\n             self.exitRule()\n         return localctx\n \n-\n     class Postfix_opContext(ParserRuleContext):\n \n         def __init__(self, parser, parent=None, invokingState=-1):\n@@ -1209,7 +1206,6 @@ def postfix_op(self):\n             self.exitRule()\n         return localctx\n \n-\n     class Eval_atContext(ParserRuleContext):\n \n         def __init__(self, parser, parent=None, invokingState=-1):\n@@ -1270,7 +1266,6 @@ def eval_at(self):\n             self.exitRule()\n         return localctx\n \n-\n     class Eval_at_subContext(ParserRuleContext):\n \n         def __init__(self, parser, parent=None, invokingState=-1):\n@@ -1334,7 +1329,6 @@ def eval_at_sub(self):\n             self.exitRule()\n         return localctx\n \n-\n     class Eval_at_supContext(ParserRuleContext):\n \n         def __init__(self, parser, parent=None, invokingState=-1):\n@@ -1398,7 +1392,6 @@ def eval_at_sup(self):\n             self.exitRule()\n         return localctx\n \n-\n     class ExpContext(ParserRuleContext):\n \n         def __init__(self, parser, parent=None, invokingState=-1):\n@@ -1505,7 +1498,6 @@ def exp(self, _p=0):\n             self.unrollRecursionContexts(_parentctx)\n         return localctx\n \n-\n     class Exp_nofuncContext(ParserRuleContext):\n \n         def __init__(self, parser, parent=None, invokingState=-1):\n@@ -1612,7 +1604,6 @@ def exp_nofunc(self, _p=0):\n             self.unrollRecursionContexts(_parentctx)\n         return localctx\n \n-\n     class CompContext(ParserRuleContext):\n \n         def __init__(self, parser, parent=None, invokingState=-1):\n@@ -1722,7 +1713,6 @@ def comp(self):\n             self.exitRule()\n         return localctx\n \n-\n     class Comp_nofuncContext(ParserRuleContext):\n \n         def __init__(self, parser, parent=None, invokingState=-1):\n@@ -1822,7 +1812,6 @@ def comp_nofunc(self):\n             self.exitRule()\n         return localctx\n \n-\n     class GroupContext(ParserRuleContext):\n \n         def __init__(self, parser, parent=None, invokingState=-1):\n@@ -1918,7 +1907,6 @@ def group(self):\n             self.exitRule()\n         return localctx\n \n-\n     class Abs_groupContext(ParserRuleContext):\n \n         def __init__(self, parser, parent=None, invokingState=-1):\n@@ -1961,7 +1949,6 @@ def abs_group(self):\n             self.exitRule()\n         return localctx\n \n-\n     class AtomContext(ParserRuleContext):\n \n         def __init__(self, parser, parent=None, invokingState=-1):\n@@ -2065,7 +2052,6 @@ def atom(self):\n             self.exitRule()\n         return localctx\n \n-\n     class BraContext(ParserRuleContext):\n \n         def __init__(self, parser, parent=None, invokingState=-1):\n@@ -2117,7 +2103,6 @@ def bra(self):\n             self.exitRule()\n         return localctx\n \n-\n     class KetContext(ParserRuleContext):\n \n         def __init__(self, parser, parent=None, invokingState=-1):\n@@ -2169,7 +2154,6 @@ def ket(self):\n             self.exitRule()\n         return localctx\n \n-\n     class MathitContext(ParserRuleContext):\n \n         def __init__(self, parser, parent=None, invokingState=-1):\n@@ -2217,7 +2201,6 @@ def mathit(self):\n             self.exitRule()\n         return localctx\n \n-\n     class Mathit_textContext(ParserRuleContext):\n \n         def __init__(self, parser, parent=None, invokingState=-1):\n@@ -2261,7 +2244,6 @@ def mathit_text(self):\n             self.exitRule()\n         return localctx\n \n-\n     class FracContext(ParserRuleContext):\n \n         def __init__(self, parser, parent=None, invokingState=-1):\n@@ -2326,7 +2308,6 @@ def frac(self):\n             self.exitRule()\n         return localctx\n \n-\n     class BinomContext(ParserRuleContext):\n \n         def __init__(self, parser, parent=None, invokingState=-1):\n@@ -2403,7 +2384,6 @@ def binom(self):\n             self.exitRule()\n         return localctx\n \n-\n     class FloorContext(ParserRuleContext):\n \n         def __init__(self, parser, parent=None, invokingState=-1):\n@@ -2447,7 +2427,6 @@ def floor(self):\n             self.exitRule()\n         return localctx\n \n-\n     class CeilContext(ParserRuleContext):\n \n         def __init__(self, parser, parent=None, invokingState=-1):\n@@ -2491,7 +2470,6 @@ def ceil(self):\n             self.exitRule()\n         return localctx\n \n-\n     class Func_normalContext(ParserRuleContext):\n \n         def __init__(self, parser, parent=None, invokingState=-1):\n@@ -2589,7 +2567,6 @@ def func_normal(self):\n             self.exitRule()\n         return localctx\n \n-\n     class FuncContext(ParserRuleContext):\n \n         def __init__(self, parser, parent=None, invokingState=-1):\n@@ -2933,7 +2910,6 @@ def func(self):\n             self.exitRule()\n         return localctx\n \n-\n     class ArgsContext(ParserRuleContext):\n \n         def __init__(self, parser, parent=None, invokingState=-1):\n@@ -2987,7 +2963,6 @@ def args(self):\n             self.exitRule()\n         return localctx\n \n-\n     class Limit_subContext(ParserRuleContext):\n \n         def __init__(self, parser, parent=None, invokingState=-1):\n@@ -3088,7 +3063,6 @@ def limit_sub(self):\n             self.exitRule()\n         return localctx\n \n-\n     class Func_argContext(ParserRuleContext):\n \n         def __init__(self, parser, parent=None, invokingState=-1):\n@@ -3142,7 +3116,6 @@ def func_arg(self):\n             self.exitRule()\n         return localctx\n \n-\n     class Func_arg_noparensContext(ParserRuleContext):\n \n         def __init__(self, parser, parent=None, invokingState=-1):\n@@ -3175,7 +3148,6 @@ def func_arg_noparens(self):\n             self.exitRule()\n         return localctx\n \n-\n     class SubexprContext(ParserRuleContext):\n \n         def __init__(self, parser, parent=None, invokingState=-1):\n@@ -3239,7 +3211,6 @@ def subexpr(self):\n             self.exitRule()\n         return localctx\n \n-\n     class SupexprContext(ParserRuleContext):\n \n         def __init__(self, parser, parent=None, invokingState=-1):\n@@ -3303,7 +3274,6 @@ def supexpr(self):\n             self.exitRule()\n         return localctx\n \n-\n     class SubeqContext(ParserRuleContext):\n \n         def __init__(self, parser, parent=None, invokingState=-1):\n@@ -3351,7 +3321,6 @@ def subeq(self):\n             self.exitRule()\n         return localctx\n \n-\n     class SupeqContext(ParserRuleContext):\n \n         def __init__(self, parser, parent=None, invokingState=-1):\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "django__django-13401", "model_patch": "diff --git a/django/db/models/fields/__init__.py b/django/db/models/fields/__init__.py\nindex 28374272f4..8a8760a25d 100644\n--- a/django/db/models/fields/__init__.py\n+++ b/django/db/models/fields/__init__.py\n@@ -516,16 +516,52 @@ class Field(RegisterLookupMixin):\n     def __eq__(self, other):\n         # Needed for @total_ordering\n         if isinstance(other, Field):\n-            return self.creation_counter == other.creation_counter\n+            # Fields are equal only if they have the same creation_counter\n+            # AND belong to the same model (or both have no model)\n+            if self.creation_counter != other.creation_counter:\n+                return False\n+            \n+            # Handle fields without models (e.g., during creation or aggregation)\n+            self_has_model = hasattr(self, 'model')\n+            other_has_model = hasattr(other, 'model')\n+            \n+            if not self_has_model and not other_has_model:\n+                return True  # Both have no model, equal based on creation_counter\n+            elif not self_has_model or not other_has_model:\n+                return False  # One has model, other doesn't\n+            else:\n+                return self.model == other.model  # Both have models, compare them\n         return NotImplemented\n \n     def __lt__(self, other):\n         # This is needed because bisect does not take a comparison function.\n         if isinstance(other, Field):\n-            return self.creation_counter < other.creation_counter\n+            # Order first by creation_counter to preserve existing ordering for unaffected cases\n+            if self.creation_counter != other.creation_counter:\n+                return self.creation_counter < other.creation_counter\n+            \n+            # If creation_counters are equal, order by model to ensure consistent ordering\n+            self_has_model = hasattr(self, 'model')\n+            other_has_model = hasattr(other, 'model')\n+            \n+            if not self_has_model and not other_has_model:\n+                return False  # Both have no model, equal based on creation_counter\n+            elif not self_has_model:\n+                return True   # self has no model, other has model - self comes first\n+            elif not other_has_model:\n+                return False  # other has no model, self has model - other comes first\n+            else:\n+                # Both have models, compare them\n+                # Use model name as string comparison for consistent ordering\n+                self_model_name = f\"{self.model._meta.app_label}.{self.model._meta.object_name}\"\n+                other_model_name = f\"{other.model._meta.app_label}.{other.model._meta.object_name}\"\n+                return self_model_name < other_model_name\n         return NotImplemented\n \n     def __hash__(self):\n+        # Include both creation_counter and model in hash to maintain hash/equality contract\n+        if hasattr(self, 'model'):\n+            return hash((self.creation_counter, self.model))\n         return hash(self.creation_counter)\n \n     def __deepcopy__(self, memodict):\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "sympy__sympy-13647", "model_patch": "diff --git a/sympy/matrices/common.py b/sympy/matrices/common.py\nindex 056d9bc49..14b1d15c6 100644\n--- a/sympy/matrices/common.py\n+++ b/sympy/matrices/common.py\n@@ -86,10 +86,10 @@ def entry(i, j):\n                 return self[i, j]\n             elif pos <= j < pos + other.cols:\n                 return other[i, j - pos]\n-            return self[i, j - pos - other.cols]\n+            return self[i, j - other.cols]\n \n-        return self._new(self.rows, self.cols + other.cols,\n-                         lambda i, j: entry(i, j))\n+        return classof(self, other)._new(self.rows, self.cols + other.cols,\n+                                         lambda i, j: entry(i, j))\n \n     def _eval_col_join(self, other):\n         rows = self.rows\n@@ -144,7 +144,7 @@ def _eval_row_insert(self, pos, other):\n         entries = list(self)\n         insert_pos = pos * self.cols\n         entries[insert_pos:insert_pos] = list(other)\n-        return self._new(self.rows + other.rows, self.cols, entries)\n+        return classof(self, other)._new(self.rows + other.rows, self.cols, entries)\n \n     def _eval_row_join(self, other):\n         cols = self.cols\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "django__django-14017", "model_patch": "diff --git a/django/db/models/query_utils.py b/django/db/models/query_utils.py\nindex c957ffa564..8a0d845ee9 100644\n--- a/django/db/models/query_utils.py\n+++ b/django/db/models/query_utils.py\n@@ -49,8 +49,18 @@ class Q(tree.Node):\n             return type(self)(*args, **kwargs)\n         # Or if this Q is empty, ignore it and just use `other`.\n         elif not self:\n-            _, args, kwargs = other.deconstruct()\n-            return type(other)(*args, **kwargs)\n+            # For complex expressions that can't be deconstructed, return a copy of other\n+            try:\n+                _, args, kwargs = other.deconstruct()\n+                return type(other)(*args, **kwargs)\n+            except (TypeError, IndexError):\n+                # If deconstruction fails, create a new Q object and copy the children\n+                new_obj = type(other)()\n+                new_obj.connector = other.connector\n+                new_obj.negated = other.negated\n+                for child in other.children:\n+                    new_obj.children.append(child)\n+                return new_obj\n \n         obj = type(self)()\n         obj.connector = conn\n@@ -59,11 +69,33 @@ class Q(tree.Node):\n         return obj\n \n     def __or__(self, other):\n+        # Only convert conditional expressions that are not already Q objects\n+        if getattr(other, 'conditional', False) and not isinstance(other, Q):\n+            # Convert conditional expression to Q and combine\n+            return self._combine(Q(other), self.OR)\n         return self._combine(other, self.OR)\n \n     def __and__(self, other):\n+        # Only convert conditional expressions that are not already Q objects\n+        if getattr(other, 'conditional', False) and not isinstance(other, Q):\n+            # Convert conditional expression to Q and combine\n+            return self._combine(Q(other), self.AND)\n         return self._combine(other, self.AND)\n \n+    def __rand__(self, other):\n+        \"\"\"Handle reverse AND operation: other & self.\"\"\"\n+        if getattr(other, 'conditional', False) and not isinstance(other, Q):\n+            # Convert conditional expression to Q and combine\n+            return self._combine(Q(other), self.AND)\n+        return NotImplemented\n+\n+    def __ror__(self, other):\n+        \"\"\"Handle reverse OR operation: other | self.\"\"\"\n+        if getattr(other, 'conditional', False) and not isinstance(other, Q):\n+            # Convert conditional expression to Q and combine\n+            return self._combine(Q(other), self.OR)\n+        return NotImplemented\n+\n     def __invert__(self):\n         obj = type(self)()\n         obj.add(self, self.AND)\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "sympy__sympy-13480", "model_patch": "diff --git a/sympy/functions/elementary/hyperbolic.py b/sympy/functions/elementary/hyperbolic.py\nindex 2a4555d919..5fbb73c786 100644\n--- a/sympy/functions/elementary/hyperbolic.py\n+++ b/sympy/functions/elementary/hyperbolic.py\n@@ -587,7 +587,7 @@ def eval(cls, arg):\n                 x, m = _peeloff_ipi(arg)\n                 if m:\n                     cothm = coth(m)\n-                    if cotm is S.ComplexInfinity:\n+                    if cothm is S.ComplexInfinity:\n                         return coth(x)\n                     else: # cothm == 0\n                         return tanh(x)\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "scikit-learn__scikit-learn-13496", "model_patch": "diff --git a/sklearn/ensemble/iforest.py b/sklearn/ensemble/iforest.py\nindex 8a1bd3625..f42c80532 100644\n--- a/sklearn/ensemble/iforest.py\n+++ b/sklearn/ensemble/iforest.py\n@@ -120,6 +120,11 @@ class IsolationForest(BaseBagging, OutlierMixin):\n     verbose : int, optional (default=0)\n         Controls the verbosity of the tree building process.\n \n+    warm_start : bool, optional (default=False)\n+        When set to ``True``, reuse the solution of the previous call to fit\n+        and add more estimators to the ensemble, otherwise, just fit a whole\n+        new forest. See :term:`the Glossary <warm_start>`.\n+\n \n     Attributes\n     ----------\n@@ -173,7 +178,8 @@ class IsolationForest(BaseBagging, OutlierMixin):\n                  n_jobs=None,\n                  behaviour='old',\n                  random_state=None,\n-                 verbose=0):\n+                 verbose=0,\n+                 warm_start=False):\n         super().__init__(\n             base_estimator=ExtraTreeRegressor(\n                 max_features=1,\n@@ -187,7 +193,8 @@ class IsolationForest(BaseBagging, OutlierMixin):\n             max_features=max_features,\n             n_jobs=n_jobs,\n             random_state=random_state,\n-            verbose=verbose)\n+            verbose=verbose,\n+            warm_start=warm_start)\n \n         self.behaviour = behaviour\n         self.contamination = contamination\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "django__django-13590", "model_patch": "diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\nindex 4648daf395..2ba04a32a4 100644\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -1077,10 +1077,15 @@ class Query(BaseExpression):\n         elif isinstance(value, (list, tuple)):\n             # The items of the iterable may be expressions and therefore need\n             # to be resolved independently.\n-            return type(value)(\n+            resolved_values = (\n                 self.resolve_lookup_value(sub_value, can_reuse, allow_joins)\n                 for sub_value in value\n             )\n+            # Named tuples require individual arguments, not an iterator\n+            if isinstance(value, tuple) and hasattr(value, '_fields'):\n+                return type(value)(*resolved_values)\n+            else:\n+                return type(value)(resolved_values)\n         return value\n \n     def solve_lookup_type(self, lookup):\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "sympy__sympy-21847", "model_patch": "diff --git a/sympy/polys/monomials.py b/sympy/polys/monomials.py\nindex 0e84403307..645e324f52 100644\n--- a/sympy/polys/monomials.py\n+++ b/sympy/polys/monomials.py\n@@ -127,7 +127,7 @@ def itermonomials(variables, max_degrees, min_degrees=None):\n                 for variable in item:\n                     if variable != 1:\n                         powers[variable] += 1\n-                if max(powers.values()) >= min_degree:\n+                if sum(p for var, p in powers.items() if var != S.One) >= min_degree:\n                     monomials_list_comm.append(Mul(*item))\n             yield from set(monomials_list_comm)\n         else:\n@@ -139,7 +139,7 @@ def itermonomials(variables, max_degrees, min_degrees=None):\n                 for variable in item:\n                     if variable != 1:\n                         powers[variable] += 1\n-                if max(powers.values()) >= min_degree:\n+                if sum(p for var, p in powers.items() if var != S.One) >= min_degree:\n                     monomials_list_non_comm.append(Mul(*item))\n             yield from set(monomials_list_non_comm)\n     else:\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "django__django-14915", "model_patch": "diff --git a/django/forms/models.py b/django/forms/models.py\nindex 5dcf923c12..bc7e6959e7 100644\n--- a/django/forms/models.py\n+++ b/django/forms/models.py\n@@ -1171,6 +1171,9 @@ class ModelChoiceIteratorValue:\n             other = other.value\n         return self.value == other\n \n+    def __hash__(self):\n+        return hash(self.value)\n+\n \n class ModelChoiceIterator:\n     def __init__(self, field):\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "scikit-learn__scikit-learn-14983", "model_patch": "diff --git a/sklearn/model_selection/_split.py b/sklearn/model_selection/_split.py\nindex c49a3ce6a..d593a12a3 100644\n--- a/sklearn/model_selection/_split.py\n+++ b/sklearn/model_selection/_split.py\n@@ -1163,6 +1163,19 @@ class _RepeatedSplits(metaclass=ABCMeta):\n                      **self.cvargs)\n         return cv.get_n_splits(X, y, groups) * self.n_repeats\n \n+    def __repr__(self):\n+        params = {}\n+        if hasattr(self, 'n_repeats'):\n+            params['n_repeats'] = self.n_repeats\n+        if hasattr(self, 'random_state'):\n+            params['random_state'] = self.random_state\n+        if hasattr(self, 'cvargs'):\n+            for key, value in self.cvargs.items():\n+                if key not in params:\n+                    params[key] = value\n+        sorted_params = {k: params[k] for k in sorted(params)}\n+        class_name = self.__class__.__name__\n+        return '%s(%s)' % (class_name, _pprint(sorted_params, offset=len(class_name)))\n \n class RepeatedKFold(_RepeatedSplits):\n     \"\"\"Repeated K-Fold cross validator.\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "astropy__astropy-12907", "model_patch": "diff --git a/astropy/modeling/separable.py b/astropy/modeling/separable.py\nindex a308e27297..45bea36085 100644\n--- a/astropy/modeling/separable.py\n+++ b/astropy/modeling/separable.py\n@@ -242,7 +242,7 @@ def _cstack(left, right):\n         cright = _coord_matrix(right, 'right', noutp)\n     else:\n         cright = np.zeros((noutp, right.shape[1]))\n-        cright[-right.shape[0]:, -right.shape[1]:] = 1\n+        cright[-right.shape[0]:, -right.shape[1]:] = right\n \n     return np.hstack([cleft, cright])\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "sympy__sympy-23262", "model_patch": "diff --git a/sympy/utilities/lambdify.py b/sympy/utilities/lambdify.py\nindex da67263b19..f147bdf62d 100644\n--- a/sympy/utilities/lambdify.py\n+++ b/sympy/utilities/lambdify.py\n@@ -957,11 +957,15 @@ def _recursive_to_string(doprint, arg):\n     elif iterable(arg):\n         if isinstance(arg, list):\n             left, right = \"[]\"\n+            return left +', '.join(_recursive_to_string(doprint, e) for e in arg) + right\n         elif isinstance(arg, tuple):\n-            left, right = \"()\"\n+            if len(arg) == 1:\n+                return \"(%s,)\" % _recursive_to_string(doprint, arg[0])\n+            else:\n+                left, right = \"()\"\n+                return left +', '.join(_recursive_to_string(doprint, e) for e in arg) + right\n         else:\n             raise NotImplementedError(\"unhandled type: %s, %s\" % (type(arg), arg))\n-        return left +', '.join(_recursive_to_string(doprint, e) for e in arg) + right\n     elif isinstance(arg, str):\n         return arg\n     else:\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "sympy__sympy-24066", "model_patch": "diff --git a/sympy/physics/units/unitsystem.py b/sympy/physics/units/unitsystem.py\nindex 3daf84c108..5a8dbee4be 100644\n--- a/sympy/physics/units/unitsystem.py\n+++ b/sympy/physics/units/unitsystem.py\n@@ -190,10 +190,68 @@ def _collect_factor_and_dimension(self, expr):\n                 dim /= idim**count\n             return factor, dim\n         elif isinstance(expr, Function):\n+            # Collect factors and dimensions for all arguments\n             fds = [self._collect_factor_and_dimension(\n                 arg) for arg in expr.args]\n-            return (expr.func(*(f[0] for f in fds)),\n-                    *(d[1] for d in fds))\n+            func_factors = [f[0] for f in fds]\n+            func_dimensions = [d[1] for d in fds]\n+\n+            # Check if all arguments are dimensionless\n+            all_args_dimensionless = all(\n+                self.get_dimension_system().is_dimensionless(dim) \n+                for dim in func_dimensions\n+            )\n+\n+            # Get the base function name for classification\n+            func_name = str(expr.func)\n+\n+            # Handle transcendental functions (exp, sin, cos, tan, etc.)\n+            # These require dimensionless arguments and return dimensionless results\n+            transcendental_funcs = ['exp', 'sin', 'cos', 'tan', 'cot', 'sec', 'csc', \n+                                   'asin', 'acos', 'atan', 'acot', 'asec', 'acsc',\n+                                   'sinh', 'cosh', 'tanh', 'coth', 'sech', 'csch',\n+                                   'asinh', 'acosh', 'atanh', 'acoth', 'asech', 'acsch']\n+            if func_name in transcendental_funcs:\n+                # All transcendental functions require dimensionless arguments\n+                if not all_args_dimensionless:\n+                    # Find the first non-dimensionless argument (for error message)\n+                    for i, dim in enumerate(func_dimensions):\n+                        if not self.get_dimension_system().is_dimensionless(dim):\n+                            arg_dim = dim\n+                            break\n+                    raise ValueError(\n+                        'Dimension of \"{}\" is {}, '\n+                        'but it should be {}'.format(\n+                            expr.args[i] if i < len(expr.args) else expr,\n+                            arg_dim, Dimension(1)))\n+                # If all arguments are dimensionless, the result is dimensionless\n+                return expr.func(*func_factors), Dimension(1)\n+\n+            # Handle logarithmic functions\n+            elif func_name in ['log', 'ln']:\n+                # Logarithms also require dimensionless arguments and return dimensionless results\n+                if not all_args_dimensionless:\n+                    for i, dim in enumerate(func_dimensions):\n+                        if not self.get_dimension_system().is_dimensionless(dim):\n+                            arg_dim = dim\n+                            break\n+                    raise ValueError(\n+                        'Dimension of \"{}\" is {}, '\n+                        'but it should be {}'.format(\n+                            expr.args[i] if i < len(expr.args) else expr,\n+                            arg_dim, Dimension(1)))\n+                return expr.func(*func_factors), Dimension(1)\n+\n+            # For other functions, apply the original dimensional analysis logic\n+            else:\n+                # If all arguments are dimensionless, the result is dimensionless\n+                if all_args_dimensionless:\n+                    return expr.func(*func_factors), Dimension(1)\n+\n+                # Otherwise, return the function applied to the collected factors and dimensions\n+                # But we need to return exactly 2 values, so handle this carefully\n+                # For now, treat as dimension-preserving function (same as original get_dimensional_expr logic)\n+                return expr.func(*func_factors), func_dimensions[0] if len(func_dimensions) == 1 else Dimension(1)\n         elif isinstance(expr, Dimension):\n             return S.One, expr\n         else:\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "matplotlib__matplotlib-24970", "model_patch": "diff --git a/lib/matplotlib/colors.py b/lib/matplotlib/colors.py\nindex 2d3072da04..f1025bd836 100644\n--- a/lib/matplotlib/colors.py\n+++ b/lib/matplotlib/colors.py\n@@ -727,9 +727,9 @@ class Colormap:\n                 xa = xa.astype(int)\n         # Set the over-range indices before the under-range;\n         # otherwise the under-range values get converted to over-range.\n-        xa[xa > self.N - 1] = self._i_over\n-        xa[xa < 0] = self._i_under\n-        xa[mask_bad] = self._i_bad\n+        xa[xa > self.N - 1] = np.array(self._i_over).astype(xa.dtype)\n+        xa[xa < 0] = np.array(self._i_under).astype(xa.dtype)\n+        xa[mask_bad] = np.array(self._i_bad).astype(xa.dtype)\n \n         lut = self._lut\n         if bytes:\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "matplotlib__matplotlib-24149", "model_patch": "diff --git a/lib/matplotlib/axes/_axes.py b/lib/matplotlib/axes/_axes.py\nindex fdac0f3560..3a61e89e14 100644\n--- a/lib/matplotlib/axes/_axes.py\n+++ b/lib/matplotlib/axes/_axes.py\n@@ -2180,12 +2180,12 @@ class Axes(_AxesBase):\n             # wrap numpy arrays.\n             try:\n                 x0 = cbook._safe_first_finite(x0)\n-            except (TypeError, IndexError, KeyError):\n+            except (TypeError, IndexError, KeyError, StopIteration):\n                 pass\n \n             try:\n                 x = cbook._safe_first_finite(xconv)\n-            except (TypeError, IndexError, KeyError):\n+            except (TypeError, IndexError, KeyError, StopIteration):\n                 x = xconv\n \n             delist = False\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "django__django-16139", "model_patch": "diff --git a/django/contrib/auth/forms.py b/django/contrib/auth/forms.py\nindex b3cfc6723c..f6c4b7fc2f 100644\n--- a/django/contrib/auth/forms.py\n+++ b/django/contrib/auth/forms.py\n@@ -163,7 +163,7 @@ class UserChangeForm(forms.ModelForm):\n         super().__init__(*args, **kwargs)\n         password = self.fields.get(\"password\")\n         if password:\n-            password.help_text = password.help_text.format(\"../password/\")\n+            password.help_text = password.help_text.format(f\"../../{self.instance.pk}/password/\")\n         user_permissions = self.fields.get(\"user_permissions\")\n         if user_permissions:\n             user_permissions.queryset = user_permissions.queryset.select_related(\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "pytest-dev__pytest-7490", "model_patch": "diff --git a/src/_pytest/skipping.py b/src/_pytest/skipping.py\nindex 335e10996..9ceb783ea 100644\n--- a/src/_pytest/skipping.py\n+++ b/src/_pytest/skipping.py\n@@ -228,6 +228,9 @@ skipped_by_mark_key = StoreKey[bool]()\n xfailed_key = StoreKey[Optional[Xfail]]()\n unexpectedsuccess_key = StoreKey[str]()\n \n+# Sentinel object to represent \"never evaluated\" state\n+_xfailed_sentinel = object()\n+\n \n @hookimpl(tryfirst=True)\n def pytest_runtest_setup(item: Item) -> None:\n@@ -239,16 +242,31 @@ def pytest_runtest_setup(item: Item) -> None:\n         skip(skipped.reason)\n \n     if not item.config.option.runxfail:\n-        item._store[xfailed_key] = xfailed = evaluate_xfail_marks(item)\n-        if xfailed and not xfailed.run:\n-            xfail(\"[NOTRUN] \" + xfailed.reason)\n+        xfailed = evaluate_xfail_marks(item)\n+        if xfailed:\n+            item._store[xfailed_key] = xfailed\n+            if not xfailed.run:\n+                xfail(\"[NOTRUN] \" + xfailed.reason)\n+        else:\n+            # Use sentinel to indicate \"evaluated but found no xfail marks\"\n+            # This allows re-evaluation during call phase if markers are added dynamically\n+            item._store[xfailed_key] = None\n \n \n @hookimpl(hookwrapper=True)\n def pytest_runtest_call(item: Item) -> Generator[None, None, None]:\n-    xfailed = item._store.get(xfailed_key, None)\n-    if xfailed is None:\n-        item._store[xfailed_key] = xfailed = evaluate_xfail_marks(item)\n+    if xfailed_key in item._store:\n+        # Already evaluated in setup phase\n+        xfailed = item._store[xfailed_key]\n+        if xfailed is None:\n+            # Found no xfail marks during setup, but re-evaluate in case \n+            # markers were added dynamically during test execution\n+            xfailed = evaluate_xfail_marks(item)\n+            item._store[xfailed_key] = xfailed\n+    else:\n+        # Never evaluated - evaluate now\n+        xfailed = evaluate_xfail_marks(item)\n+        item._store[xfailed_key] = xfailed\n \n     if not item.config.option.runxfail:\n         if xfailed and not xfailed.run:\n@@ -262,6 +280,9 @@ def pytest_runtest_makereport(item: Item, call: CallInfo[None]):\n     outcome = yield\n     rep = outcome.get_result()\n     xfailed = item._store.get(xfailed_key, None)\n+    # If test failed and we have no xfail info, re-evaluate in case markers were added\n+    if call.when == \"call\" and call.excinfo and xfailed is None:\n+        xfailed = evaluate_xfail_marks(item)\n     # unittest special case, see setting of unexpectedsuccess_key\n     if unexpectedsuccess_key in item._store and rep.when == \"call\":\n         reason = item._store[unexpectedsuccess_key]\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "sympy__sympy-12419", "model_patch": "diff --git a/sympy/matrices/expressions/matexpr.py b/sympy/matrices/expressions/matexpr.py\nindex b4d759836e..374f755975 100644\n--- a/sympy/matrices/expressions/matexpr.py\n+++ b/sympy/matrices/expressions/matexpr.py\n@@ -6,7 +6,7 @@\n from sympy.core.decorators import call_highest_priority\n from sympy.core.compatibility import range\n from sympy.core.sympify import SympifyError, sympify\n-from sympy.functions import conjugate, adjoint\n+from sympy.functions import conjugate, adjoint, KroneckerDelta\n from sympy.matrices import ShapeError\n from sympy.simplify import simplify\n \n@@ -476,10 +476,7 @@ def conjugate(self):\n         return self\n \n     def _entry(self, i, j):\n-        if i == j:\n-            return S.One\n-        else:\n-            return S.Zero\n+        return KroneckerDelta(i, j)\n \n     def _eval_determinant(self):\n         return S.One\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "astropy__astropy-14365", "model_patch": "diff --git a/astropy/io/ascii/qdp.py b/astropy/io/ascii/qdp.py\nindex 83a4f004aa..768beb0de9 100644\n--- a/astropy/io/ascii/qdp.py\n+++ b/astropy/io/ascii/qdp.py\n@@ -68,7 +68,7 @@ def _line_type(line, delimiter=None):\n     _new_re = rf\"NO({sep}NO)+\"\n     _data_re = rf\"({_decimal_re}|NO|[-+]?nan)({sep}({_decimal_re}|NO|[-+]?nan))*)\"\n     _type_re = rf\"^\\s*((?P<command>{_command_re})|(?P<new>{_new_re})|(?P<data>{_data_re})?\\s*(\\!(?P<comment>.*))?\\s*$\"\n-    _line_type_re = re.compile(_type_re)\n+    _line_type_re = re.compile(_type_re, re.IGNORECASE)\n     line = line.strip()\n     if not line:\n         return \"comment\"\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "django__django-15252", "model_patch": "diff --git a/django/db/migrations/recorder.py b/django/db/migrations/recorder.py\nindex 1a37c6b7d0..03c2a0b13e 100644\n--- a/django/db/migrations/recorder.py\n+++ b/django/db/migrations/recorder.py\n@@ -1,5 +1,5 @@\n from django.apps.registry import Apps\n-from django.db import DatabaseError, models\n+from django.db import DatabaseError, models, router\n from django.utils.functional import classproperty\n from django.utils.timezone import now\n \n@@ -62,6 +62,9 @@ class MigrationRecorder:\n         # in the codebase.\n         if self.has_table():\n             return\n+        # Check if migration is allowed on this database\n+        if not router.allow_migrate_model(self.connection.alias, self.Migration):\n+            return\n         # Make the table\n         try:\n             with self.connection.schema_editor() as editor:\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "sympy__sympy-20154", "model_patch": "diff --git a/sympy/utilities/iterables.py b/sympy/utilities/iterables.py\nindex dd36dea304..bb8c47122e 100644\n--- a/sympy/utilities/iterables.py\n+++ b/sympy/utilities/iterables.py\n@@ -1738,19 +1738,9 @@ def partitions(n, m=None, k=None, size=False):\n     {2: 1, 4: 1}\n     {3: 2}\n \n-    Note that the _same_ dictionary object is returned each time.\n-    This is for speed:  generating each partition goes quickly,\n-    taking constant time, independent of n.\n-\n-    >>> [p for p in partitions(6, k=2)]\n-    [{1: 6}, {1: 6}, {1: 6}, {1: 6}]\n-\n-    If you want to build a list of the returned dictionaries then\n-    make a copy of them:\n-\n-    >>> [p.copy() for p in partitions(6, k=2)]  # doctest: +SKIP\n+    >>> [p for p in partitions(6, k=2)]  # doctest: +SKIP\n     [{2: 3}, {1: 2, 2: 2}, {1: 4, 2: 1}, {1: 6}]\n-    >>> [(M, p.copy()) for M, p in partitions(6, k=2, size=True)]  # doctest: +SKIP\n+    >>> [(M, p) for M, p in partitions(6, k=2, size=True)]  # doctest: +SKIP\n     [(3, {2: 3}), (4, {1: 2, 2: 2}), (5, {1: 4, 2: 1}), (6, {1: 6})]\n \n     References\n@@ -1802,9 +1792,9 @@ def partitions(n, m=None, k=None, size=False):\n         keys.append(r)\n     room = m - q - bool(r)\n     if size:\n-        yield sum(ms.values()), ms\n+        yield sum(ms.values()), ms.copy()\n     else:\n-        yield ms\n+        yield ms.copy()\n \n     while keys != [1]:\n         # Reuse any 1's.\n@@ -1842,9 +1832,9 @@ def partitions(n, m=None, k=None, size=False):\n             break\n         room -= need\n         if size:\n-            yield sum(ms.values()), ms\n+            yield sum(ms.values()), ms.copy()\n         else:\n-            yield ms\n+            yield ms.copy()\n \n \n def ordered_partitions(n, m=None, sort=True):\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "matplotlib__matplotlib-25311", "model_patch": "diff --git a/lib/matplotlib/offsetbox.py b/lib/matplotlib/offsetbox.py\nindex 1dee8a23d9..eeafaeb110 100644\n--- a/lib/matplotlib/offsetbox.py\n+++ b/lib/matplotlib/offsetbox.py\n@@ -1580,6 +1580,36 @@ class DraggableBase:\n     def finalize_offset(self):\n         pass\n \n+    def __getstate__(self):\n+        \"\"\"\n+        Custom serialization method to handle unpicklable canvas reference.\n+        \n+        The canvas reference (especially Qt backends) cannot be pickled.\n+        This method removes the canvas from the state during pickling,\n+        similar to how Figure.__getstate__ handles it.\n+        \"\"\"\n+        state = self.__dict__.copy()\n+        # Remove the unpicklable canvas reference\n+        state.pop('canvas', None)\n+        return state\n+\n+    def __setstate__(self, state):\n+        \"\"\"\n+        Custom deserialization method to restore canvas reference.\n+        \n+        Restores the canvas reference from the ref_artist.figure.canvas\n+        after unpickling, ensuring the draggable functionality works.\n+        \"\"\"\n+        self.__dict__ = state\n+        # Restore the canvas reference from the ref_artist\n+        # The figure should be restored by the time this is called\n+        if hasattr(self.ref_artist, 'figure') and self.ref_artist.figure is not None:\n+            self.canvas = self.ref_artist.figure.canvas\n+        else:\n+            # If figure is not available yet, we'll restore it lazily\n+            # For now, just set it to None to avoid errors\n+            self.canvas = None\n+\n \n class DraggableOffsetBox(DraggableBase):\n     def __init__(self, ref_artist, offsetbox, use_blit=False):\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "matplotlib__matplotlib-25332", "model_patch": "diff --git a/lib/matplotlib/cbook.py b/lib/matplotlib/cbook.py\nindex c9699b2e21..b2000e6a73 100644\n--- a/lib/matplotlib/cbook.py\n+++ b/lib/matplotlib/cbook.py\n@@ -846,6 +846,40 @@ class Grouper:\n         siblings = self._mapping.get(weakref.ref(a), [weakref.ref(a)])\n         return [x() for x in siblings]\n \n+    def __getstate__(self):\n+        \"\"\"\n+        Adjust the object's state for pickling by converting weakrefs to strong references.\n+        \n+        This follows the same pattern established in CallbackRegistry to handle\n+        serialization of objects containing weak references.\n+        \"\"\"\n+        state = vars(self).copy()\n+        # Clean dead references first\n+        self.clean()\n+        # Convert weakrefs to strong references for pickling\n+        state['_mapping'] = {\n+            key(): [ref() for ref in value if ref() is not None]\n+            for key, value in self._mapping.items()\n+            if key() is not None and any(ref() is not None for ref in value)\n+        }\n+        return state\n+\n+    def __setstate__(self, state):\n+        \"\"\"\n+        Restore the object's state after unpickling by converting strong references\n+        back to weak references.\n+        \n+        This follows the same pattern established in CallbackRegistry to handle\n+        deserialization of objects containing weak references.\n+        \"\"\"\n+        vars(self).update(state)\n+        # Convert strong references back to weakrefs\n+        self._mapping = {\n+            weakref.ref(key): [weakref.ref(elem) for elem in value]\n+            for key, value in state['_mapping'].items()\n+            if key is not None\n+        }\n+\n \n class GrouperView:\n     \"\"\"Immutable view over a `.Grouper`.\"\"\"\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "django__django-14580", "model_patch": "diff --git a/django/db/migrations/serializer.py b/django/db/migrations/serializer.py\nindex e19c881cda..072a2efc14 100644\n--- a/django/db/migrations/serializer.py\n+++ b/django/db/migrations/serializer.py\n@@ -273,7 +273,7 @@ class TupleSerializer(BaseSequenceSerializer):\n class TypeSerializer(BaseSerializer):\n     def serialize(self):\n         special_cases = [\n-            (models.Model, \"models.Model\", []),\n+            (models.Model, \"models.Model\", [\"from django.db import models\"]),\n             (type(None), 'type(None)', []),\n         ]\n         for case, string, imports in special_cases:\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "django__django-12125", "model_patch": "diff --git a/django/db/migrations/serializer.py b/django/db/migrations/serializer.py\nindex 7d226955d5..755b86822f 100644\n--- a/django/db/migrations/serializer.py\n+++ b/django/db/migrations/serializer.py\n@@ -90,7 +90,22 @@ class DeconstructableSerializer(BaseSerializer):\n \n     @staticmethod\n     def _serialize_path(path):\n-        module, name = path.rsplit(\".\", 1)\n+        parts = path.split(\".\")\n+        module_parts = []\n+        name_parts = []\n+        for i, part in enumerate(parts):\n+            potential_module = \".\".join(parts[:i+1])\n+            try:\n+                __import__(potential_module)\n+                module_parts = parts[:i+1]\n+                name_parts = parts[i+1:]\n+            except ImportError:\n+                break\n+        if module_parts:\n+            module = \".\".join(module_parts)\n+            name = \".\".join(name_parts) if name_parts else module_parts[-1]\n+        else:\n+            module, name = path.rsplit(\".\", 1)\n         if module == \"django.db.models\":\n             imports = {\"from django.db import models\"}\n             name = \"models.%s\" % name\n@@ -266,10 +281,11 @@ class TypeSerializer(BaseSerializer):\n                 return string, set(imports)\n         if hasattr(self.value, \"__module__\"):\n             module = self.value.__module__\n+            qualname = getattr(self.value, \"__qualname__\", self.value.__name__)\n             if module == builtins.__name__:\n-                return self.value.__name__, set()\n+                return qualname, set()\n             else:\n-                return \"%s.%s\" % (module, self.value.__name__), {\"import %s\" % module}\n+                return \"%s.%s\" % (module, qualname), {\"import %s\" % module}\n \n \n class UUIDSerializer(BaseSerializer):\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "django__django-13033", "model_patch": "diff --git a/django/db/models/sql/compiler.py b/django/db/models/sql/compiler.py\nindex abbb1e37cb..edc283d94c 100644\n--- a/django/db/models/sql/compiler.py\n+++ b/django/db/models/sql/compiler.py\n@@ -727,7 +727,7 @@ class SQLCompiler:\n         # If we get to this point and the field is a relation to another model,\n         # append the default ordering for that model unless it is the pk\n         # shortcut or the attribute name of the field that is specified.\n-        if field.is_relation and opts.ordering and getattr(field, 'attname', None) != name and name != 'pk':\n+        if field.is_relation and opts.ordering and getattr(field, 'attname', None) != pieces[-1] and pieces[-1] != 'pk':\n             # Firstly, avoid infinite loops.\n             already_seen = already_seen or set()\n             join_tuple = tuple(getattr(self.query.alias_map[j], 'join_cols', None) for j in joins)\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "matplotlib__matplotlib-23314", "model_patch": "diff --git a/lib/mpl_toolkits/mplot3d/axes3d.py b/lib/mpl_toolkits/mplot3d/axes3d.py\nindex 9db44b7994..5479bc1af0 100644\n--- a/lib/mpl_toolkits/mplot3d/axes3d.py\n+++ b/lib/mpl_toolkits/mplot3d/axes3d.py\n@@ -387,6 +387,8 @@ class Axes3D(Axes):\n \n     @martist.allow_rasterization\n     def draw(self, renderer):\n+        if not self.get_visible():\n+            return\n         self._unstale_viewLim()\n \n         # draw the background patch\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "astropy__astropy-14182", "model_patch": "diff --git a/astropy/io/ascii/rst.py b/astropy/io/ascii/rst.py\nindex abdeba8efb..4201ff0915 100644\n--- a/astropy/io/ascii/rst.py\n+++ b/astropy/io/ascii/rst.py\n@@ -57,10 +57,27 @@ class RST(FixedWidth):\n     data_class = SimpleRSTData\n     header_class = SimpleRSTHeader\n \n-    def __init__(self):\n-        super().__init__(delimiter_pad=None, bookend=False)\n+    def __init__(self, header_rows=None):\n+        super().__init__(delimiter_pad=None, bookend=False, header_rows=header_rows)\n \n     def write(self, lines):\n         lines = super().write(lines)\n-        lines = [lines[1]] + lines + [lines[1]]\n+        # RST format requires the separator line at the top and bottom\n+        # The separator is always the line immediately after the header rows\n+        # In standard RST without header_rows, this is index 1\n+        # With header_rows, we need to find where the header lines end and data starts\n+        \n+        # Find the separator line (the one with equal signs or dashes)\n+        separator_line_idx = None\n+        for i, line in enumerate(lines):\n+            if line.strip().startswith('=') or line.strip().startswith('-'):\n+                separator_line_idx = i\n+                break\n+        \n+        # Fallback to default RST behavior if no separator found\n+        if separator_line_idx is None:\n+            separator_line_idx = min(1, len(lines) - 1)\n+            \n+        separator_line = lines[separator_line_idx]\n+        lines = [separator_line] + lines + [separator_line]\n         return lines\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "django__django-13933", "model_patch": "diff --git a/django/forms/models.py b/django/forms/models.py\nindex 422bc5d178..bcf591593f 100644\n--- a/django/forms/models.py\n+++ b/django/forms/models.py\n@@ -1188,7 +1188,7 @@ class ModelChoiceField(ChoiceField):\n     # This class is a subclass of ChoiceField for purity, but it doesn't\n     # actually use any of ChoiceField's implementation.\n     default_error_messages = {\n-        'invalid_choice': _('Select a valid choice. That choice is not one of'\n+        'invalid_choice': _('Select a valid choice. %(value)s is not one of'\n                             ' the available choices.'),\n     }\n     iterator = ModelChoiceIterator\n@@ -1284,7 +1284,7 @@ class ModelChoiceField(ChoiceField):\n                 value = getattr(value, key)\n             value = self.queryset.get(**{key: value})\n         except (ValueError, TypeError, self.queryset.model.DoesNotExist):\n-            raise ValidationError(self.error_messages['invalid_choice'], code='invalid_choice')\n+            raise ValidationError(self.error_messages['invalid_choice'], code='invalid_choice', params={'value': value})\n         return value\n \n     def validate(self, value):\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "sphinx-doc__sphinx-8595", "model_patch": "diff --git a/sphinx/ext/autodoc/__init__.py b/sphinx/ext/autodoc/__init__.py\nindex d85d79617..c9f90acca 100644\n--- a/sphinx/ext/autodoc/__init__.py\n+++ b/sphinx/ext/autodoc/__init__.py\n@@ -1074,7 +1074,7 @@ class ModuleDocumenter(Documenter):\n     def get_object_members(self, want_all: bool) -> Tuple[bool, ObjectMembers]:\n         members = self.get_module_members()\n         if want_all:\n-            if not self.__all__:\n+            if self.__all__ is None:\n                 # for implicit module members, check __module__ to avoid\n                 # documenting imported objects\n                 return True, list(members.values())\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "pylint-dev__pylint-7080", "model_patch": "diff --git a/pylint/lint/pylinter.py b/pylint/lint/pylinter.py\nindex e2bbf061e..ca90036f6 100644\n--- a/pylint/lint/pylinter.py\n+++ b/pylint/lint/pylinter.py\n@@ -610,11 +610,16 @@ class PyLinter(\n                         skip_subtrees.append(root)\n                         yield root\n                     else:\n-                        yield from (\n-                            os.path.join(root, file)\n-                            for file in files\n-                            if file.endswith(\".py\")\n-                        )\n+                        for file in files:\n+                            if file.endswith(\".py\"):\n+                                file_path = os.path.join(root, file)\n+                                if not _is_ignored_file(\n+                                    file_path,\n+                                    self.config.ignore,\n+                                    self.config.ignore_patterns,\n+                                    self.config.ignore_paths,\n+                                ):\n+                                    yield file_path\n             else:\n                 yield something\n \n@@ -1011,7 +1016,7 @@ class PyLinter(\n                 self.config.extension_pkg_whitelist\n             )\n         self.stats.reset_message_count()\n-        self._ignore_paths = self.linter.config.ignore_paths\n+        self._ignore_paths = self.config.ignore_paths\n \n     def generate_reports(self) -> int | None:\n         \"\"\"Close the whole package /module, it's time to make reports !\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "django__django-11815", "model_patch": "diff --git a/django/db/migrations/serializer.py b/django/db/migrations/serializer.py\nindex 27b5cbd379..4622b0fcd8 100644\n--- a/django/db/migrations/serializer.py\n+++ b/django/db/migrations/serializer.py\n@@ -120,9 +120,9 @@ class EnumSerializer(BaseSerializer):\n     def serialize(self):\n         enum_class = self.value.__class__\n         module = enum_class.__module__\n-        v_string, v_imports = serializer_factory(self.value.value).serialize()\n+        v_string, v_imports = serializer_factory(self.value.name).serialize()\n         imports = {'import %s' % module, *v_imports}\n-        return \"%s.%s(%s)\" % (module, enum_class.__name__, v_string), imports\n+        return \"%s.%s[%s]\" % (module, enum_class.__name__, v_string), imports\n \n \n class FloatSerializer(BaseSimpleSerializer):\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "django__django-17087", "model_patch": "diff --git a/django/db/migrations/serializer.py b/django/db/migrations/serializer.py\nindex d88cda6e20..06657ebaab 100644\n--- a/django/db/migrations/serializer.py\n+++ b/django/db/migrations/serializer.py\n@@ -168,7 +168,7 @@ class FunctionTypeSerializer(BaseSerializer):\n         ):\n             klass = self.value.__self__\n             module = klass.__module__\n-            return \"%s.%s.%s\" % (module, klass.__name__, self.value.__name__), {\n+            return \"%s.%s.%s\" % (module, klass.__qualname__, self.value.__name__), {\n                 \"import %s\" % module\n             }\n         # Further error checking\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "django__django-15851", "model_patch": "diff --git a/django/db/backends/mysql/client.py b/django/db/backends/mysql/client.py\nindex 6aa11b2e1f..3d8c1bf1ad 100644\n--- a/django/db/backends/mysql/client.py\n+++ b/django/db/backends/mysql/client.py\n@@ -56,9 +56,9 @@ class DatabaseClient(BaseDatabaseClient):\n             args += [\"--ssl-key=%s\" % client_key]\n         if charset:\n             args += [\"--default-character-set=%s\" % charset]\n+        args.extend(parameters)\n         if database:\n             args += [database]\n-        args.extend(parameters)\n         return args, env\n \n     def runshell(self, parameters):\ndiff --git a/django/db/backends/oracle/client.py b/django/db/backends/oracle/client.py\nindex 365b116046..30aa060c8a 100644\n--- a/django/db/backends/oracle/client.py\n+++ b/django/db/backends/oracle/client.py\n@@ -19,9 +19,10 @@ class DatabaseClient(BaseDatabaseClient):\n \n     @classmethod\n     def settings_to_cmd_args_env(cls, settings_dict, parameters):\n-        args = [cls.executable_name, \"-L\", cls.connect_string(settings_dict)]\n+        args = [cls.executable_name, \"-L\"]\n         wrapper_path = shutil.which(cls.wrapper_name)\n         if wrapper_path:\n             args = [wrapper_path, *args]\n         args.extend(parameters)\n+        args.append(cls.connect_string(settings_dict))\n         return args, None\ndiff --git a/django/db/backends/postgresql/client.py b/django/db/backends/postgresql/client.py\nindex 4c9bd63546..3b5ddafaca 100644\n--- a/django/db/backends/postgresql/client.py\n+++ b/django/db/backends/postgresql/client.py\n@@ -32,9 +32,9 @@ class DatabaseClient(BaseDatabaseClient):\n             args += [\"-h\", host]\n         if port:\n             args += [\"-p\", str(port)]\n+        args.extend(parameters)\n         if dbname:\n             args += [dbname]\n-        args.extend(parameters)\n \n         env = {}\n         if passwd:\ndiff --git a/django/db/backends/sqlite3/client.py b/django/db/backends/sqlite3/client.py\nindex 7cee35dc81..3f04766cdd 100644\n--- a/django/db/backends/sqlite3/client.py\n+++ b/django/db/backends/sqlite3/client.py\n@@ -6,5 +6,5 @@ class DatabaseClient(BaseDatabaseClient):\n \n     @classmethod\n     def settings_to_cmd_args_env(cls, settings_dict, parameters):\n-        args = [cls.executable_name, settings_dict[\"NAME\"], *parameters]\n+        args = [cls.executable_name, *parameters, settings_dict[\"NAME\"]]\n         return args, None\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "django__django-14672", "model_patch": "diff --git a/django/db/models/fields/reverse_related.py b/django/db/models/fields/reverse_related.py\nindex ccc2223a5f..65950590e2 100644\n--- a/django/db/models/fields/reverse_related.py\n+++ b/django/db/models/fields/reverse_related.py\n@@ -310,7 +310,7 @@ class ManyToManyRel(ForeignObjectRel):\n     def identity(self):\n         return super().identity + (\n             self.through,\n-            self.through_fields,\n+            make_hashable(self.through_fields),\n             self.db_constraint,\n         )\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "django__django-14752", "model_patch": "diff --git a/django/contrib/admin/views/autocomplete.py b/django/contrib/admin/views/autocomplete.py\nindex 3903e4c98c..a12ff01be5 100644\n--- a/django/contrib/admin/views/autocomplete.py\n+++ b/django/contrib/admin/views/autocomplete.py\n@@ -26,12 +26,15 @@ class AutocompleteJsonView(BaseListView):\n         context = self.get_context_data()\n         return JsonResponse({\n             'results': [\n-                {'id': str(getattr(obj, to_field_name)), 'text': str(obj)}\n-                for obj in context['object_list']\n+                self.serialize_result(obj, to_field_name) for obj in context['object_list']\n             ],\n             'pagination': {'more': context['page_obj'].has_next()},\n         })\n \n+    def serialize_result(self, obj, to_field_name):\n+        \"\"\"Serialize a single result object to dictionary.\"\"\"\n+        return {'id': str(getattr(obj, to_field_name)), 'text': str(obj)}\n+\n     def get_paginator(self, *args, **kwargs):\n         \"\"\"Use the ModelAdmin's paginator.\"\"\"\n         return self.model_admin.get_paginator(self.request, *args, **kwargs)\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "django__django-11099", "model_patch": "diff --git a/django/contrib/auth/validators.py b/django/contrib/auth/validators.py\nindex b4878cfd45..1304f20a60 100644\n--- a/django/contrib/auth/validators.py\n+++ b/django/contrib/auth/validators.py\n@@ -7,7 +7,7 @@ from django.utils.translation import gettext_lazy as _\n \n @deconstructible\n class ASCIIUsernameValidator(validators.RegexValidator):\n-    regex = r'^[\\w.@+-]+$'\n+    regex = r'\\A[\\w.@+-]+\\Z'\n     message = _(\n         'Enter a valid username. This value may contain only English letters, '\n         'numbers, and @/./+/-/_ characters.'\n@@ -17,7 +17,7 @@ class ASCIIUsernameValidator(validators.RegexValidator):\n \n @deconstructible\n class UnicodeUsernameValidator(validators.RegexValidator):\n-    regex = r'^[\\w.@+-]+$'\n+    regex = r'\\A[\\w.@+-]+\\Z'\n     message = _(\n         'Enter a valid username. This value may contain only letters, '\n         'numbers, and @/./+/-/_ characters.'\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "django__django-14534", "model_patch": "diff --git a/django/forms/boundfield.py b/django/forms/boundfield.py\nindex 2ff8b0ee26..a8aff2e71c 100644\n--- a/django/forms/boundfield.py\n+++ b/django/forms/boundfield.py\n@@ -277,6 +277,8 @@ class BoundWidget:\n \n     @property\n     def id_for_label(self):\n+        if self.data.get('attrs', {}).get('id'):\n+            return self.data['attrs']['id']\n         return 'id_%s_%s' % (self.data['name'], self.data['index'])\n \n     @property\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "sympy__sympy-12481", "model_patch": "diff --git a/sympy/combinatorics/permutations.py b/sympy/combinatorics/permutations.py\nindex 136ed5a478..4854a07853 100644\n--- a/sympy/combinatorics/permutations.py\n+++ b/sympy/combinatorics/permutations.py\n@@ -896,10 +896,7 @@ def __new__(cls, *args, **kwargs):\n \n         temp = flatten(args)\n         if has_dups(temp):\n-            if is_cycle:\n-                raise ValueError('there were repeated elements; to resolve '\n-                'cycles use Cycle%s.' % ''.join([str(tuple(c)) for c in args]))\n-            else:\n+            if not is_cycle:\n                 raise ValueError('there were repeated elements.')\n         temp = set(temp)\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "pydata__xarray-4094", "model_patch": "diff --git a/xarray/core/dataarray.py b/xarray/core/dataarray.py\nindex b0df8749..c0401847 100644\n--- a/xarray/core/dataarray.py\n+++ b/xarray/core/dataarray.py\n@@ -1961,7 +1961,11 @@ class DataArray(AbstractArray, DataWithCoords):\n         # pull variables out of datarray\n         data_dict = {}\n         for k in variables:\n-            data_dict[k] = self.sel({variable_dim: k}).squeeze(drop=True)\n+            selected = self.sel({variable_dim: k}).squeeze(drop=False)\n+            # Remove the coordinate that came from the MultiIndex level to avoid conflicts\n+            if dim in selected.coords:\n+                selected = selected.drop_vars(dim)\n+            data_dict[k] = selected\n \n         # unstacked dataset\n         return Dataset(data_dict)\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "django__django-13925", "model_patch": "diff --git a/django/db/models/options.py b/django/db/models/options.py\nindex 4028e05b99..ec4d9af941 100644\n--- a/django/db/models/options.py\n+++ b/django/db/models/options.py\n@@ -280,6 +280,8 @@ class Options:\n                 if already_created:\n                     field = already_created[0]\n                 field.primary_key = True\n+                # The field is inherited from parent, not auto-created for this model\n+                field.auto_created = False\n                 self.setup_pk(field)\n             else:\n                 pk_class = self._get_default_pk_class()\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "sympy__sympy-22714", "model_patch": "diff --git a/sympy/geometry/point.py b/sympy/geometry/point.py\nindex 73c20334d0..fd3efcaaa3 100644\n--- a/sympy/geometry/point.py\n+++ b/sympy/geometry/point.py\n@@ -152,8 +152,20 @@ def __new__(cls, *args, **kwargs):\n                         'warn' or 'ignore'.'''))\n         if any(coords[dim:]):\n             raise ValueError('Nonzero coordinates cannot be removed.')\n-        if any(a.is_number and im(a) for a in coords):\n-            raise ValueError('Imaginary coordinates are not permitted.')\n+        # Check for imaginary coordinates, handling unevaluated im() expressions\n+        for a in coords:\n+            if a.is_number:\n+                im_part = im(a)\n+                # If im() returns an unevaluated expression, check if it's actually non-zero\n+                if hasattr(im_part, 'args') and im_part.args:\n+                    # This is an unevaluated im(expression), check if the argument is extended real\n+                    if not (hasattr(im_part.args[0], 'is_extended_real') and \n+                           im_part.args[0].is_extended_real):\n+                        # Argument is not extended real, so this might be genuinely imaginary\n+                        raise ValueError('Imaginary coordinates are not permitted.')\n+                elif im_part != 0:\n+                    # im() returned an evaluated value, check if it's non-zero\n+                    raise ValueError('Imaginary coordinates are not permitted.')\n         if not all(isinstance(a, Expr) for a in coords):\n             raise TypeError('Coordinates must be valid SymPy expressions.')\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "django__django-14855", "model_patch": "diff --git a/django/contrib/admin/helpers.py b/django/contrib/admin/helpers.py\nindex dd154f72ee..35108cc359 100644\n--- a/django/contrib/admin/helpers.py\n+++ b/django/contrib/admin/helpers.py\n@@ -209,7 +209,7 @@ class AdminReadonlyField:\n             remote_field.model._meta.model_name,\n         )\n         try:\n-            url = reverse(url_name, args=[quote(remote_obj.pk)])\n+            url = reverse(url_name, args=[quote(remote_obj.pk)], current_app=self.model_admin.admin_site.name)\n             return format_html('<a href=\"{}\">{}</a>', url, remote_obj)\n         except NoReverseMatch:\n             return str(remote_obj)\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "django__django-16595", "model_patch": "diff --git a/django/db/migrations/operations/fields.py b/django/db/migrations/operations/fields.py\nindex cd3aab43ad..4f3d4c7fcc 100644\n--- a/django/db/migrations/operations/fields.py\n+++ b/django/db/migrations/operations/fields.py\n@@ -251,6 +251,10 @@ class AlterField(FieldOperation):\n             operation\n         ):\n             return [operation]\n+        elif isinstance(operation, AlterField) and self.is_same_field_operation(\n+            operation\n+        ):\n+            return [operation]\n         elif (\n             isinstance(operation, RenameField)\n             and self.is_same_field_operation(operation)\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "scikit-learn__scikit-learn-10297", "model_patch": "diff --git a/sklearn/linear_model/ridge.py b/sklearn/linear_model/ridge.py\nindex 911c74ae3..c0d07ce42 100644\n--- a/sklearn/linear_model/ridge.py\n+++ b/sklearn/linear_model/ridge.py\n@@ -1301,6 +1301,11 @@ class RidgeClassifierCV(LinearClassifierMixin, _BaseRidgeCV):\n         weights inversely proportional to class frequencies in the input data\n         as ``n_samples / (n_classes * np.bincount(y))``\n \n+    store_cv_values : boolean, default=False\n+        Flag indicating if the cross-validation values corresponding to\n+        each alpha should be stored. The flag is only compatible with\n+        ``cv=None`` (i.e. using Generalized Cross-Validation).\n+\n     Attributes\n     ----------\n     cv_values_ : array, shape = [n_samples, n_alphas] or \\\n@@ -1333,10 +1338,11 @@ class RidgeClassifierCV(LinearClassifierMixin, _BaseRidgeCV):\n     advantage of the multi-variate response support in Ridge.\n     \"\"\"\n     def __init__(self, alphas=(0.1, 1.0, 10.0), fit_intercept=True,\n-                 normalize=False, scoring=None, cv=None, class_weight=None):\n+                 normalize=False, scoring=None, cv=None, class_weight=None,\n+                 store_cv_values=False):\n         super(RidgeClassifierCV, self).__init__(\n             alphas=alphas, fit_intercept=fit_intercept, normalize=normalize,\n-            scoring=scoring, cv=cv)\n+            scoring=scoring, cv=cv, store_cv_values=store_cv_values)\n         self.class_weight = class_weight\n \n     def fit(self, X, y, sample_weight=None):\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "django__django-14238", "model_patch": "diff --git a/django/db/models/fields/__init__.py b/django/db/models/fields/__init__.py\nindex 0f53d9c30b..597f32956e 100644\n--- a/django/db/models/fields/__init__.py\n+++ b/django/db/models/fields/__init__.py\n@@ -2524,7 +2524,13 @@ class AutoFieldMeta(type):\n         return isinstance(instance, self._subclasses) or super().__instancecheck__(instance)\n \n     def __subclasscheck__(self, subclass):\n-        return subclass in self._subclasses or super().__subclasscheck__(subclass)\n+        if subclass in self._subclasses:\n+            return True\n+        # Check if subclass is a subclass of any field in _subclasses\n+        for base_class in self._subclasses:\n+            if issubclass(subclass, base_class):\n+                return True\n+        return super().__subclasscheck__(subclass)\n \n \n class AutoField(AutoFieldMixin, IntegerField, metaclass=AutoFieldMeta):\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "psf__requests-2317", "model_patch": "diff --git a/requests/sessions.py b/requests/sessions.py\nindex d701ff2e..adcfbac7 100644\n--- a/requests/sessions.py\n+++ b/requests/sessions.py\n@@ -425,7 +425,7 @@ class Session(SessionRedirectMixin):\n             If Tuple, ('cert', 'key') pair.\n         \"\"\"\n \n-        method = builtin_str(method)\n+        method = to_native_string(method)\n \n         # Create the Request.\n         req = Request(\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "django__django-16527", "model_patch": "diff --git a/django/contrib/admin/templatetags/admin_modify.py b/django/contrib/admin/templatetags/admin_modify.py\nindex 9df4b7aadb..5b742af46a 100644\n--- a/django/contrib/admin/templatetags/admin_modify.py\n+++ b/django/contrib/admin/templatetags/admin_modify.py\n@@ -100,6 +100,7 @@ def submit_row(context):\n                 and context.get(\"show_delete\", True)\n             ),\n             \"show_save_as_new\": not is_popup\n+            and has_add_permission\n             and has_change_permission\n             and change\n             and save_as,\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "sphinx-doc__sphinx-8721", "model_patch": "diff --git a/sphinx/ext/viewcode.py b/sphinx/ext/viewcode.py\nindex a7d52a91c..060604e25 100644\n--- a/sphinx/ext/viewcode.py\n+++ b/sphinx/ext/viewcode.py\n@@ -182,6 +182,8 @@ def collect_pages(app: Sphinx) -> Generator[Tuple[str, Dict[str, Any], str], Non\n     env = app.builder.env\n     if not hasattr(env, '_viewcode_modules'):\n         return\n+    if app.builder.name.startswith(\"epub\") and not env.config.viewcode_enable_epub:\n+        return\n     highlighter = app.builder.highlighter  # type: ignore\n     urito = app.builder.get_relative_uri\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "sympy__sympy-17655", "model_patch": "diff --git a/sympy/geometry/point.py b/sympy/geometry/point.py\nindex 7c978c47be..0cf03b5f61 100644\n--- a/sympy/geometry/point.py\n+++ b/sympy/geometry/point.py\n@@ -213,6 +213,22 @@ def __add__(self, other):\n         sympy.geometry.point.Point.translate\n \n         \"\"\"\n+        # Handle Mul expressions containing Points (e.g., scalar * Point)\n+        from sympy.core.mul import Mul\n+        if isinstance(other, Mul):\n+            # Look for Point in the Mul expression\n+            point_arg = None\n+            scalar_arg = None\n+            for arg in other.args:\n+                if hasattr(arg, 'is_Point') and arg.is_Point:\n+                    point_arg = arg\n+                elif isinstance(arg, (int, float)) or hasattr(arg, 'is_Number'):\n+                    scalar_arg = arg\n+            \n+            # If we found both a Point and a scalar, evaluate the multiplication\n+            if point_arg is not None and scalar_arg is not None:\n+                other = point_arg * scalar_arg\n+        \n         try:\n             s, o = Point._normalize_dimension(self, Point(other, evaluate=False))\n         except TypeError:\n@@ -278,6 +294,8 @@ def __mul__(self, factor):\n         coords = [simplify(x*factor) for x in self.args]\n         return Point(coords, evaluate=False)\n \n+    __rmul__ = __mul__\n+\n     def __neg__(self):\n         \"\"\"Negate the point.\"\"\"\n         coords = [-x for x in self.args]\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "django__django-11964", "model_patch": "diff --git a/django/db/models/enums.py b/django/db/models/enums.py\nindex bbe362a6ab..3ce327bfba 100644\n--- a/django/db/models/enums.py\n+++ b/django/db/models/enums.py\n@@ -65,11 +65,14 @@ class Choices(enum.Enum, metaclass=ChoicesMeta):\n \n class IntegerChoices(int, Choices):\n     \"\"\"Class for creating enumerated integer choices.\"\"\"\n-    pass\n+    def __str__(self):\n+        return str(self.value)\n \n \n class TextChoices(str, Choices):\n     \"\"\"Class for creating enumerated string choices.\"\"\"\n+    def __str__(self):\n+        return self.value\n \n     def _generate_next_value_(name, start, count, last_values):\n         return name\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "pytest-dev__pytest-7432", "model_patch": "diff --git a/src/_pytest/skipping.py b/src/_pytest/skipping.py\nindex 7bd975e5a..c9bdfee89 100644\n--- a/src/_pytest/skipping.py\n+++ b/src/_pytest/skipping.py\n@@ -291,7 +291,7 @@ def pytest_runtest_makereport(item: Item, call: CallInfo[None]):\n             else:\n                 rep.outcome = \"passed\"\n                 rep.wasxfail = xfailed.reason\n-    elif (\n+    if (\n         item._store.get(skipped_by_mark_key, True)\n         and rep.skipped\n         and type(rep.longrepr) is tuple\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "django__django-13551", "model_patch": "diff --git a/django/contrib/auth/tokens.py b/django/contrib/auth/tokens.py\nindex 93e2d71af2..d8efb65cee 100644\n--- a/django/contrib/auth/tokens.py\n+++ b/django/contrib/auth/tokens.py\n@@ -85,6 +85,7 @@ class PasswordResetTokenGenerator:\n            same password is chosen, due to password salting).\n         2. The last_login field will usually be updated very shortly after\n            a password reset.\n+        3. The email field will change when the user changes their email address.\n         Failing those things, settings.PASSWORD_RESET_TIMEOUT eventually\n         invalidates the token.\n \n@@ -94,7 +95,9 @@ class PasswordResetTokenGenerator:\n         # Truncate microseconds so that tokens are consistent even if the\n         # database doesn't support microseconds.\n         login_timestamp = '' if user.last_login is None else user.last_login.replace(microsecond=0, tzinfo=None)\n-        return str(user.pk) + user.password + str(login_timestamp) + str(timestamp)\n+        email_field_name = user.get_email_field_name()\n+        email = getattr(user, email_field_name, '') or ''\n+        return str(user.pk) + user.password + str(login_timestamp) + str(timestamp) + email\n \n     def _num_seconds(self, dt):\n         return int((dt - datetime(2001, 1, 1)).total_seconds())\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "django__django-13158", "model_patch": "diff --git a/django/db/models/sql/compiler.py b/django/db/models/sql/compiler.py\nindex 686e75c979..e8e7010a5f 100644\n--- a/django/db/models/sql/compiler.py\n+++ b/django/db/models/sql/compiler.py\n@@ -432,6 +432,9 @@ class SQLCompiler:\n \n     def get_combinator_sql(self, combinator, all):\n         features = self.connection.features\n+        # If the main query is empty, the entire combined result should be empty\n+        if self.query.is_empty() and self.query.combined_queries:\n+            raise EmptyResultSet\n         compilers = [\n             query.get_compiler(self.using, self.connection)\n             for query in self.query.combined_queries if not query.is_empty()\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "sympy__sympy-24213", "model_patch": "diff --git a/sympy/physics/units/unitsystem.py b/sympy/physics/units/unitsystem.py\nindex a436880c4b..5705c821c2 100644\n--- a/sympy/physics/units/unitsystem.py\n+++ b/sympy/physics/units/unitsystem.py\n@@ -175,7 +175,7 @@ def _collect_factor_and_dimension(self, expr):\n             for addend in expr.args[1:]:\n                 addend_factor, addend_dim = \\\n                     self._collect_factor_and_dimension(addend)\n-                if dim != addend_dim:\n+                if not self.get_dimension_system().equivalent_dims(dim, addend_dim):\n                     raise ValueError(\n                         'Dimension of \"{}\" is {}, '\n                         'but it should be {}'.format(\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "django__django-13315", "model_patch": "diff --git a/django/db/models/fields/__init__.py b/django/db/models/fields/__init__.py\nindex 2bce85beef..aaaf4f2002 100644\n--- a/django/db/models/fields/__init__.py\n+++ b/django/db/models/fields/__init__.py\n@@ -880,7 +880,7 @@ class Field(RegisterLookupMixin):\n             if hasattr(self.remote_field, 'get_related_field')\n             else 'pk'\n         )\n-        qs = rel_model._default_manager.complex_filter(limit_choices_to)\n+        qs = rel_model._default_manager.complex_filter(limit_choices_to).distinct()\n         if ordering:\n             qs = qs.order_by(*ordering)\n         return (blank_choice if include_blank else []) + [\ndiff --git a/django/forms/models.py b/django/forms/models.py\nindex 5d115458a1..f993bb9c98 100644\n--- a/django/forms/models.py\n+++ b/django/forms/models.py\n@@ -100,7 +100,7 @@ def apply_limit_choices_to_to_formfield(formfield):\n     if hasattr(formfield, 'queryset') and hasattr(formfield, 'get_limit_choices_to'):\n         limit_choices_to = formfield.get_limit_choices_to()\n         if limit_choices_to is not None:\n-            formfield.queryset = formfield.queryset.complex_filter(limit_choices_to)\n+            formfield.queryset = formfield.queryset.complex_filter(limit_choices_to).distinct()\n \n \n def fields_for_model(model, fields=None, exclude=None, widgets=None,\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "scikit-learn__scikit-learn-13142", "model_patch": "diff --git a/sklearn/mixture/base.py b/sklearn/mixture/base.py\nindex bd34333c0..8920bef18 100644\n--- a/sklearn/mixture/base.py\n+++ b/sklearn/mixture/base.py\n@@ -257,11 +257,6 @@ class BaseMixture(DensityMixin, BaseEstimator, metaclass=ABCMeta):\n                 best_params = self._get_parameters()\n                 best_n_iter = n_iter\n \n-        # Always do a final e-step to guarantee that the labels returned by\n-        # fit_predict(X) are always consistent with fit(X).predict(X)\n-        # for any value of max_iter and tol (and any random_state).\n-        _, log_resp = self._e_step(X)\n-\n         if not self.converged_:\n             warnings.warn('Initialization %d did not converge. '\n                           'Try different init parameters, '\n@@ -273,6 +268,11 @@ class BaseMixture(DensityMixin, BaseEstimator, metaclass=ABCMeta):\n         self.n_iter_ = best_n_iter\n         self.lower_bound_ = max_lower_bound\n \n+        # Always do a final e-step to guarantee that the labels returned by\n+        # fit_predict(X) are always consistent with fit(X).predict(X)\n+        # for any value of max_iter and tol (and any random_state).\n+        _, log_resp = self._e_step(X)\n+\n         return log_resp.argmax(axis=1)\n \n     def _e_step(self, X):\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "sympy__sympy-20590", "model_patch": "diff --git a/sympy/core/_print_helpers.py b/sympy/core/_print_helpers.py\nindex 96d7e72676..40ac1cec31 100644\n--- a/sympy/core/_print_helpers.py\n+++ b/sympy/core/_print_helpers.py\n@@ -16,6 +16,7 @@ class Printable:\n \n     This also adds support for LaTeX printing in jupyter notebooks.\n     \"\"\"\n+    __slots__ = ()\n \n     # Note, we always use the default ordering (lex) in __str__ and __repr__,\n     # regardless of the global setting. See issue 5487.\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "matplotlib__matplotlib-23299", "model_patch": "diff --git a/lib/matplotlib/__init__.py b/lib/matplotlib/__init__.py\nindex c268a56724..0acba41c97 100644\n--- a/lib/matplotlib/__init__.py\n+++ b/lib/matplotlib/__init__.py\n@@ -1175,7 +1175,7 @@ def get_backend():\n     --------\n     matplotlib.use\n     \"\"\"\n-    return rcParams['backend']\n+    return rcParams._get_backend_or_none() or rcParams['backend']\n \n \n def interactive(b):\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "sphinx-doc__sphinx-11445", "model_patch": "diff --git a/sphinx/util/rst.py b/sphinx/util/rst.py\nindex 7a1538325..e4937ec88 100644\n--- a/sphinx/util/rst.py\n+++ b/sphinx/util/rst.py\n@@ -25,7 +25,7 @@ except ImportError:\n \n logger = logging.getLogger(__name__)\n \n-docinfo_re = re.compile(':\\\\w+:.*?')\n+docinfo_re = re.compile(r':[\\w ]+:(?!`).*?')\n symbols_re = re.compile(r'([!-\\-/:-@\\[-`{-~])')  # symbols without dot(0x2e)\n SECTIONING_CHARS = ['=', '-', '~']\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "django__django-15814", "model_patch": "diff --git a/django/db/models/query.py b/django/db/models/query.py\nindex be0deb90b0..4a084a4397 100644\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -2596,7 +2596,7 @@ class RelatedPopulator:\n             )\n \n         self.model_cls = klass_info[\"model\"]\n-        self.pk_idx = self.init_list.index(self.model_cls._meta.pk.attname)\n+        self.pk_idx = self.init_list.index(self.model_cls._meta.concrete_model._meta.pk.attname)\n         self.related_populators = get_related_populators(klass_info, select, self.db)\n         self.local_setter = klass_info[\"local_setter\"]\n         self.remote_setter = klass_info[\"remote_setter\"]\ndiff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\nindex 33cc636b22..5036335bec 100644\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -748,7 +748,7 @@ class Query(BaseExpression):\n                     cur_model = source.related_model\n                 else:\n                     cur_model = source.remote_field.model\n-                opts = cur_model._meta\n+                opts = cur_model._meta.concrete_model._meta\n                 # Even if we're \"just passing through\" this model, we must add\n                 # both the current model's pk and the related reference field\n                 # (if it's not a reverse relation) to the things we select.\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "django__django-11999", "model_patch": "diff --git a/django/db/models/fields/__init__.py b/django/db/models/fields/__init__.py\nindex ee45bb941e..ce790675c1 100644\n--- a/django/db/models/fields/__init__.py\n+++ b/django/db/models/fields/__init__.py\n@@ -763,8 +763,10 @@ class Field(RegisterLookupMixin):\n             if not getattr(cls, self.attname, None):\n                 setattr(cls, self.attname, self.descriptor_class(self))\n         if self.choices is not None:\n-            setattr(cls, 'get_%s_display' % self.name,\n-                    partialmethod(cls._get_FIELD_display, field=self))\n+            method_name = 'get_%s_display' % self.name\n+            if not getattr(cls, method_name, None):\n+                setattr(cls, method_name,\n+                        partialmethod(cls._get_FIELD_display, field=self))\n \n     def get_filter_kwargs_for_object(self, obj):\n         \"\"\"\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "django__django-13028", "model_patch": "diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\nindex ce18098fd2..76447a771f 100644\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -1124,7 +1124,10 @@ class Query(BaseExpression):\n \n     def check_filterable(self, expression):\n         \"\"\"Raise an error if expression cannot be used in a WHERE clause.\"\"\"\n-        if not getattr(expression, 'filterable', True):\n+        # Only check filterable attribute for Django expression objects, not model instances\n+        # or other arbitrary objects that might have a field named 'filterable'\n+        if (hasattr(expression, 'get_source_expressions') and \n+            not getattr(expression, 'filterable', True)):\n             raise NotSupportedError(\n                 expression.__class__.__name__ + ' is disallowed in the filter '\n                 'clause.'\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "django__django-11848", "model_patch": "diff --git a/django/utils/http.py b/django/utils/http.py\nindex 572cfb4347..88d65c3e8f 100644\n--- a/django/utils/http.py\n+++ b/django/utils/http.py\n@@ -176,10 +176,15 @@ def parse_http_date(date):\n     try:\n         year = int(m.group('year'))\n         if year < 100:\n-            if year < 70:\n-                year += 2000\n+            # RFC 7231: Two-digit years that appear to be more than 50 years\n+            # in the future should be interpreted as the most recent year\n+            # in the past that had the same last two digits.\n+            current_year = datetime.datetime.now().year\n+            full_year = 2000 + year\n+            if full_year > current_year + 50:\n+                year = full_year - 100\n             else:\n-                year += 1900\n+                year = full_year\n         month = MONTHS.index(m.group('mon').lower()) + 1\n         day = int(m.group('day'))\n         hour = int(m.group('hour'))\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "django__django-14999", "model_patch": "diff --git a/django/db/migrations/operations/models.py b/django/db/migrations/operations/models.py\nindex 982816be3a..daac1aad2e 100644\n--- a/django/db/migrations/operations/models.py\n+++ b/django/db/migrations/operations/models.py\n@@ -320,6 +320,11 @@ class RenameModel(ModelOperation):\n         new_model = to_state.apps.get_model(app_label, self.new_name)\n         if self.allow_migrate_model(schema_editor.connection.alias, new_model):\n             old_model = from_state.apps.get_model(app_label, self.old_name)\n+            # If the table name hasn't changed, this is a no-op\n+            if (old_model._meta.db_table == new_model._meta.db_table or\n+                (schema_editor.connection.features.ignores_table_name_case and\n+                 old_model._meta.db_table.lower() == new_model._meta.db_table.lower())):\n+                return\n             # Move the main table\n             schema_editor.alter_db_table(\n                 new_model,\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "django__django-12308", "model_patch": "diff --git a/django/contrib/admin/utils.py b/django/contrib/admin/utils.py\nindex e4ddc8f017..c27628a134 100644\n--- a/django/contrib/admin/utils.py\n+++ b/django/contrib/admin/utils.py\n@@ -398,6 +398,8 @@ def display_for_field(value, field, empty_value_display):\n         return formats.number_format(value)\n     elif isinstance(field, models.FileField) and value:\n         return format_html('<a href=\"{}\">{}</a>', value.url, value)\n+    elif isinstance(field, models.JSONField):\n+        return field.formfield().prepare_value(value)\n     else:\n         return display_for_value(value, empty_value_display)\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "scikit-learn__scikit-learn-13439", "model_patch": "diff --git a/sklearn/pipeline.py b/sklearn/pipeline.py\nindex 7eaf9a46f..54841e476 100644\n--- a/sklearn/pipeline.py\n+++ b/sklearn/pipeline.py\n@@ -219,6 +219,10 @@ class Pipeline(_BaseComposition):\n             return self.named_steps[ind]\n         return est\n \n+    def __len__(self):\n+        \"\"\"Returns the number of steps in the pipeline.\"\"\"\n+        return len(self.steps)\n+\n     @property\n     def _estimator_type(self):\n         return self.steps[-1][1]._estimator_type\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "scikit-learn__scikit-learn-14894", "model_patch": "diff --git a/sklearn/svm/base.py b/sklearn/svm/base.py\nindex 64cebe837..3509ba4bc 100644\n--- a/sklearn/svm/base.py\n+++ b/sklearn/svm/base.py\n@@ -286,12 +286,17 @@ class BaseLibSVM(BaseEstimator, metaclass=ABCMeta):\n             n_class = 1\n         n_SV = self.support_vectors_.shape[0]\n \n-        dual_coef_indices = np.tile(np.arange(n_SV), n_class)\n-        dual_coef_indptr = np.arange(0, dual_coef_indices.size + 1,\n-                                     dual_coef_indices.size / n_class)\n-        self.dual_coef_ = sp.csr_matrix(\n-            (dual_coef_data, dual_coef_indices, dual_coef_indptr),\n-            (n_class, n_SV))\n+        if n_SV == 0:\n+            # Handle edge case: no support vectors\n+            self.dual_coef_ = sp.csr_matrix((n_class, n_SV))\n+        else:\n+            # Normal case: create sparse matrix with support vector coefficients\n+            dual_coef_indices = np.tile(np.arange(n_SV), n_class)\n+            dual_coef_indptr = np.arange(0, dual_coef_indices.size + 1,\n+                                         dual_coef_indices.size / n_class)\n+            self.dual_coef_ = sp.csr_matrix(\n+                (dual_coef_data, dual_coef_indices, dual_coef_indptr),\n+                (n_class, n_SV))\n \n     def predict(self, X):\n         \"\"\"Perform regression on samples in X.\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "scikit-learn__scikit-learn-25747", "model_patch": "diff --git a/sklearn/utils/_set_output.py b/sklearn/utils/_set_output.py\nindex 335773c6a..0e40cb94d 100644\n--- a/sklearn/utils/_set_output.py\n+++ b/sklearn/utils/_set_output.py\n@@ -56,7 +56,8 @@ def _wrap_in_pandas_container(\n         if columns is not None:\n             data_to_wrap.columns = columns\n         if index is not None:\n-            data_to_wrap.index = index\n+            if len(index) == len(data_to_wrap):\n+                data_to_wrap.index = index\n         return data_to_wrap\n \n     return pd.DataFrame(data_to_wrap, index=index, columns=columns)\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
{"instance_id": "django__django-11133", "model_patch": "diff --git a/django/http/response.py b/django/http/response.py\nindex 6a84e193ba..b1192f1fc7 100644\n--- a/django/http/response.py\n+++ b/django/http/response.py\n@@ -234,6 +234,8 @@ class HttpResponseBase:\n         if isinstance(value, str):\n             return bytes(value.encode(self.charset))\n         # Handle non-string types.\n+        if isinstance(value, memoryview):\n+            return bytes(value)\n         return str(value).encode(self.charset)\n \n     # These methods partially implement the file-like object interface.\n", "model_name_or_path": "Lingxi_v1.5_x_Kimi_K2"}
